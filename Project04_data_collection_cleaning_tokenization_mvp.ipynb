{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from https://www.kaggle.com/extralime/math-lectures/version/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T23:09:32.207880Z",
     "start_time": "2019-11-12T23:08:54.858980Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:03.564421Z",
     "start_time": "2019-11-11T20:22:03.557359Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:03.592196Z",
     "start_time": "2019-11-11T20:22:03.570865Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes ~30 seconds to import\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:03.603584Z",
     "start_time": "2019-11-11T20:22:03.595919Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:03.612950Z",
     "start_time": "2019-11-11T20:22:03.608624Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:03.882601Z",
     "start_time": "2019-11-11T20:22:03.617155Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:05.809546Z",
     "start_time": "2019-11-11T20:22:03.885968Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:15.315649Z",
     "start_time": "2019-11-11T20:22:05.817744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/metis/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T23:10:18.345028Z",
     "start_time": "2019-11-12T23:10:17.486907Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T23:10:18.493229Z",
     "start_time": "2019-11-12T23:10:18.421740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The following content is\\nprovided under a Cre...</td>\n",
       "      <td>Calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>In this sequence of segments,\\nwe review some ...</td>\n",
       "      <td>Probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The following content is\\nprovided under a Cre...</td>\n",
       "      <td>CS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The following\\ncontent is provided under a Cre...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The following\\ncontent is provided under a Cre...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        label\n",
       "0  The following content is\\nprovided under a Cre...     Calculus\n",
       "1  In this sequence of segments,\\nwe review some ...  Probability\n",
       "2  The following content is\\nprovided under a Cre...           CS\n",
       "3  The following\\ncontent is provided under a Cre...   Algorithms\n",
       "4  The following\\ncontent is provided under a Cre...   Algorithms"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T23:10:20.568420Z",
     "start_time": "2019-11-12T23:10:20.435679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AI</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Algorithms</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CS</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Calculus</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Data Structures</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Diff. Eq.</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Linear Algebra</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Math for Eng.</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NLP</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Probability</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Statistics</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text\n",
       "label                \n",
       "AI                 48\n",
       "Algorithms         81\n",
       "CS                104\n",
       "Calculus           70\n",
       "Data Structures    62\n",
       "Diff. Eq.          93\n",
       "Linear Algebra    152\n",
       "Math for Eng.      28\n",
       "NLP                19\n",
       "Probability       124\n",
       "Statistics         79"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:17.959614Z",
     "start_time": "2019-11-11T20:22:17.749200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The following content is\\nprovided under a Creative Commons license. Your support will help\\nMIT OpenCourseWare continue to offer high quality\\neducational resources for free. To make a donation, or to\\nview additional materials from hundreds of MIT courses,\\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: So,\\nProfessor Jerison is relaxing in sunny\\nLondon, Ontario today and sent me in as\\nhis substitute again. I'm glad to the here\\nand see you all again. So our agenda today: he\\nsaid that he'd already talked about power series\\nand Taylor's formula, I guess on last week\\nright, on Friday? So I'm going to go a\\nlittle further with that and show you some examples,\\nshow you some applications, and then I have this\\ncourse evaluation survey that I'll hand out in the last\\n10 minutes or so of the class. I also have this handout\\nthat he made that says 18.01 end of term 2007. If you didn't pick this up\\ncoming in, grab it going out. People tend not to pick it\\nup when they walk in, I see. So grab this when\\nyou're going out. There's some things\\nmissing from it. He has not decided\\nwhen his office hours will be at the end of term. He will have them, just\\nhasn't decided when. So, check the website\\nfor that information. And we're looking forward to\\nthe final exam, which is uh -- aren't we? Any questions about\\nthis technical stuff? All right, let's talk about\\npower series for a little bit. So I thought I should\\nreview for you what the story with power series is. OK, could I have your\\nattention please? So, power series is a way of\\nwriting a function as a sum of integral powers of x. These a_0, a_1, and\\nso on, are numbers. An example of a power\\nseries is a polynomial. Not to be forgotten,\\none type of power series is one which goes on for\\na finite number of terms and then ends, so that all of\\nthe other, all the higher a_i's are all 0. This is a perfectly good\\nexample of a power series; it's a very special\\nkind of power series. And part of what I\\nwant to tell you today is that power series\\nbehave, almost exactly like, polynomials. There's just one\\nthing that you have to be careful about when you're\\nusing power series that isn't a concern for polynomials,\\nand I'll show you what that is in a minute. So, you should think of them\\nas generalized polynomials. The one thing that you\\nhave to be careful about is that there is a\\nnumber-- So one caution. There's a number which I'll\\ncall R, where R can be between 0 and it can also be infinity. It's a number between 0\\nand infinity, inclusive, so that when the absolute\\nvalue of x is less than R. So when x is smaller than R\\nin size, the sum converges. This sum-- that sum\\nconverges to a finite value. And when x is bigger\\nthan R in absolute value, the sum diverges. This R is called the\\nradius of convergence. So we'll see some examples of\\nwhat the radius of convergence is in various powers series as\\nwell, and how you find it also. But, let me go on and\\ngive you a few more of the properties\\nabout power series which I think that professor\\nJerison talked about earlier. So one of them is there's\\na radius of convergence. Here's another one. If you're inside of\\nthe radius convergence, then the function has\\nall its derivatives, has all its derivatives,\\njust like a polynomial does. You can differentiate\\nit over and over again. And in terms of\\nthose derivatives, the number a_n in\\nthe power series can be expressed in terms of the\\nvalue of the derivative at 0. And this is called\\nTaylor's formula. So I'm saying that inside of\\nthis radius of convergence, the function that we're\\nlooking at, this f(x), can be written as the value of\\nthe function at 0, that's a_0, plus the value of\\nthe derivative. This bracket n means you\\ntake the derivative n times. So when n is 1, you take\\nthe derivative once at 0, divided by 1!, which is\\n!, and multiply it by x. That's the linear term\\nin the power series. And then the quadratic term is\\nyou take the second derivative. Remember to divide\\nby 2!, which is 2. Multiply that by\\nx^2 and so on out. So, in terms-- So\\nthe coefficients in the power series just record\\nthe values of the derivatives of the function at x = 0. They can be computed\\nthat way also. Let's see. I think that's the end\\nof my summary of things that he talked about. I think he did one\\nexample, and I'll repeat that example of a power series. This example wasn't\\ndue to David Jerison; it was due to Leonard Euler. It's the example of where the\\nfunction is the exponential function e^x. So, let's see. Let's compute what-- I will just\\nrepeat for you the computation of the power series for\\ne^x, just because it's such an important thing to do. So, in order to do that, I have\\nto know what the derivative of e^x is, and what the\\nsecond derivative of e^x is, and so on, because that\\ncomes into the Taylor formula for the coefficients. But we know what the derivative\\nof e^x is, it's just e^x again, and it's that way\\nall the way down. All the derivatives are\\ne^x over and over again. So when I evaluate this at x =\\n0, well, the value of e^x is 1, the value of e^x is 1 at x = 0. You get a value of\\n1 all the way down. So all these derivatives\\nat 0 have the value 1. And now, when I plug\\ninto this formula, I find e^x is 1 plus 1*x\\nplus 1/2! x^2 plus 1/3! x^3, plus and so on. So all of these\\nnumbers are 1, and all you wind up with is the\\nfactorials in the denominators. That's the power series for e^x. This was a discovery of Leonhard\\nEuler in 1740 or something. Yes, Ma'am. AUDIENCE: When you're\\nwriting out the power series, how far do you have\\nto write it out? PROFESSOR: How far do you\\nhave to write the power series before it becomes well defined? Before it's a satisfactory\\nsolution to an exam problem, I suppose, is another way\\nto phrase the question. Until you can see\\nwhat the pattern is. I can see what the pattern is. Is there anyone who's\\nin doubt about what the next term might be? Some people would\\ntell you that you have to write the\\nsummation convention thing. Don't believe them. If you right out enough\\nterms to make it clear, that's good enough. OK? Is that an answer for you? AUDIENCE: Yes, Thank you. PROFESSOR: OK, so\\nthat's a basic example. Let's do another basic\\nexample of a power series. Oh yes, and by the way, whenever\\nyou write out a power series, you should say what the\\nradius of convergence is. And for now, I will\\njust to tell you that the radius of convergence\\nof this power series is infinity; that\\nis, this sum always converges for any value of x. I'll say a little more\\nabout that in a few minutes. Yeah? AUDIENCE: So which functions\\ncan be written as power series? PROFESSOR: Which functions can\\nbe written as power series? That's an excellent question. Any function that has\\na reasonable expression can be written as\\na power series. I'm not giving you a very good\\nanswer because the true answer is a little bit complicated. But any of the\\nfunctions that occur in calculus like sines,\\ncosines, tangents, they all have power series expansions, OK? We'll see more examples. Let's do another example. Here's another example. I guess this was example one. So, this example, I think,\\nwas due to Newton, not Euler. Let's find the power series\\nexpansion of this function: 1/(1+x). Well, I think that\\nsomewhere along the line, you learned about the geometric\\nseries which tells you that-- which tells you\\nwhat the answer to this is, and I'll just write it out. The geometric series tells\\nyou that this function can be written as an\\nalternating sum of powers of x. You may wonder where\\nthese minuses came from. Well, if you really think\\nabout the geometric series, as you probably remembered,\\nthere was a minus sign here, and that gets replaced\\nby these minus signs. I think maybe Jerison\\ntalked about this also. Anyway, here's\\nanother basic example. Remember what the\\ngraph of this function looks like when x = -1. Then there's a\\nlittle problem here because the\\ndenominator becomes 0, so the graph has a pole there. It goes up to\\ninfinity at x = -1, and that's an indication that\\nthe radius of convergence is not infinity. Because if you try to converge\\nto this infinite number by putting in x = -1, here,\\nyou'll have a big problem. In fact, you see when\\nyou put in x = -1, you keep getting\\n1 in every term, and it gets bigger and\\nbigger and does not converge. In this example, the\\nradius of convergence is 1. OK, so, let's do\\na new example now. Oh, and by the way,\\nI should say you can calculate these numbers\\nusing Taylor's formula. If you haven't seen\\nit, check it out. Calculate the iterated\\nderivatives of this function and plug in x = 0 and see\\nthat you get +1, -1, +1, -1, and so on. Yes sir. AUDIENCE: For the\\nradius of convergence I see that if you do\\n-1 it'll blow out. If you put in 1 though, it\\nseems like it would be fine. PROFESSOR: The\\nquestions is I can see that there's a\\nproblem at x = -1, why is there also\\na problem at x = 1 where the graph is\\nperfectly smooth and innocuous and finite. That's another\\nexcellent question. The problem is that if you\\ngo off to a radius of 1 in any direction and there's\\na problem, that's it. That's what the radius\\nof convergence is. Here, what does happen\\nif I put an x = +1? So, let's look at\\nthe partial sums. Do x = +1 in your mind here. So I'll get a partial sum 1,\\nthen 0, and then 1, and then 0, and then 1. So even though it doesn't\\ngo up to infinity, it still does not converge. AUDIENCE: And\\nanything in between? PROFESSOR: Any of\\nthese other things will also fail to\\nconverge in this example. Well, that's the only two\\nreal numbers at the edge. Right? OK, let's do a\\ndifferent example now. How about a trig function? The sine of x. I'm going to compute the power\\nseries expansion for sin(x). and I'm going to do it\\nusing Taylor's formula. So Taylor's formula\\nsays that I have to start computing\\nderivatives of sin(x). Sounds like it's going\\nto be a lot of work. Let's see, the derivative\\nof the sine is the cosine. And the derivative\\nof the cosine, that's the second derivative\\nof the sine, is what? Remember the minus,\\nit's -sin(x). OK, now I want to take the third\\nderivative of the sine, which is the derivative\\nof sine prime prime, so it's the derivative of this. And we just decided\\nthe derivative of sine is cosine, so I\\nget cosine, but I have this minus sign in front. And now I want to\\ndifferentiate again, so the cosine\\nbecomes a minus sine, and that sign cancels with this\\nminus sign to give me sin(x). You follow that? It's a lot of -1's\\ncanceling out there. So, all of a sudden, I'm\\nright back where I started; these two are the same and the\\npattern will now repeat forever and ever. Higher and higher\\nderivatives of sines are just plus or minus\\nsines and cosines. Now Taylor's formula says I\\nshould now substitute x = 0 into this and see what\\nhappens, so let's do that. When x is equals to 0, the\\nsine is 0 and the cosine is 1. The sine is 0, so\\nminus 0 is also 0. The cosine is 1, but\\nnow there's a minus one, and now I'm back\\nwhere I started, and so the pattern will repeat. OK, so the values\\nof the derivatives are all zeros and\\nplus and minus ones and they go through that\\npattern, four-fold periodicity, over and over again. And so we can write\\nout what sin(x) is using Taylor's formula,\\nusing this formula. So I put in the value\\nat 0 which is 0, then I put in the derivative\\nwhich is 1, multiplied by x. Then, I have the second\\nderivative divided by 2!, but the second\\nderivative at 0 is 0. So I'm going to\\ndrop that term out. Now I have the third\\nderivative which is -1. And remember the 3! in the denominator. That's the coefficient of x^3. What's the fourth derivative? Well, here we are, it's\\non the board, it's 0. So I drop that term out\\ngo up to the fifth term, the fifth power of x. Its derivative is now 1. We've gone through the pattern,\\nwe're back at +1 as the value of the iterated derivative,\\nso now I get 1/5! x^5. Now, you tell me, have we\\ndone enough terms to see what the pattern is? I guess the next\\nterm will be a -1/7! x^7, and so on. Let me write this out\\nagain just so we have it. x^3 / 3!-- So it's\\nx minus x^3 / 3! plus x^5 / 5!. You guessed it, and so on. That's the power\\nseries expansion for the sine of x, OK? And so, the sign alternate,\\nand these denominators get very big, don't they? Exponentials grow very fast. Let me make a remark. R is infinity here. The radius of convergence\\nof this power series again is infinity, and\\nlet me just say why. The reason is that the general\\nterm is going to be like x^(2n+1) / (2n+1)!. An odd number I can\\nwrite as 2n + 1. And what I want to\\nsay is that the size of this, what happens\\nto the size of this as n goes to infinity? So let's just think about this. For a fixed x, let's\\nfix the number x. Look at powers of x and\\nthink about the size of this expression when\\nn gets to be large. So let's just do\\nthat for a second. So, x^(2n+1) / (2n+1)!, I\\ncan write out like this. It's x / 1 times x / 2\\n-- sorry -- times x / 3, times x / (2n+1). I've multiplied x by itself\\n2n+1 times in the numerator, and I've multiplied\\nthe numbers 1, 2, 3, 4, and so on, by each other\\nin the denominator, and that gives me the factorial. So I've just written\\nthis out like this. Now x is fixed, so maybe\\nit's a million, OK? It's big, but fixed. What happens to these numbers? Well at first,\\nthey're pretty big. This is 1,000,000 / 2,\\nthis is 1,000,000 / 3. But when n gets to be--\\nMaybe if n is 1,000,000, then this is about 1/2. If n is a billion, then this\\nis about 1/2,000, right? The denominators keep\\ngetting bigger and bigger, but the numerators stay\\nthe same; they're always x. So when I take the product,\\nif I go far enough out, I'm going to be multiplying,\\nby very, very small numbers and more and more of them. And so no matter what\\nx is, these numbers will converge to 0. They'll get smaller and\\nsmaller as x gets to be bigger. That's the sign that x is inside\\nof the radius of convergence. This is the sign for\\nyou that this series converges for that value of x. And because I could do\\nthis for any x, this works. This convergence to\\n0 for any fixed x. That's what tells\\nyou that you can take-- that the radius of\\nconvergence is infinity. Because in the\\nformula, in the fact, in this property that\\nthe radius of convergence talks about, if R is\\nequal to infinity, this is no condition on x. Every number is less than\\ninfinity in absolute value. So if this convergence\\nto 0 of the general term works for every x, then radius\\nof convergence is infinity. Well that was kind\\nof fast, but I think that you've heard\\nsomething about that earlier as well. Anyway, so we've got the\\nsine function, a new function with its own power series. It's a way of computing sin(x). If you take enough\\nterms you'll get a good evaluation of sin(x). for any x. This tells you a lot\\nabout the function sin(x) but not everything at all. For example, from\\nthis formula, it's very hard to see that the\\nsine of x is periodic. It's not obvious at all. Somewhere hidden away\\nin this expression is the number pi, the\\nhalf of the period. But that's not clear from\\nthe power series at all. So the power series are\\nvery good for some things, but they hide other\\nproperties of functions. Well, so I want to spend\\na few minutes telling you about what you can do\\nwith a power series, once you have one, to get new\\npower series, so new power series from old. And this is also called\\noperations on power series. So what are the things that\\nwe can do to a power series? Well one of the things\\nyou can do is multiply. So, for example, what if\\nI want to compute a power series for x sin(x)? Well I have a power series\\nfor sin(x), I just did it. How about a power series for x? Actually, I did that here too. The function x is a\\nvery simple polynomial. It's a polynomial where\\nthat's 0, a_1 is 1, and all the other\\ncoefficients are 0. So x itself is a power\\nseries, a very simple one. sin(x) is a powers series. And what I want to\\nencourage you to do is treat power series\\njust like polynomials and multiply them together. We'll see other operations too. So, to compute the power series\\nfor x sin(x), of I just take this one and multiply it by x. So let's see if I\\ncan do that right. It distributes through:\\nx^2 minus x^4 / 3! plus x^6 / 5!, and so on. And again, the\\nradius of convergence is going to be the smaller of\\nthe two radii of convergence here. So it's R equals\\ninfinity in this case. OK, you can multiply\\npower series together. It can be a pain if the\\npower series are very long, but if one of them is\\nx, it's pretty simple. OK, that's one thing I can do. Notice something by the way. You know that even\\nand odd functions? So, sine is an odd function,\\nx is an odd function, the product of two odd\\nfunctions is an even function. And that's reflected in the fact\\nthat all the powers that occur in the power series are even. For an odd function, like the\\nsine, all the powers that occur are odd powers of x. That's always true. OK, we can multiply. I can also differentiate. So let's just do a\\ncase of that, and use the process of\\ndifferentiation to find out what the power\\nseries for cos(x) is by writing the cos(x) as\\nthe derivative of the sine and differentiating\\nterm by term. So, I'll take this\\nexpression for the power series of the sine and\\ndifferentiate it term by term, and I'll get the power\\nseries for cosine. So, let's see. The derivative of x is one. Now, the derivative of x^3 is\\n3x^2, and then there's a 3! in the denominator. And the derivative of x^5\\n5x^4, and there's a 5! in the denominator,\\nand so on and so on. And now some\\ncancellation happens. So this is 1 minus, well, the\\n3 cancels with the last factor in this 3 factorial\\nand leaves you with 2!. And the 5 cancels with the\\nlast factor in the 5 factorial and leaves you with a 4! in the denominator. And so there you go, there's\\nthe power series expansion for the cosine. It's got all even powers of x. They alternate, and you have\\nfactorials in the denominator. And of course, you could\\nderive that expression by using Taylor's formula, by\\nthe same kind of calculation you did here, taking higher\\nand higher derivatives of the cosine. You get the same\\nperiodic pattern of derivatives and values\\nof derivatives at x = 0. But here's a cleaner way to\\ndo it, simpler way to do it, because we already knew\\nthe derivative of the sine. When you differentiate, you keep\\nthe same radius of convergence. OK, so we can\\nmultiply, I can add too and multiply by a\\nconstant, things like that. How about integrating? That's what half of this\\ncourse was about isn't it? So, let's integrate something. So, the integration I'm\\ngoing to do is this one: the integral from 0\\nto x of dt / (1+x). What is that integral\\nas a function? So, when I find the\\nanti-derivative of this, I get ln(1+t), and then when\\nI evaluate that at t = x, I get ln(1+x). And when I evaluate the natural\\nlog at 0, I get the ln 1, which is 0, so this\\nis what you get, OK? This is really valid, by the\\nway, for x bigger than -1. But you don't want to think\\nabout this quite like this when x is smaller than that. Now, I'm going to try to apply\\npower series methods here and find-- use this integral\\nto find a power series for the natural log, and I'll\\ndo it by plugging into this expression what the power\\nseries for 1/(1+t) was. And I know what that is because\\nI wrote it down on the board up here. Change the variable\\nfrom x to t there, and so 1/(1+t) is 1 minus t\\nplus t^2 minus t^3, and so on. So that's the thing in the\\ninside of the integral, and now it's legal to\\nintegrate that term by term, so let's do that. I'm going to get something\\nwhich I will then evaluate at x and at 0. So, when I integrate 1 I get\\nx, and when I integrate t, I get t. I'm sorry. When I integrate t, I get t^2\\n/ 2, and t^2 gives me t^3 / 3, and so on and so on. And then, when I\\nput in t = x, well, I just replace all the t's by\\nx's, and when I put in t = 0, I get 0. So this equals x. So, I've discovered that ln(1+x)\\nis x minus x^2 / 2 plus x^3 / 3 minus x^4 / 4, and\\nso on and so on. There's the power series\\nexpansion for ln(1+x). And because I began\\nwith a power series whose radius of\\nconvergence was just 1, I began with this power\\nseries, the radius of convergence of this\\nis also going to be 1. Also, because this function,\\nas I just pointed out, this function goes bad when\\nx becomes less than -1, so some problem happens,\\nand that's reflected in the radius of convergence. Cool. So, you can integrate. That is the correct power series\\nexpansion for the ln(1+x), and another victory of Euler's\\nwas to use this kind of power series expansion to calculate\\nnatural logarithms in a much more efficient way than\\npeople had done before. OK, one more property, I think. What are we at here, 3? 4. Substitute. Very appropriate for me\\nas a substitute teacher to tell you about substitution. So I'm going to try to find\\nthe power series expansion of e^(-t^2). OK? And the way I'll do that is\\nby taking the power series expansion for e^x,\\nwhich we have up there, and make the substitution x =\\n-t^2 in the expansion for e^x. Did you have a question? AUDIENCE: Well,\\nit's just concerning the radius of convergence. You can't define x so that is\\nalways positive, and if so, it wouldn't have a radius\\nof convergence, right? PROFESSOR: Like I say, again the\\nworry is this ln(1+x) function is perfectly well\\nbehaved for large x. Why does the power series\\nfail to converge for large x? Well suppose that\\nx is bigger than 1, then here you get\\nbigger and bigger powers of x, which will\\ngrow to infinity, and they grow large faster\\nthan the numbers 2, 3, 4, 5, 6. They grow exponentially, and\\nthese just grow linearly. So, again, the general term,\\nwhen x is bigger than one, the general term will\\ngo off to infinity, even though the function\\nthat you're talking about, log of net of 1 plus\\nx is perfectly good. So the power series is not\\ngood outside of the radius of convergence. It's just a fact of life. Yes? AUDIENCE: [INAUDIBLE] PROFESSOR: I'd rather--\\ntalk to me after class. The question is why is\\nit the smaller of the two radii of convergence? The basic answer\\nis, well, you can't expect it to be bigger than that\\nsmaller one, because the power series only gives\\nyou information inside of that range\\nabout the function, so. AUDIENCE: [INAUDIBLE] PROFESSOR: Well, in this\\ncase, both of the radii of convergence are infinity. x has radius of convergence\\ninfinity for sure, and sin(x) does too. So you get infinity\\nin that case, OK? OK, let's just do\\nthis, and then I'm going to integrate\\nthis and that'll be the end of what I\\nhave time for today. So what's the power\\nseries expansion for this? The power series\\nexpansion of this is going to be a\\nfunction of t, right, because the variable here is t. I get it by taking my expansion\\nfor e^x and putting in what x is in terms of t. Whoops! And so on and so on. I just put in -t^2 in place of\\nx there in the series expansion for e^x. I can work this out\\na little bit better. -t^2 is what it is. This is going to give me a t^4\\nand the minus squared is going to give me a plus,\\nso I get t^4 / 2!. Then I get (-t)^3, so there'll\\nbe a minus sign and a t^6 and the denominator 3!. So the signs are\\ngoing to alternate, the powers are all even,\\nand the denominators are these factorials. Several times as this\\ncourse has gone on, the error function has\\nmade an appearance. The error function was, I guess\\nit gets normalized by putting a 2 over the square\\nroot of pi in front, and it's the integral of\\ne^(-t^2) dt from 0 to x. And this normalization\\nis here because as x gets to be large\\nthe value becomes 1. So this error function is\\nvery important in the theory of probability. And I think you calculated\\nthis fact at some point in the course. So the standard definition of\\nthe error function, you put a 2 over the square\\nroot of pi in front. Let's calculate its\\npower series expansion. So there's a 2 over\\nthe square root of pi that hurts nobody\\nhere in the front. And now I want to\\nintegrate e^(-t^2), and I'm going to use this\\npower series expansion for that to see what you get. So I'm just going to\\nwrite this out I think. I did it out carefully in\\nanother example over there, so I'll do it a\\nlittle quicker now. Integrate this term\\nby term, you're just integrating powers of\\nt so it's pretty simple, so I get-- and then I'm\\nevaluating at x and then at 0. So I get x minus x^3 /\\n3, plus x^5 / (5*2!), 5 from integrating\\nthe t^4, and the 2! from this denominator\\nthat we already had. And then there's a -x^7\\n/ (7*3!), and plus, and so on, and you can imagine\\nhow they go on from there. I guess to get this\\nexactly in the form that we began talking about,\\nI should multiply through. So the coefficient of x is 2\\nover the square root of pi, and the coefficient of x^3 is\\n-2 over 3 times the square root of pi, and so on. But this is a perfectly good\\nway to write this power series expansion as well. And, this is a very good way to\\ncompute the value of the error function. It's a new function\\nin our experience. Your calculator\\nprobably calculates it, and your calculator probably\\ndoes it by this method. OK, so that's my sermon\\non examples of things you can do with power series. So, we're going to do the\\nCEG thing in just a minute. Professor Jerison wanted\\nme to make an ad for 18.02. Just in case you were thinking\\nof not taking it next term, you really should take it. It will put a lot of\\nthings in this course into context, for one thing. It's about vector\\ncalculus and so on. So you'll learn about\\nvectors and things like that. But it comes back and\\nexplains some things in this course that might\\nhave been a little bit strange, like these strange\\nformulas for the product rule and the quotient rule and\\nthe sort of random formulas. Well, one of the things\\nyou learn in 18.02 is that they're all special\\ncases of the chain rule. And just to drive\\nthat point home, he wanted me to show you\\nthis poem of his that really drives the points\\nhome forcefully, I think.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:18.989517Z",
     "start_time": "2019-11-11T20:22:17.965122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) # 860 documents in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:21.028538Z",
     "start_time": "2019-11-11T20:22:18.993562Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at balance of labels\n",
    "subjects = df.label.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:21.647847Z",
     "start_time": "2019-11-11T20:22:21.030735Z"
    }
   },
   "outputs": [],
   "source": [
    "subjects = pd.Series(subjects.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:22.135127Z",
     "start_time": "2019-11-11T20:22:21.651735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Linear Algebra\n",
       "1         Probability\n",
       "2                  CS\n",
       "3           Diff. Eq.\n",
       "4          Algorithms\n",
       "5          Statistics\n",
       "6            Calculus\n",
       "7     Data Structures\n",
       "8                  AI\n",
       "9       Math for Eng.\n",
       "10                NLP\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most videos cover Linear Algebra. Fewest cover NLP.  \n",
    "\n",
    "Some thoughts:\n",
    "- Are Algorithms, Data Structures, AI, and NLP all sub-categories of CS?\n",
    "- Would Probability and Statistics have a lot of overlap?\n",
    "- I expect Calculus, Linear Algebra, and Diff. Eq. to be mostly unique.\n",
    "- How do I account for one subject depending on another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a few documents at random from each subject and test some cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:22.733511Z",
     "start_time": "2019-11-11T20:22:22.139545Z"
    }
   },
   "outputs": [],
   "source": [
    "import random # for some reason, random.choices doesn't work here unless you import random again.\n",
    "test_df = df.copy()\n",
    "test = []\n",
    "for s in subjects:\n",
    "    test.append(random.choices(test_df.iloc[:,0], k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:23.533737Z",
     "start_time": "2019-11-11T20:22:22.737030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:24.151165Z",
     "start_time": "2019-11-11T20:22:23.537899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The following content is\\nprovided under a Creative Commons license. Your support will help\\nMIT OpenCourseWare continue to offer high quality\\neducational resources for free. To make a donation or\\nview additional materials from hundreds of MIT courses,\\nvisit MIT OpenCourseWare at ocw.mit.edu. ERIC GRIMSON: Ladies\\nand gentlemen, I\\'d like to get started. My name\\'s Eric Grimson. I have the privilege of\\nserving as MIT\\'S chancellor for academic advancement, you\\ncan go look up what that means, and like John I\\'m a\\nformer head of course six. This term, with\\nAna and John, I\\'m going to be splitting the\\nlectures, so I\\'m up to date. OK last time Ana introduced\\nthe first of the compound data types, tuples and lists. She showed lots of ways\\nof manipulating them, lots of built in things for\\nmanipulating those structures. And the key difference\\nbetween the two of them was that tuples were immutable,\\nmeaning you could not change them, lists\\nwere mutable, they could be changed, or mutated. And that led to both some nice\\npower and some opportunities for challenges. And, in particular, she showed\\nyou things like aliasing, where you could have two names\\npointing to the same list structure, and\\nbecause of that, you could change the\\ncontents of one, it would change the appearance\\nof the contents of the other, and that leads to\\nsome nice challenges. So the side effects\\nof mutability are one of the things you\\'re\\ngoing to see, both as a plus and minus, as we go\\nthrough the course. Today we\\'re going to take\\na different direction for a little while, we\\'re\\ngoing to talk about recursion. It Is a powerful\\nand wonderful tool for solving\\ncomputational problems. We\\'re then going to look at\\nanother kind of compound data structure, a dictionary,\\nwhich is also mutable. And then we\\'re going to put the\\ntwo pieces together and show how together they actually\\ngive you a lot of power for solving some really neat\\nproblems very effectively. But I want to start\\nwith recursion. Perhaps one of the most\\nmysterious, at least according to programmer\\'s, concepts in\\ncomputer science, one that leads to lots of really\\nbad computer science jokes, actually all computer\\nscience jokes are bad, but these are particularly bad. So let\\'s start with the obvious\\nquestion, what is recursion? If you go to the ultimate\\nsource of knowledge, Wikipedia, you get something that\\nsays, in essence, recursion is the process of repeating\\nitems in a self-similar way. Well that\\'s really\\nhelpful, right? But we\\'re going to see that\\nidea because recursion, as we\\'re going to\\nsee in a second, is the idea of taking a problem\\nand reducing it to a smaller version of the same\\nproblem, and using that idea to actually tackle a bunch of\\nreally interesting problems. But recursion gets used\\nin a lot of places. So it\\'s this idea of\\nusing, or repeating, the idea multiple times. So wouldn\\'t it be great if your\\n3D printer printed 3D printers? And you could just keep\\ndoing that all the way along. Or one that\\'s a\\nlittle more common, it\\'s actually got\\na wonderful name, it\\'s called mise en abyme,\\nin art, sometimes referred to as the Droste\\neffect, pictures that have inside them a\\npicture of the picture, which has inside them a picture of the\\npicture, and you get the idea. And of course, one\\nof the things you want to think about\\nin recursion is not to have it go on infinitely. And yes there are even light\\nbulb jokes about recursion, if you can\\'t read\\nit, it says, how many twists does it take to\\nscrew in a light bulb? And it says, if it\\'s already\\nscrewed in, the answer is 0. Otherwise, twist it once, ask\\nme again, add 1 to my answer. And that\\'s actually a nice\\ndescription of recursion. So let\\'s look at\\nit more seriously. What is recursion? I want to describe it both\\nabstractly, or algorithmically, and semantically or, if you\\nlike, in terms of programming. Abstractly, this is a\\ngreat instance of something often called divide-and-conquer,\\nor sometimes called decrease-and-conquer. And the idea of\\nrecursion is, I want to take a problem I\\'m trying\\nto solve and say, how could I reduce it to a simpler\\nversion of the same problem, plus some things\\nI know how to do? And then that\\nsimpler version, I\\'m going to reduce\\nit again and keep doing that until I get\\ndown to a simple case that I can solve directly. That is how we\\'re going to\\nthink about designing solutions to problems. Semantically, this is typically\\ngoing to lead to the case where a program, a\\ndefinition of function, will refer to\\nitself in its body. It will call itself\\ninside its body. Now, if you remember your\\nhigh school geometry teacher, she probably would wrap your\\nknuckles, which you\\'re not allowed to do, because\\nin things like geometry you can\\'t define something\\nin terms of itself, right? That\\'s not allowed. In recursion, this is OK. Our definition of a procedure\\ncan in its body call itself, so long as I have what\\nI call a base case, a way of stopping that\\nunwinding of the problems, when I get to something\\nI can solve directly. And so what we\\'re going to do\\nis avoid infinite recursion by ensuring that we have\\nat least one or more base cases that are easy to solve. And then the basic\\nidea is I just want to solve the same\\nproblem on some simpler input with the idea\\nof using that solution to solve the larger problem. OK, let\\'s look at an\\nexample, and to set the stage I\\'m going to go back\\nto something you\\'ve been doing, iterative algorithms. For loops, while\\nloops, they naturally lead to what we would\\ncall iterative algorithms, and these algorithms\\ncan be described as being captured by a\\nset of state variables, meaning one or more variables\\nthat tell us exactly the state of the computation. That\\'s a lot of words,\\nlet\\'s look at an example. I know it\\'s trivial,\\nbut bear with me. Suppose I want to do\\ninteger multiplication, multiply two integers\\ntogether, and all I have available\\nto me is addition. So a times b is the same as\\nadding a to itself b times. If I\\'m thinking about\\nthis iteratively, I could capture this computation\\nwith two state variables. One we\\'d just call\\nthe iteration number, and it would be\\nsomething, for example, that starts at b, and each time\\nthrough the loop reduces 1. One. And it will keep doing that\\nuntil I\\'ve counted down b times, and I get down to 0. And at the same\\ntime, I would have some value of the\\ncomputation, I might call it result, which starts at 0,\\nfirst time through adds an a, next time through\\nadds an a, and it just keeps track of how\\nmany things have I added up, until I get done. And yeah, I know you\\ncould just do mult, but this is trying\\nto get this idea of, how would I do\\nthis iteratively. So I might start off with i,\\nsaying there are b things still to add, and the result is 1. The first time through the\\nloop, I add an a, reduce i by 1. Next time through the\\nloop, I add in another a, reduce i by 1, and\\nyou get the idea. I just walk down it\\nuntil, eventually, I got to the end of this computation. So we could write code\\nfor this, and, actually, it should be pretty\\nstraightforward. There it is. Going to call it mult_iter,\\ntakes in two arguments a and b, and I\\'m going to capture\\nexactly that process. So notice what I\\ndo, I set up result internally as just\\na little variable I\\'m going to use to\\naccumulate things. And then, there\\nis the iteration, as long as b is greater\\nthan 0 what do I do? Add a to result, store\\nit away, reduce b by 1, and I\\'ll keep doing\\nthat until b gets down to being equal\\nto 0, in which case I just return the result.\\nOK, simple solution. Now, let\\'s think about\\nthis a different way. A times b is just adding\\na to itself b times, and that\\'s the same as a\\nplus adding a to a itself b minus 1 times. OK, that sounds\\nlike leisure to me, that sounds like just\\nplaying with words. But it\\'s really important,\\nbecause what is this? Ah, that\\'s just a\\ntimes b minus 1, by the definition\\nof the top point. And I know you\\'re\\ntotally impressed, but this is actually really\\ncool, because what have I done? I\\'ve taken one problem,\\nthis one up here, and I\\'ve reduced it to a simpler\\nversion of the same problem, plus some things\\nI know how to do. And how would I solve this? Same trick, that\\'s a\\ntimes a times b minus 2, I would just unwrap\\nit one more time, and I would just keep\\ndoing that until I get down to something I can solve\\ndirectly, a base case. And that\\'s easy, when b equal\\nto 1, the answer is just a. Or I could do when b is equal\\nto 0 the answer is just 0. And there\\'s code\\nto capture that. Different form, wonderful\\ncompact description, what does it say? It says, if I\\'m at the base\\ncase, if b is equal to 1, the answer is just a. Otherwise, I\\'m going to solve\\nthe same problem with a smaller version and add it to a\\nand return that result. And that\\'s nice, crisp\\ncharacterization of a problem. Recursive definition that\\nreduces a problem to a simpler version of the same problem. OK, let\\'s look at\\nanother example. Classic problem in recursion\\nis to compute factorial, right? n factorial,\\nor n bang if you like, n exclamation point\\nis n times n minus 1, all the way down to 1. So it\\'s the product of\\nall the integers from 1 up to n assuming n is\\na positive integer. So we can ask the\\nsame question if I wanted to solve this recursively\\nwhat would the base case be? Well, when n is equal\\nto 1, it\\'s just 1. In the recursive case,\\nwill n times n minus 1 all the way down to 1,\\nthat\\'s the same as n times n minus 1 factorial. So I can easily write\\nout the base case, and I\\'ve got a nice recursive\\nsolution to this problem. OK, if you\\'re like me and\\nthis is the first time you\\'ve seen it, it feels like\\nI\\'ve taken your head and twisted it\\nabout 180 degrees. I\\'m going to take it another\\n180 degrees because you might be saying, well,\\nwait a minute, how do you know it really stops. How do you know it really\\nterminates the computation? So let\\'s look at it. There is my definition for\\nfact, short for factorial. Fact of 1 is, if n is\\nequal to 1 return 1, otherwise return n\\ntimes fact of n minus 1. And let\\'s use the tools\\nthat Ana talked about, in terms of an\\nenvironment at a scope, and think about\\nwhat happens here. So when I read that in or I\\nevaluate that in Python, it creates a definition that binds\\nthe name fact to some code, just all of that stuff\\nover here plus the name for the formal parameter, hasn\\'t\\ndone anything with it yet. And then I\\'m going to\\nevaluate print a fact of 4. Print needs a value, so it has\\nto get the value of fact of 4, and we know what that does. It looks up fact, there it\\nis, it\\'s procedure definition. So it creates a new\\nframe, a new environment, it calls that procedure,\\nand inside that frame the formal parameter for fact\\nis bound to the value passed in. So n is bound to 4. That frame is scoped\\nby this global frame meaning it\\'s going to inherit\\nthings in the global frame. And what does it do? It says, inside of this frame\\nevaluate the body of fact. OK, so it says as n equal to 1? Nope, it\\'s not, it\\'s 4. So in that case, go to the\\nelse statement and says, oh, return n times fact of n\\nand n as 4, fact of n minus 1 says I need to return\\n4 times fact of 3. 4 is easy, multiplication\\nis easy, fact of 3, ah yes, I look up fact. Now I\\'m in this frame,\\nI don\\'t see fact there, but I go up to that frame. There\\'s the definition\\nfor fact, and we\\'re going to do the rest of\\nthis a little more quickly, what does that do? It creates a new\\nframe called by fact. And the argument passed\\nin for n is n minus 1, that value, right there, of 3. So 3 is now bound to n. Same game, evaluate the\\nbody is n equal to 1? No, so in that case, I\\'m going\\nto go to the return statement, it says return 3\\ntimes fact of 2. And notice it\\'s only\\nlooking at this value of n because that\\'s the\\nframe in which I\\'m in. It never sees that value of n. OK, aren\\'t you glad I\\ndidn\\'t do fact of 400? We\\'ve only got two more to\\ngo, but you get the idea. Same thing, I need\\nto get fact of 2 is going to call fact\\nagain with n bound to 2. Relative that evaluates the\\nbody and is not yet equal to 1. That says I\\'m going\\nto the else clause and return 2 times fact of 1. I call fact again,\\nnow with n bound to 1, and, fortunately, now\\nthat clause is true, and it says return 1. Whoops, sorry, before I do,\\nso there\\'s the base case. And it may seem apparent to you,\\nbut this is important, right? I\\'m unwinding this\\ntill I get to something that can stop the computation. Now I\\'m simply going to\\ngather the computation up, because it says return 1. Who asked for it? Well that call to fact of 1. So that reduces to\\nreturn 2 times 1. And who called for that? Fact of 2. That reduces to return a 3 times\\n2, which reduces to 4 times 6, which reduces\\nto printing out 24. So it unwinds it down to\\na base case and it stops. A couple of observations, notice\\nhow each recursive call creates its own frame, and\\nas a consequence, there\\'s no confusion about\\nwhich value of n I\\'m using. Also notice, in the other\\nframes, n was not changed. We did not mutate it. So we\\'re literally\\ncreating a local scope for that recursive call,\\nwhich is exactly what we want. Also notice how there was\\na sense of flow of control in computing fact of something,\\nthat reduces to returning n times fact of n minus 1, and\\nthat creates a new scope. And that will simply\\nkeep unwinding until I get to something\\nthat can return a value and then I gather all\\nthose frames back up. So there\\'s a natural\\nflow of control here. But most importantly, there\\'s no\\nconfusion about which variable I\\'m using when I\\'m\\nlooking for a value of n. All right, because this\\nis often a place where things get a little confusing,\\nI want to do one more example. But let me first\\nshow you side by side the two different\\nversions of factorial. Actually, I have lied slightly,\\nwe didn\\'t show this one earlier but there\\'s factorial if I\\nwanted to do it iteratively. I\\'d set up some\\ninitial variable to 1, and then I\\'d just\\nrun through a loop. For example, from 1 up to just\\nbelow n minus 1, or 1 up to n, multiplying it and putting\\nit back into return product. Which one do you like more? You can\\'t say neither\\nyou have to pick one. Show of hands, how many\\nof you like this one? Some hesitant ones, how\\nmany prefer this one? Yeah, that\\'s my view. I\\'m biased, but I really\\nlike the recursive one. It is crisper to look at,\\nyou can see what it\\'s doing. I\\'m reducing this\\nproblem to a simpler version of that problem. Pick your own\\nversion but I would argue that the\\nrecursive version is more intuitive to understand. From a programmer\\'s\\nperspective, it\\'s actually often more\\nefficient to write, because I don\\'t have to think\\nabout interior variables. Depending on the machine,\\nit may not be as efficient when you call it because\\nin the recursive version I\\'ve got it set up,\\nthat set of frames. And some versions\\nof these languages are actually very\\nefficient about it, some of them a little less so. But given the speed\\nof computers today, who cares as long as it actually\\njust does the computation. Right, one more example,\\nhow do we really know our recursive code works? Well, we just did a\\nsimulation but let\\'s look at it one more way. The iterative version,\\nwhat can I say about it? Well, I know it\\'s\\ngoing to terminate because b is initially\\npositive, assuming I gave it an appropriate value. It decreases by 1 every\\ntime around this loop, at some point it has to get\\nless than 1, it\\'s going to stop. So I can conclude it\\'s\\nalways going to terminate. What about the\\nrecursive version? Well, if I call it with\\nb equal to one, I\\'m done. If I call it with\\nb greater than one, again it\\'s going to reduce it\\nby one on the recursive call, which means on each recursive\\ncall it\\'s going to reduce and eventually it\\ngets down to a place, assuming I gave it a\\npositive integer, where b is equal to one. So it\\'ll stop, which just good. What we just did was\\nwe used the great tool from math, second best\\ndepartment at MIT. Wow, I didn\\'t even get any\\nhisses on that one, John, all right, and\\nI\\'m now in trouble with the head of\\nthe math department. So now that I got\\nyour attention, and yes, all computer\\nscience jokes are bad, and mine are really\\nbad, but I\\'m tenured. You cannot do a\\ndamn thing about it. Let\\'s look at mathematical\\ninduction which turns out to be a tool that lets\\nus think about programs in a really nice way. You haven\\'t seen\\nthis, here\\'s the idea of mathematical induction. If I want to prove\\na statement, and we refer to it as being\\nindexed on the integers. In other words, it\\'s some\\nmathematical statement that runs over integers. If I want to prove it\\'s true for\\nall values of those integers, mathematically I\\'d do\\nit by simply proving it\\'s true for the smallest\\nvalue of n typically n is equal to 0 or 1, and then\\nI do an interesting thing. I say I need to prove that\\nif it\\'s true for an arbitrary value of n, I\\'m just going\\nto prove that it\\'s also then true for n plus 1. And if I can do those\\ntwo things I can then conclude for an infinite\\nnumber of values of n it\\'s always true. Then we\\'ll relate it back\\nto programming in a second, but let me show you a\\nsimple example of this, one that you may have seen. If I had the integers from 0 up\\nto n, or even from 1 up to n, I claim that\\'s the same as\\nn times n plus 1 over 2. So 1, 2, 3, that\\'s 6, right. And that\\'s exactly\\nright, 3 times 4, which is divided by 2,\\nwhich gives me out 6. How would I prove this? Well, by induction? I need to do the simple\\ncases if n is equal to 0, well then this side is just 0. And that\\'s 0 times 1,\\nwhich is 0 divided by true. So 0 equals 0, it\\'s true. Now the inductive step. I\\'m going to assume\\nit\\'s true for some k, I should have picked\\nn, but for some k, and then what I need to show\\nis it\\'s true for k plus 1. Well, there\\'s the\\nleft hand side, and I want to show that\\nthis is equal to that. And I\\'m going do it by using\\nexactly this recursive idea, because what do I know, I know\\nthat this sum, in here, I\\'m assuming is true. And so that says that the left\\nhand side, the first portion of it, is just k\\ntimes k plus 1 over 2, that\\'s the definition of the\\nthing I\\'m assuming is true. To that I\\'m going\\nto add k plus 1. Well, you can do\\nthe algebra, right? That\\'s k plus 1\\nall times k over 2 plus 1, which is\\nk plus 2 over 2. Oh cool, it\\'s exactly that. Having done that, I\\ncan now conclude this is true for all values of n. What does it have to\\ndo with programming? That\\'s exactly what\\nwe\\'re doing when we think about recursive code, right? We\\'re saying, show that\\nit\\'s true for the base case, and then what I\\'m\\nessentially assuming is that, if it works for\\nvalues smaller than b, then does the code return\\nthe right answer for b? And the answer is,\\nabsolutely it does, and I\\'m using induction to\\ndeduce that, in fact, my code does the right thing. Why am I torturing\\nyou with this? Because this is the way I want\\nyou to think about recursion. When I\\'m going to\\nbreak a problem down into a smaller version\\nof the same problem, I can assume that the smaller\\nversion gives the answer. All I have to do is make sure\\nthat what I combined together gives me out the right result. OK, you may be\\nwondering what I\\'m doing with these wonderful\\nhigh tech toys down here. I want to show you another\\nexample of recursion. So far we\\'ve seen simple things\\nthat have just had one base case, and this is a\\nmythical story called The towers of Hanoi and\\nthis story, as I heard it, is there\\'s a temporal\\nsomewhere in Hanoi with three tall spikes and 64\\njewel-encrusted golden disks all of a different size. They all started out on\\none spike with the property that they were ordered from\\nsmallest down to largest. And there are priests in this\\ntemple who are moving the disks one at a time, one per\\nsecond, and their goal is to move the entire stack\\nfrom one spike to another spike. And when they do\\nnirvana is achieved and we all get a\\nreally great life. We\\'ll talk separately\\nabout how long is this going to take because\\nthere\\'s one trick to it. They can never cover a smaller\\ndisk with a larger disk as they\\'re doing it, so\\nthey\\'ve got a third disk as a temporary thing. And I want to show you\\nhow to solve this problem because you\\'re going to write\\ncode with my help in a second, or I\\'m going to write\\ncode with your help in a second to solve it. So let\\'s look at it,\\nso watch carefully, moving a disk of size one,\\nwell that\\'s pretty easy, right? Moving a disk of\\nsize two, we\\'ll just put this one on the spare\\none while you move it over so you don\\'t cover it up. That\\'s easy. Moving a disk of\\nsize three, you\\'ve got be a little more careful,\\nyou can\\'t cover up a smaller one with a larger one, so\\nyou have to really think about where you\\'re putting it. It would help with these things\\ndidn\\'t juggle and there you go, you got it done. All right, you\\'re watching? You\\'ve got to do four. To do four, again, you\\'ve got to\\nbe really careful not to cover things up as you do this. You want to get the bottom\\none eventually exposed, and so are you going to\\npull that one over there. If you do the\\npattern really well, you won\\'t notice if I make\\na serious mistake as I\\'m doing this, which I just did. But I\\'m going to\\nrecover from that and do it that way to\\nput this one over here, and that one goes there, and\\nif I did this in Harvard Square I could make money. There you go, right? OK, got the solution? See how to solve it? Could you write code for this? Eh, maybe not. That\\'s on the\\nquiz, thanks, John, don\\'t tell them\\non the quiz, damn. All right, I want to claim\\nthough that in fact there\\'s a beautiful recursive solution. And here\\'s the way to\\nthink about it recursively. I want to move a\\ntower of size n, I\\'m going to assume I\\ncan move smaller towers and then it\\'s really easy. What do I do, I take a\\nstack of size n minus 1, I move it onto the spare one,\\nI move the bottom one over, and then I move a\\nstack of size n minus 1 to there, beautiful,\\nrecursive solution. And how do I move\\nthe smaller stack? Just the same way,\\nI just unwind it, simple, and, in fact, the\\ncode follows exactly that. OK, I do a little\\n[INAUDIBLE] domain up here to try and get your\\nattention, but notice by doing that what did I do? I asked you to think\\nabout it recursively, the recursive solution,\\nwhen you see it, is in fact very straightforward,\\nand there\\'s the code. Dead trivial, well,\\nthat trivial is unfair, but it\\'s very simple. Right? I simply write something,\\nso let me describe it, I need to say how big\\nof tower am I moving and I\\'m going to label the\\nthree stacks a from, a to, and a spare. I have a little procedure\\nthat just prints out the move for me, and\\nthen what\\'s the solution? If it\\'s just a stack of size\\none, just print the move, take it to from--\\nfrom from to to. Otherwise, move a\\ntower of size n minus 1 from the from spot to\\nthe spare spot, then move what\\'s left of tower\\nsize one from to two, and then take that\\nthing are stuck on spare and move it over to\\ntwo, and I\\'m done. In that code that we handed\\nout, you\\'ll see this code, you can run it. I\\'m not going to print\\nit out because, if I did, you are just going\\nto say, OK, it looks like it does the\\nright kind of thing. Look at the code, nice\\nand easy, and that\\'s what we like you to do when\\nyou\\'re given a problem. We asked you to think\\nabout recursively. How do I solve\\nthis with a smaller version of the same problem? And then how do I use that\\nto build the larger solution? This case is a little different. You could argue that\\nthis is not really a recursive call here, it\\'s\\njust moving the bottom one, I could have done that directly. But I\\'ve got two recursive\\ncalls in the body here. I have to move a\\nsmaller stack twice. We\\'re going to come back\\nto that in a little bit. Let me show you one other\\nexample of recursion that runs a little bit differently. In this case it\\'s going to\\nhave multiple base cases and this is another\\nvery old problem, it\\'s called the\\nFibonacci numbers. It\\'s based on something\\nfrom several centuries ago when a gentleman,\\nnamed Leonardo of Pisa, also known as Fibonacci,\\nasked the following challenge. He said, I\\'m going to put\\na newborn pair of rabbits, one male and one female, into an\\nenclosure, a pan of some sort. And the rabbits have the\\nfollowing properties, they mate at age one month, so\\nthey take a month to mature. After a one month\\ngestation period, they produce another pair of\\nrabbits, a male and a female, and he says I\\'m going to assume\\nthat the rabbits never die. So each month mature females are\\ngoing to produce another pair. And his question was, how\\nmany female rabbits are there at the end of a year, or\\ntwo years, or three years? The idea is, I start off\\nwith two immature rabbits, after one month\\nthey\\'ve matured, which means after another month, they\\nwill have produced a new pair. After another month, that mature\\npair has produced another pair, and the immature\\npair has matured. Which means, after\\nanother month, those two mature pairs are\\ngoing to produce offspring, and that immature\\npair has matured. And you get the idea,\\nand after several months, you get to Australia. You can also see this is going\\nto be interesting to think about how do you compute this,\\nbut what I want you to see is the recursive solution to it. So how could we capture this? Well here\\'s another way\\nof thinking about it, after the first\\nmonth, and I know we\\'re going to do\\nthis funny thing, we\\'re going to index it\\n0, so call it month 0. There is 1 female\\nwhich is immature. After the second\\nmonth, that female is mature and now pregnant which\\nmeans after the third month it has produced an offspring. And more generally,\\nthat the n-th month, after we get past the first\\nfew cases, what do we have? Any female that was\\nthere two months ago has produced an offspring. Because it\\'s taken at\\nleast one month to mature, if it hasn\\'t\\nalready been mature, and then it\\'s going to\\nproduce an offspring. And any female that\\nwas around last month is still around because\\nthey never die off. So this is a little different. This is now the number\\nof females at month n is the number of females\\nT month n minus 1, plus the number of females\\nand month n minus 2. So two recursive calls, but\\nwith different arguments. Different from towers of Hanoi,\\nwhere there were two recursive calls, but with the\\nsame sized problem. So now I need two\\nbase cases, one for when n is equal to 0,\\none for when n is equal to 1. And then I\\'ve got\\nthat recursive case, so there\\'s a nice\\nlittle piece of code. Fibonacci, I\\'m going to assume\\nx is an integer greater than or equal to 0. I\\'m going to return\\nFibonacci of x. And you can see now it says,\\nif either x is equal to 0 or x is equal to 1\\nI\\'m going to return 1, otherwise, reduce it to two\\nsimpler versions of the problem but with different\\narguments, and I add them up. OK, and if we go look at this,\\nwe can actually run this, if I can find my code. Which is right there,\\nand I\\'m just going to, so we can, for example,\\ncheck it by saying fib of 0. I just hit a bug\\nwhich I don\\'t see. Let me try it again. I\\'ll try it one more\\ntime with fib of 0. Darn, it\\'s wrong, let me try it. I\\'ve got two different\\nversions of fib in here, that\\'s what\\nI\\'ve got going on. So let me do it again,\\nlet\\'s do fib of 1. There we go, fib of 2 which\\nis 2, fib of 3 just three, and fib of 4 which should\\nadd the previous two, which gives me 5. There we go. Sorry about that, I\\nhad two versions of fib in my file, which is\\nwhy it complained at me. And which is why\\nyou should always read the error instructions\\nbecause it tells you what you did wrong. Let\\'s go on and look at one\\nmore example of doing recursion, and we\\'re going to\\ndo dictionaries, and then we\\'re going to\\npull it all together. So far we\\'ve been doing\\nrecursion on numerical things, we can do it on\\nnon-numerical things. So a nice way of\\nthinking about this is, how would I tell if a string\\nof characters is a palindrome? Meaning it reads the same\\nbackwards and forwards. Probably the most\\nfamous palindrome is attributed to Napoleon\\n\"Able was I ere I saw Elba.\" Given that Napoleon\\nwas French, I really doubt he said \"Able\\nwas I ere I saw Elba,\" but it\\'s a great palindrome. Or another one attributed\\nto Anne Michaels \"Are we not drawn we few\\ndrawn onward to a new era,\" reads the same\\nbackwards and forwards. It\\'s fun to think about how\\ndo you create the palindromes. I want to write\\ncode to solve this. Again, I want to think\\nabout it recursively, so here\\'s what I\\'m going to do. I\\'m first going to take\\na string of characters, reduce them all to\\nlowercase, and strip out spaces and punctuation. I just want the characters. And once I got\\nthat, I want to say, is that string, that\\nlist of characters or that collection of characters\\nas I should say, a palindrome? And I\\'m going to think\\nabout it recursively, and that\\'s actually pretty easy. If it\\'s either 0 or 1\\nlong, it\\'s a palindrome. Otherwise you could think\\nabout having an index at each end of this thing\\nand sort of counting into the middle,\\nbut it\\'s much easier to say take the two at the\\nend, if they\\'re the same, then check to see what\\'s left\\nin the middle is a palindrome, and if those two properties\\nare true, I\\'m done. And notice what I just did I\\nnicely reduced a bigger problem to a slightly smaller problem. It\\'s exactly what I want to do. OK? So it says to check is\\nthis, I\\'m going to reduce it to just the string\\nof characters, and then I\\'m going to check if\\nthat\\'s a palindrome by pulling those two off and checking\\nto see they\\'re the same, and then checking to see if the\\nmiddle is itself a palindrome. How would I write it? I\\'m going to create a procedure\\nup here, isPalindrome. I\\'m going to have inside of it\\ntwo internal procedures that do the work for me. The first one is simply\\ngoing to reduce this to all lowercase with no spaces. And notice what I can do because\\ns is a string of characters. I can use the built in string\\nmethod lower, so there\\'s that dot notation, s.lower. It says. apply the\\nmethod lower to a string. I need an open and close\\nper end to actually call that procedure, and\\nthat will mutate s to just be all lowercase. And then I\\'m going\\nto run a little loop, I\\'ll set up answer or ans\\nto be an empty string, and then, for everything\\ninside that mutated string, I\\'ll simply say, if it\\'s inside\\nthis string, if it\\'s a letter, add it into answer. If it\\'s a space or comma or\\nsomething else I\\'ll ignore it, and when I\\'m done\\njust return answer, strips it down to lowercase. And then I\\'m going to pass that\\ninto isPal which simply says, if this is either\\n0 or 1 long, it\\'s a palindrome, returned true. Otherwise, check to see that\\nthe first and last element of the string are\\nthe same, notice the indexing to get\\ninto the last element, and similarly just\\nslice into the string, ignoring the first and\\nlast element, and ask is that a palindrome. And then just call it,\\nand that will do it. And again there\\'s a nice example\\nof that in the code I\\'m not going to run it, I\\'ll let\\nyou just go look at it, but it will actually pull\\nout something that checks, is this a palindrome. Notice again, what\\nI\\'m doing here. I\\'m doing divide-and-conquer. I\\'m taking a problem reducing\\nit, I keep saying this, to a simpler version\\nof the same problem. Keep unwinding it\\ntill I get down to something I can\\nsolve directly, my base case and I\\'m done. And that\\'s really\\nthe heart of thinking about recursive\\nsolutions to problems. I would hope that one of\\nthe things I remember, besides my really\\nlousy patter up here, is the idea of Towers of\\nHanoi, because to me it\\'s one of the nicest\\nexamples of a problem that would be hard to\\nsolve iteratively, but when you see the\\nrecursive solution is pretty straightforward. Keep that in mind as you\\nthink about doing recursion. OK, let\\'s switch\\ngears, and let\\'s talk very briefly about\\nanother kind of data type called a dictionary. And the idea of a\\ndictionary I\\'m going to motivate with\\na simple example. There\\'s a quiz coming\\nup on Thursday. I know you don\\'t\\nwant to hear that, but there is, which means we\\'re\\ngoing to be recording grades. And so imagine I wanted to\\nbuild a little database just to keep track of\\ngrades of students. So one of the ways\\nI could do it, I could create a list with\\nthe names of the students, I could create another\\nlist with their grades, and a third list with the\\nactual subject or course from which they got that great. I keep a separate list\\nfor each one of them, keep them of the same\\nlength, and in essence, what I\\'m doing here is\\nI\\'m storing information at the same index in each list. So Ana, who\\'s going to have to\\ntake the class again, gets a B, John, who\\'s created the class,\\ngets an A plus, Sorry Ana, John\\'s had a longer time at it. All right, bad jokes\\naside, what I\\'m doing is I can imagine\\njust creating lists. I could create lists of\\nlists, but a simple way is to do lists where\\nbasically at each index I\\'ve got associated information. It\\'s a simple way\\nto deal with it. Getting a grade out takes\\na little bit of work because if I want to\\nget the grade associated with a particular\\nstudent, what would I do? I would go into the name list\\nand use the method index, which you\\'ve seen before, again\\nnotice the dot notation it says, this is a list,\\nuse the index method, call it on student, and\\nwhatever the value of student is, it will find\\nthat in the list, return the index at\\nthat point, and then I can use that to go in and\\nget the grade in the course and return something out. Simple way to do it but\\na little ugly, right, because among other\\nthings, I\\'ve got things stored in different\\nplaces in the list. I\\'ve got to think about if\\nI\\'m going to add something to the list I\\'ve got to put them\\nin the same spot in the list. I\\'ve got to remember to\\nalways index using integers which is what we know how to\\ndo with lists, at least so far. It would be nice if I had\\na better way to do it, and that\\'s exactly\\nwhat a dictionary is going to provide for me. So rather than\\nindexing on integers I\\'d like to index directly\\non the item of interest. I\\'d like to say\\nwhere\\'s Ana\\'s record and find that in\\none data structure. And so, whereas a list\\nis indexed by integers, and has elements associated\\nwith it, a dictionary is going to combine a key, or if you\\nlike, a name of some sort, with an actual value. And we\\'re going to\\nindex just by the name or the label as we go into it. So let me show\\nyou some examples. First of all, to create a\\ndictionary I use curly braces, open closed curly brace,\\nso an empty dictionary would be simply that call. If I want to create\\nan actual dictionary, before I insert\\nthings into it, I use a little bit of\\na funky notation. It is a key or a label,\\na colon, and then a value, in this\\ncase the string Ana and the string b, followed\\nby a comma which separates it from the next pairing\\nof a key and a label, or a key and a value, and so on. So if I do this what it\\ndoes in my dictionary is it creates pairings of\\nthose labels with the values I associated with them. OK, these are pretty\\nsimple, but in fact, there\\'s lots of nice things\\nwe can do with it. So once we\\'ve got them indexing\\nnow is similar to a list but not done by a number,\\nit\\'s done by value. So if that\\'s my key, I can\\nsay, what\\'s John\\'s grade, notice the call, it\\'s grades,\\nwhich is in my dictionary, open close square brackets,\\nwith the label John. And what it does, it goes in and\\nfinds that in the dictionary, returns the value\\nassociated with it. If I ask for something\\nnot in the dictionary, it\\'s going to give\\nme a key error. Other things we can\\ndo with dictionaries, we can add entries just\\nlike we would do with lists. Grades as a dictionary, in open\\nand closed square brackets, I put in a new\\nlabel and a value, and that adds that\\nto the dictionary. I can test if something\\'s in\\nthe dictionary by simply saying, is this label in\\ngrades, and it simply checks all of the labels or\\nthe keys for the dictionary to see if it\\'s there, and\\nif it\\'s not returns false. I can remove entries, del,\\nsomething we\\'ve seen before, a very generic thing. It will delete something,\\nand in this case, it says, in the\\ndictionary grades, find the entry associated\\nwith that key, sorry, Ana, you\\'re about to be\\nflushed, remove it. She\\'s only getting a b in\\nthe class and she teaches it. We\\'ve got to do something\\nabout this, right? So I can add things,\\nI can delete things, I can test if things are there. Let me show you a\\ncouple of other things about dictionaries. I can ask for all of the\\nkeys in the dictionary. Notice the format, there is\\nthat dot notation, grades as a dictionary, it says, use\\nthe keys method associated with this data\\nstructure dictionaries. Open close actually\\ncalls it, and it gives me back a collection of all the\\nkeys in some arbitrary order. I\\'m going to use\\na funny term here which I\\'m not certain\\nwe\\'ve seen so far. It returns something we call\\nan iterable, it\\'s like range. Think of it as giving us back\\nthe equivalent of a list, it\\'s not actually\\na list, but it\\'s something we can walk down. Which is exactly why I\\ncan then say, is something in a dictionary, because it\\nreturns this set of keys, and I can test to see\\nsomething\\'s in there. I can similarly get\\nall of the values if I wanted to look at them,\\ngiving us out two iterables. Here are the key things to keep\\nin mind about dictionaries. The values can be anything,\\nany type, mutable, immutable. They could be duplicates. That\\'d actually makes sense,\\nI could have the same value associated, for example,\\nthe same grade associated with different people,\\nthat\\'s perfectly fine. The values could be lists, they\\ncould be other data structures, they could even be\\nother dictionaries. They can be anything,\\nwhich is great. The keys, the first part of it\\nare a little more structure. They need to be unique. Well duh, that make sense. If I have that same key in\\ntwo places in the dictionary, when I go to look\\nit up, how am I going to know which one I want? So it needs to be\\nunique, and they also need to be immutable,\\nwhich also makes sense. If I\\'m storing something\\nin a key in the dictionary, and I can go and change\\nthe value of the key, how am I going to remember\\nwhat I was looking for? So they can only be things like\\nints, floats, strings, tuples, Booleans. I don\\'t recommend using\\nfloats because you need to make sure it\\'s\\nexactly the same float and that\\'s sometimes a\\nlittle bit challenging, but nonetheless, you can have\\nany immutable type as your key. And notice that there\\'s no\\norder to the keys or the values. They are simply stored\\narbitrarily by the Python as it puts them in. So if I compare these two, lists\\nor ordered sequences indexed by integers, I look them\\nup by integer index, and the indices have to have\\nan order as a consequence. Dictionaries are this\\nnice generalization, arbitrarily match\\nkeys to values. I simply look up one\\nitem by looking up things under the appropriate key. All I require is that the\\nkeys have to be immutable. OK, I want to do\\ntwo last things I\\'ve got seven minutes to go here. I want to show you an example\\nof using dictionaries, and I\\'m going to do this\\nwith a little bit more interesting, I hope, example. I want to analyze song lyrics. Now I\\'m going to show\\nyou, you can already tell the difference between\\nmy age and Ana\\'s age. She used Taylor Swift\\nand Justin Bieber. I\\'m going to use The Beatles. That\\'s more my generation. Most of you have never\\nheard of The Beatles unless you watched\\nShining Time Station where you saw Ringo Starr, right? OK, what I\\'m going\\nto do is, I want to write a little\\nset of procedures that record the frequencies\\nof words in a song lyric. So I\\'m going to match strings,\\nor words, to integers. How many times did that word\\nappear in the song lyric? And then I want to ask,\\ncan I easily figure out which words occur most\\noften, and how many times. Then I\\'m going to\\ngather them together to see what are the most\\ncommon words in here. And I\\'m going to do that where\\nI\\'m going to let a user say, I want every word that appears\\nmore than some number of times. It\\'s a simple\\nexample, but I want you to see how a mutation\\nof the dictionary gives you a really powerful\\ntool for solving this problem. So let\\'s write the\\ncode to do that. It\\'s also in the\\nhandout, here we go. Lyrics to frequency\\'s, lyrics is\\njust a list of words, strings. So I\\'m going to set up\\nan empty dictionary, there\\'s that open\\nclose curly brace, and here\\'s what I want to do. I\\'m going to walk through\\nall the words in lyrics. You\\'ve seen this\\nbefore, this is looping over every word in lyrics. Ah, notice what I\\'m going to do. I\\'m going to simply say-- so\\nthe first part is, I can easily iterate over the list,\\n--but now I\\'m going to say, if the word is in\\nthe dictionary, and because the\\ndictionary is iterable, it\\'s simply going to give\\nme back all of the keys, it\\'s simply going to\\nsay, in this case, if it\\'s in the dictionary,\\nit\\'s already there, I\\'ve got some value\\nassociated with it, get the value out, add\\n1 to it, put it back in. If it\\'s not already\\nin the dictionary, this is the first time\\nI\\'ve seen it, just store it into the dictionary. And when I\\'m done just\\nreturn the dictionary. OK? So I\\'m going to, if I can do\\nthis right with my Python, show you an example of this. I have put in one of the\\ngreat classic Beatles songs, you might recognize\\nit right there. Mostly because it\\'s got a whole\\nlot of repetitions of things. So she loves you yeah,\\nyeah, yeah, yeah. Sorry, actually they sing\\nit better than I just did it sarcastically. Sorry about that, but I\\ngot she loves you there, and here\\'s my code up\\nhere, lyrics to frequency. So let\\'s see what\\nhappens if we call it. And we say lyrics to\\nfrequencies she loves you. And it would help\\nif I can type, all right, we\\'ll try it\\none more time, lyrics to frequency\\'s, she loves you. Cool, this gave me\\nback a dictionary, you can see the curly\\nbraces, and there are all the words that appear\\nin there and the number of times that they appear. What\\'s the order? You don\\'t care. You don\\'t know. What we want to do\\nis to think about how can we analyze\\nthis, so let\\'s go back and look at the\\nlast piece of this. Which is, OK, I can convert\\nlyrics to frequencies. So here\\'s the next thing\\nI want to do, how do I find the most common words? Well, here\\'s what\\nI\\'m going to do, frequencies is the\\ndictionary, something that I just pulled out. So I can use the\\nvalues method on it which returns and iterable,\\nas I said earlier, again notice the open close\\nbecause I got to call it. That gives me back\\nan iterable that has all of the frequencies\\ninside of there, because it\\'s an iterable,\\nI can use max on it, and it will take that\\neditable and give me back the biggest value. I\\'m going to call that\\nbest, I\\'m going to set up words to be an empty\\nlist, and then I\\'m just going to walk\\nthrough all of the entries in the dictionary saying,\\nif the value at that entry is equal to best add\\nthat entry into words, just append it onto\\nthe end of the list. And when I\\'m done\\nall of that loop, I\\'m just going to return a\\ntuple of both the collections of words that period\\nthat many times and how often they appeared. I\\'m going to show you\\nan example in a second, but notice I\\'m simply using the\\nproperties of the dictionary. The last thing I want\\nto do then is say, I want to see how\\noften the words appear. So I\\'m going to give it a\\ndictionary and a minimum number of times. And here I\\'m going to set\\nresult up to be an empty list, I\\'m going to create\\na flag called false, it\\'s going to keep\\ntrack of when I\\'m done. And as long as I\\'m\\nnot yet done, I\\'ll call that previous\\nprocedure that\\'s going to give me back\\nthe most common words and how often they appeared. I check and remember\\nit was a tuple, how often do they appear, if\\nit\\'s bigger than the thing I\\'m looking for, I\\'ll\\nadd that into my result. And then the best\\npart is, I\\'m now going to walk\\nthrough all the words that appeared that many\\ntimes, and just delete them from the dictionary. I can mutate the dictionary. And by doing that, I can go\\nback around and do this again, and it will pull out how\\nmany times has this appeared and keep doing it. When I can go all\\nthe way through that, if I can\\'t find any\\nmore, I\\'ll set the flag to true which means it\\nwill drop out of here and return the result. I\\'m going\\nto let you run this yourself, if you do that, you\\'ll\\nfind that it comes up with, not surprisingly, I think\\nyeah is the most common one and she loves you, followed\\nby loves and a few others. What I want you to see here\\nis how the dictionary captured the pieces we wanted to. Very last one,\\nthere\\'s Fibonacci, as we called it before. It\\'s actually\\nincredibly inefficient, because if I call it, I\\nhave to do all the sub calls until I get down to\\nthe base case, which is OK. But notice, every\\nother thing I do here, I\\'ve actually\\ncomputed those values. I\\'m wasting measures,\\nor wasting time, it\\'s not so bad with fib of\\n5, but if this is fib of 20, almost everything on the\\nright hand side of this tree I\\'ve already computed once. That means fibs\\nvery inefficient. I can improve it by using a\\ndictionary, very handy tool. I\\'m going to call fib not\\nonly with a value of n, but a dictionary\\nwhich initially I\\'m going to initialized\\nto the base cases. And notice what I do, I\\'m\\ngoing to say if I\\'ve already computed this, just return\\nthe value in the dictionary. If I haven\\'t, go ahead\\nand do the computation, store it in the\\ndictionary at that point, and return the answer. Different way of\\nthinking about it, and the reason this is really\\nnice is a method called memoization, is if\\nI call fib of 34 the standard way it takes 11\\nmillion plus recursive calls to get the answer out. It takes a long time. I\\'ve given you some\\ncode for it, you can try it and see\\nhow long it takes. Using the dictionary to keep\\ntrack of intermediate values, 65 calls. And if you try it, you\\'ll\\nsee the difference in speed as you run this. So dictionaries\\nare valuable, not only for just storing\\naway data, they\\'re valuable on procedure calls when\\nthose intermediate values are not going to change. What you\\'re going to\\nsee as we go along is we\\'re going to use exactly\\nthese ideas, using dictionaries to capture information, but\\nespecially using recursion to break bigger problems\\ndown into smaller versions of the same problem,\\nto use that as a tool for solving what turn out\\nto be really complex things. And with that, we\\'ll\\nsee you next time.',\n",
       " 'The following\\ncontent is provided under a Creative\\nCommons license. Your support will help MIT\\nOpenCourseWare continue to offer high quality\\neducational resources for free. To make a donation or\\nview additional materials from hundreds of MIT courses,\\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Hey, everybody. You ready to learn\\nsome algorithms? Yeah! Let\\'s do it. I\\'m Eric Domain. You can call me Eric. And the last class, we\\nsort of jumped into things. We studied peak\\nfinding and looked at a bunch of algorithms\\nfor peak finding on your problem set. You\\'ve already\\nseen a bunch more. And in this class, we\\'re going\\nto do some more algorithms. Don\\'t worry. That will be at the end. We\\'re going to talk about\\nanother problem, document distance, which will be a\\nrunning example for a bunch of topics that we\\ncover in this class. But before we go there, I wanted\\nto take a step back and talk about, what actually\\nis an algorithm? What is an algorithm\\nallowed to do? And also deep philosophical\\nquestions like, what is time? What is the running\\ntime of an algorithm? How do we measure it? And what are the rules the game? For fun, I thought I\\nwould first mention where the word comes\\nfrom, the word algorithm. It comes from this guy,\\na little hard to spell. Al-Khwarizmi, who is sort\\nof the father of algebra. He wrote this book called \"The\\nCompendious Book on Calculation by Completion and\\nBalancing\" back in the day. And it was in\\nparticular about how to solve linear and\\nquadratic equations. So the beginning of algebra. I don\\'t think he invented\\nthose techniques. But he was sort of\\nthe textbook writer who wrote sort of how\\npeople solved them. And you can think\\nof how to solve those equations as\\nearly algorithms. First, you take this number. You multiply by this. You add it or you reduce\\nto squares, whatever. So that\\'s where the word\\nalgebra comes from and also where the word\\nalgorithm comes from. There aren\\'t very many\\nwords with these roots. So there you go. Some fun history. What\\'s an algorithm? I\\'ll start with sort of\\nsome informal definitions and then the point\\nof this lecture. And the idea of a\\nmodel of computation is to formally specify\\nwhat an algorithm is. I don\\'t want to get super\\ntechnical and formal here, but I want to give\\nyou some grounding so when we write Python code,\\nwhen we write pseudocode, we have some idea what\\nthings actually cost. This is a new lecture. We\\'ve never done\\nthis before in 006. But I think it\\'s important. So at a high level,\\nyou can think of an algorithm is just\\na-- I\\'m sure you\\'ve seen the definition before. It\\'s a way to define computation\\nor computational procedure for solving some problem. So whereas computer\\ncode, I mean, it could just be running\\nin the background all the time doing whatever. An algorithm we think\\nof as having some input and generating some output. Usually, it\\'s to\\nsolve some problem. You want to know is this\\nnumber prime, whatever. Question? AUDIENCE: Can you turn up\\nthe volume for your mic? PROFESSOR: This microphone does\\nnot feed into the AV system. So I shall just talk louder, OK? And quiet the set, please. OK, so that\\'s an algorithm. You take some input. You run it through. You compute some output. Of course, computer\\ncode can do this too. An algorithm is basically\\nthe mathematical analog of a computer program. So if you want to reason about\\nwhat computer programs do, you translate it into\\nthe world algorithms. And vice versa, you want to\\nsolve some problem-- first, you usually develop an\\nalgorithm using mathematics, using this class. And then you convert\\nit into computer code. And this class is about\\nthat transition from one to the other. You can draw a picture\\nof sort of analogs. So an algorithm is a\\nmathematical analog of a computer program. A computer program is built on\\ntop of a programming language. And it\\'s written in a\\nprogramming language. The mathematical analog\\nof a programming language, what we write algorithms\\nin, usually we write them in pseudocode,\\nwhich is basically another fancy word for\\nstructured English, good English, whatever\\nyou want to say. Of course, you could use\\nanother natural language. But the idea is, you need to\\nexpress that algorithm in a way that people can understand\\nand reason about formally. So that\\'s the structured part. Pseudocode means lots\\nof different things. It\\'s just sort of an abstract\\nhow you would write down formal specification\\nwithout necessarily being able to actually run\\nit on a computer. Though there\\'s a particular\\npseudocode in your textbook which you probably\\ncould run on a computer. A lot of it, anyway. But you don\\'t have\\nto use that version. It just makes sense to humans\\nwho do the mathematics. OK, and then ultimately, this\\nprogram runs on a computer. You all have computers,\\nprobably in your pockets. There\\'s an analog of a computer\\nin the mathematical world. And that is the\\nmodel of computation. And that\\'s sort of the focus of\\nthe first part of this lecture. Model of computation says what\\nyour computer is allowed to do, what it can do in\\nconstant time, basically? And that\\'s what I want\\nto talk about here. So the model of computation\\nspecifies basically what operations you\\ncan do in an algorithm and how much they cost. This is the what is time. So for each\\noperation, we\\'re going to specify how\\nmuch time it costs. Then the algorithm does\\na bunch of operations. They\\'re combined together\\nwith control flow, for loops, if statements,\\nstuff like that which we\\'re not going to worry about too much. But obviously, we\\'ll\\nuse them a lot. And what we count is how much\\ndo each of the operations cost. You add them up. That is the total cost\\nof your algorithm. So in particular, we\\ncare mostly in this class about running time. Each operation has a time cost. You add those up. That\\'s running time\\nof the algorithm. OK, so let\\'s-- I\\'m going to\\ncover two models of computation which you can just think of\\nas different ways of thinking. You\\'ve probably seen\\nthem in some sense as-- what you call them? Styles of programming. Object oriented style of\\nprogramming, more assembly style of programming. There\\'s lots of different\\nstyles of programming languages which I\\'m not going\\nto talk about here. But you\\'ve see analogs if\\nyou\\'ve seen those before. And these models\\nreally give you a way of structuring your\\nthinking about how you write an algorithm. So they are the random access\\nmachine and the pointer machine. So we\\'ll start with random\\naccess machine, also known as the RAM. Can someone tell me what\\nelse RAM stands for? AUDIENCE: Random Access Memory? PROFESSOR: Random Access Memory. So this is both confusing\\nbut also convenience. Because RAM simultaneously\\nstands for two things and they mean almost the\\nsame thing, but not quite. So I guess that\\'s more\\nconfusing than useful. But there you go. So we have random access memory. Oh, look at that. Fits perfectly. And so we\\'re thinking,\\nthis is a real-- this is-- random access memory\\nis over here in real computer land. That\\'s like, D-RAM\\nSD-RAM, whatever-- the things you buy and stick\\ninto your motherboard, your GP, or whatever. And over here, the mathematical\\nanalog of-- so here\\'s, it\\'s a RAM. Here, it\\'s also a RAM. Here, it\\'s a random\\naccess machine. Here, it\\'s a random\\naccess memory. It\\'s technical detail. But the idea is, if you look\\nat RAM that\\'s in your computer, it\\'s basically a\\ngiant array, right? You can go from zero\\nto, I don\\'t know. A typical chip these days is\\nlike four gigs in one thing. So you can go from\\nzero to four gigs. You can access anything in the\\nmiddle there in constant time. To access something, you\\nneed to know where it is. That\\'s random access memory. So that\\'s an array. So I\\'ll just draw a big picture. Here\\'s an array. Now, RAM is usually\\norganized by words. So these are a\\nmachine word, which we\\'re going to\\nput in this model. And then there\\'s address zero,\\naddress one, address two. This is the fifth word. And just keeps going. You can think of\\nthis as infinite. Or the amount that\\nyou use, that\\'s the space of your algorithm, if\\nyou care about storage space. So that\\'s basically it. OK, now how do we-- this is\\nthe memory side of things. How do we actually\\ncompute with it? It\\'s very simple. We just say, in constant time,\\nan algorithm can basically read in or load a constant\\nnumber of words from memory, do a constant number of\\ncomputations on them, and then write them out. It\\'s usually called store. OK, it needs to know\\nwhere these words are. It accesses them by address. And so I guess I\\nshould write here you have a constant number of\\nregisters just hanging around. So you load some\\nwords into registers. You can do some computations\\non those registers. And then you can\\nwrite them back, storing them in\\nlocations that are specified by your registers. So you\\'ve ever done\\nassembly programming, this is what assembly\\nprogramming is like. And it can be rather annoying to\\nwrite algorithms in this model. But in some sense,\\nit is reality. This is how we think\\nabout computers. If you ignore\\nthings like caches, this is an accurate\\nmodel of computation that loading,\\ncomputing, and storing all take roughly the\\nsame amount of time. They all take constant time. You can manipulate a\\nwhole word at a time. Now, what exactly is a word? You know, computers these days,\\nit\\'s like 32 bits or 64 bits. But we like to be a\\nlittle bit more abstract. A word is w bits. It\\'s slightly annoying. And most of this class, we won\\'t\\nreally worry about what w is. We\\'ll assume that\\nwe\\'re given as input a bunch of things\\nwhich are words. So for example, peak finding. We\\'re given a matrix of numbers. We didn\\'t really say whether\\nthey\\'re integers or floats or what. We don\\'t worry about that. We just think of\\nthem as words and we assume that we can\\nmanipulate those words. In particular, given two\\nnumbers, we can compare them. Which is bigger? And so we can determine,\\nis this cell in the matrix a peak by comparing it with\\nits neighbors in constant time. We didn\\'t say why it was\\nconstant time to do that. But now you kind of know. If those things are\\nall words and you can manipulate a constant number\\nof words in constant time, you can tell whether a number\\nis a peak in constant time. Some things like w should be at\\nleast log the size of memory. Because my word should\\nbe able to specify an index into this array. And we might use that someday. But basically, don\\'t\\nworry about it. Words are words. Words come in as inputs. You can manipulate\\nthem and you don\\'t have to worry about\\nit for the most part. In unit four of\\nthis class, we\\'re going to talk about, what if we\\nhave really giant integers that don\\'t fit in a word? How do we manipulate them? How do we add them,\\nmultiply them? So that\\'s another topic. But most of this\\nclass, we\\'ll just assume everything we\\'re\\ngiven is one word. And it\\'s easy to compute on. So this is a realistic\\nmodel, more or less. And it\\'s a powerful one. But a lot of the\\ntime, a lot of code just doesn\\'t use\\narrays-- doesn\\'t need it. Sometimes we need arrays,\\nsometimes we don\\'t. Sometimes you feel like a\\nnut, sometimes you don\\'t. So it\\'s useful to think about\\nsomewhat more abstract models that are not quite as\\npowerful but offer a simpler way of thinking about things. For example, in\\nthis model there\\'s no dynamic memory allocation. You probably know you could\\nimplement dynamic memory allocation because\\nreal computers do it. But it\\'s nice to\\nthink about a model where that\\'s taken\\ncare of for you. It\\'s kind of like a higher\\nlevel programming abstraction. So the one is useful in this\\nclass is the pointer machine. This basically corresponds to\\nobject oriented programming in a simple, very\\nsimple version. So we have dynamically\\nallocated objects. And an object has a\\nconstant number of fields. And a field is going to\\nbe either a word-- so you can think of this\\nas, for example, storing an integer, one\\nof the input objects or something you computed on it\\nor a counter, all these sorts of things-- or a pointer. And that\\'s where pointer\\nmachine gets its name. A pointer is something that\\npoints to another object or has a special value\\nnull, also known as nil, also known as none in Python. OK, how many people have\\nheard about pointers before? Who hasn\\'t? Willing to admit it? OK, only a few. That\\'s good. You should have seen pointers. You may have heard\\nthem called references. Modern languages these days\\ndon\\'t call them pointers because pointers are scary. But there\\'s a very subtle\\ndifference between them. And this model actually\\nreally is references. But for whatever reason, it\\'s\\ncalled a pointer machine. It doesn\\'t matter. The point is, you\\'ve\\nseem linked lists I hope. And linked lists have a\\nbunch of fields in each node. Maybe you\\'ve got a pointer\\nto the previous element, a pointer to the next\\nelement, and some value. So here\\'s a very\\nsimple linked list. This is what you\\'d call a\\ndoubly linked list because it has previous and next pointers. So the next pointer\\npoints to this node. The previous pointer\\npoints to this node. Next pointer points to null. The previous pointer\\npoints to null, let\\'s say. So that\\'s a two node\\ndoubly linked list. You presume we have a pointer\\nto the head of the list, maybe a pointer to the\\ntail of list, whatever. So this is a structure\\nin the pointer machine. It\\'s a data structure. In Python, you might\\ncall this a named tuple, or it\\'s just an object\\nwith three attributes, I guess, they\\'re\\ncalled in Python. So here we have the value. That\\'s a word like an integer. And then some things\\ncan be pointers that point to other nodes. And you can create a new node. You can destroy a node. That\\'s the dynamic\\nmemory allocation. In this model, yeah,\\npointers are pointers. You can\\'t touch them. Now, you can implement this\\nmodel in a random access machine. A pointer becomes an index\\ninto this giant table. And that\\'s more like\\nthe pointers in C if you\\'ve ever\\nwritten C programs. Because then you\\ncan take a pointer and you can add one to it and\\ngo to the next thing after that. In this model, you can\\njust follow a pointer. That\\'s all you can do. OK, following a pointer\\ncosts constant time. Changing one of these\\nfields costs constant time. All the usual things you might\\nimagine doing to these objects take constant time. So it\\'s actually a weaker\\nmodel than this one. Because you could\\nimplement a pointer machine with a random access machine. But it offers a different\\nway of thinking. A lot of data structures\\nare built this way. Cool. So that\\'s the theory side. What I\\'d like to talk about\\nnext is actually in Python, what\\'s a reasonable\\nmodel of what\\'s going on? So these are old models. This goes back to the \\'80s. This one probably \\'80s or \\'70s. So they\\'ve been\\naround a long time. People have used them forever. Python is obviously much\\nmore recent, at least modern versions of Python. And it\\'s the model of\\ncomputation in some sense that we use in this class. Because we\\'re implementing\\neverything in Python. And Python offers both a random\\naccess machine perspective because it has arrays, and\\nit offers a pointer machine perspective because\\nit has references, because it has pointers. So you can do either one. But it also has a\\nlot of operations. It doesn\\'t just have load\\nand store and follow pointer. It\\'s got things\\nlike sort and append and concatenation of two\\nlists and lots of things. And each of those has a\\ncost associated with them. So whereas the random access\\nmachine and pointer machine, they\\'re theoretical models. They\\'re designed\\nto be super simple. So it\\'s clear that everything\\nyou do takes constant time. In Python, some of the\\noperations you can do take a lot of time. Some of the operations in Python\\ntake exponential time to do. And you\\'ve got to know when\\nyou\\'re writing your algorithms down either thinking in a Python\\nmodel or your implementing your algorithms\\nin actual Python, which operations are\\nfast and which are slow. And that\\'s what I\\'d like to\\nspend the next few minutes on. There\\'s a lot of operations. I\\'m not going to\\ncover all of them. But we\\'ll cover\\nmore in recitation. And there\\'s a whole\\nbunch in my notes. I won\\'t get to all of them. So in Python, you can do\\nrandom access style things. In Python, arrays\\nare called lists, which is super confusing. But there you go. A list in Python is an\\narray in real world. It\\'s a super cool\\narray, of course? And you can think\\nof it as a list. But in terms implementation,\\nit\\'s implemented as an array. Question? AUDIENCE: I thought\\nthat [INAUDIBLE]. PROFESSOR: You thought Python\\nlinks lists were linked lists. That\\'s why it\\'s so confusing. In fact, they are not. In, say, scheme, back in the\\ndays when we taught scheme, lists are linked lists. And it\\'s very different. So when you do-- I\\'ll\\ngive an operation here. You have a list L, and you\\ndo something like this. L is a list object. This takes constant time. In a linked list, it\\nwould take linear time. Because we\\'ve got a scan to\\nposition I, scan to position J, add 5, and store. But conveniently in Python,\\nthis takes constant time. And that\\'s important to know. I know that the terminology\\nis super confusing. But blame the benevolent\\ndictator for life. On the other hand, you can do\\nstyle two, pointer machine, using object oriented\\nprogramming, obviously. I\\'ll just mention\\nthat I\\'m not really worrying about methods here. Because methods are just sort of\\na way of thinking about things, not super important\\nfrom a cost standpoint. If your object has a constant\\nnumber of attributes-- it can\\'t have like\\na million attributes or can\\'t have n\\nexecutes-- then it fits into this\\npointer machine model. So if you have an\\nobject that only has like three things or\\n10 things or whatever, that\\'s a pointer machine. You can think of\\nmanipulating that object as taking constant time. If you are screwing around\\nthe object\\'s dictionary and doing lots of\\ncrazy things, then you have to be careful about\\nwhether this remains true. But as long as you only\\nhave a reasonable number of attributes, this\\nis all fair game. And so if you do something like,\\nif you\\'re implementing a linked list, Python I\\nchecked still does not have built-in linked lists. They\\'re pretty easy\\nto build, though. You have a pointer. And you just say\\nx equals x.next. That takes constant time\\nbecause accessing this field in an object of constant\\nsize takes constant time. And we don\\'t care what\\nthese constants are. That\\'s the beauty of algorithms. Because we only care\\nabout scalability with n. There\\'s no n here. This takes constant time. This takes constant time. No matter how big\\nyour linked list is or no matter how\\nmany objects you have, these are constant time. OK, let\\'s do some\\nharder ones, though. In general, the\\nidea is, if you take an operation like L.append--\\nso you have a list. And you want to append\\nsome item to the list. It\\'s an array, though. So think about it. The way to figure out\\nhow much does this cost is to think about\\nhow it\\'s implemented in terms of these\\nbasic operations. So these are your sort of\\nthe core concept time things. Most everything can be reduced\\nto thinking about this. But sometimes,\\nit\\'s less obvious. L.apend is a little\\ntricky to think about. Because basically, you\\nhave an array of some size. And now you want to make\\nan array one larger. And the obvious way to do that\\nis to allocate a new array and copy all the elements. That would take linear time. Python doesn\\'t do that. What does it do? Stay tuned for lecture eight. It does something\\ncalled table doubling. It\\'s a very simple idea. You can almost get\\nguess it from the title. And if you go to lecture--\\nis it eight or nine? Nine, sorry. You\\'ll see how\\nthis can basically be done in constant time. There\\'s a slight catch,\\nbut basically, think of it as a constant time operation. Once we have that,\\nand so this is why you should take\\nthis class so you\\'ll understand how Python works. This is using an algorithmic\\nconcept that was invented, I don\\'t know, decades\\nago, but is a simple thing that we need to do to solve\\nlots of other problems. So it\\'s cool. There\\'s a lot of features in\\nPython that use algorithms. And that\\'s kind of\\nwhy I\\'m telling you. All right, so let\\'s\\ndo another one. A little easier. What if I want to\\nconcatenate two lists? You should know in Python this\\nis a non-destructive operation. You basically take a copy of\\nL1 and L2 and concatenate them. Of course, they\\'re arrays. The way to think about\\nthis is to re-implement it as Python code. This is the same\\nthing as saying, well, L is initially empty. And then for every item\\nx and L1, L.append(x). And a lot of the times in\\ndocumentation for Python, you see this sort of here\\'s\\nwhat it means, especially in the fancier features. They give sort of an equivalent\\nsimple Python, if you will. This doesn\\'t use\\nany fancy operations that we haven\\'t seen already. So now we know this\\ntakes constant time. The append, this append,\\ntakes constant time. And so the amount of\\ntime here is basically order the length of L1. And the time here is\\norder the length of L2. And so in total,\\nit\\'s order-- I\\'m going to be careful and\\nsay 1 plus length of L1 plus length of L2. The 1 plus is just in\\ncase these are both 0. It still takes constant time\\nto build an initial list. OK, so there are a\\nbunch of operations that are written in these notes. I\\'m not going to go\\nthrough all of them because they\\'re tedious. But a lot of you, could just\\nexpand out code like this. And it\\'s very easy to analyze. Whereas you just\\nlook at plus, you think, oh, plus\\nis constant time. And plus is constant\\ntime if this is a word and this is a word. But these are entire\\ndata structures. And so it\\'s not constant time. All right. There are more subtle\\nfun ones to think about. Like, if I want to know is x in\\nthe list, how does that happen? Any guesses? There\\'s an operator\\nin Python called in-- x in L. How long\\ndo you think this takes? Altogether? Linear, yeah. Linear time. In the worst case,\\nyou\\'re going to have to scan through the whole list. Lists aren\\'t necessarily sorted. We don\\'t know\\nanything about them. So you\\'ve got to just\\nscan through and test for every item. Is x equal to that item? And it\\'s even worse if\\nequal equals costs a lot. So if x is some really\\ncomplicated thing, you have to take\\nthat into account. OK, blah, blah, blah. OK, another fun one. This is like a pop quiz. How long\\'s it take to\\ncompute the length of a list? Constant. Yeah, luckily, if you\\ndidn\\'t know anything, you\\'d have to scan through\\nthe list and count the items. But in Python, lists\\nare implemented with a counter built in. It always stores the\\nlist at the beginning-- stores the length of the\\nlist at the beginning. So you just look it up. This is instantaneous. It\\'s important, though. That can matter. All right. Let\\'s do some more. What if I want to sort a list? How long does that take? N log n where n is the\\nlength of the list. Technically times the time\\nto compare two items, which usually we\\'re just\\nsorting words. And so this is constant time. If you look at Python\\nsorting algorithm, it uses a comparison sort. This is the topic of lectures\\nthree and four and seven. But in particular,\\nthe very next lecture, we will see how this is\\ndone in n log n time. And that is using algorithms. All right, let\\'s\\ngo to dictionaries. Python called dicts. And these let you do things. They\\'re a generalization\\nof lists in some sense. Instead of putting just an\\nindex here, an integer between 0 and the length minus 1, you\\ncan put an arbitrary key and store a value, for example. How long does this take? I\\'m not going to ask you\\nbecause, it\\'s not obvious. In fact, this is one of the\\nmost important data structures in all of computer science. It\\'s called a hash table. And it is the topic of\\nlectures eight through 10. So stay tuned for how to\\ndo this in constant time, how to be able to\\nstore an arbitrary key, get it back out\\nin constant time. This is assuming the\\nkey is a single word. Yeah. AUDIENCE: Does it first check to\\nsee whether the key is already in the dictionary? PROFESSOR: Yeah, it will\\nclobber any existing key. There\\'s also, you\\nknow, you can test whether a key is\\nin the dictionary. That also takes constant time. You can delete something\\nfrom the dictionary. All the usual-- dealing with\\na single key in dictionaries, obviously dictionary.update,\\nthat involves a lot of keys. That doesn\\'t take some time. How long does it take? Well, you write out a\\nfor loop and count them. AUDIENCE: But how can you\\nsee whether [INAUDIBLE] dictionary in constant time? PROFESSOR: How do you do\\nthis in constant time? Come to lecture\\neight through 10. I should say a\\nslight catch, which is this is constant time\\nwith high probability. It\\'s a randomized algorithm. It doesn\\'t always\\ntake constant time. It\\'s always correct. But sometimes, very rarely,\\nit takes a little more than constant time. And I\\'m going to\\nabbreviate this WHP. And we\\'ll see more what\\nthat means mostly, actually, in 6046. But we\\'ll see a fair amount\\nin 6006 on how this works and how it\\'s possible. It\\'s a big area of research. A lot of people work on hashing. It\\'s very cool and\\nit\\'s super useful. If you write any code these\\ndays, you use a dictionary. It\\'s the way to solve problems. I\\'m basically using\\nPython is a platform to advertise the rest of the\\nclass you may have noticed. Not every topic we cover in\\nthis class is already in Python, but a lot of them are. So we\\'ve got table doubling. We\\'ve got dictionaries. We\\'ve got sorting. Another one is longs, which\\nare long integers in Python through version two. And this is the\\ntopic of lecture 11. And so for fun, if I have\\ntwo integers x and y, and let\\'s say one of them\\nis this many words long and the other one is\\nthis many words long, how long do you think\\nit takes to add them? Guesses? AUDIENCE: [INAUDIBLE]. PROFESSOR: Plus? Times? Plus is the answer. You can do it in that much time. If you think about the\\ngrade school algorithm for adding really big\\nmulti-digit numbers, it\\'ll only take that much time. Multiplication is a\\nlittle bit harder, though. If you look at the\\ngrade school algorithm, it\\'s going to be x times y--\\nit\\'s quadratic time not so good. The algorithm that\\'s\\nimplemented in Python is x plus y to the\\nlog base 2 of 3. By the way, I always write\\nLG to mean log base 2. Because it only has two\\nletters, so OK, this is 2. Log base 2 of 3 is about 1.6. So while the straightforward\\nalgorithm is basically x plus y squared, this one\\nis x plus y to the 1.6 power, a little better than quadratic. And the Python developers\\nfound that was faster than grade school\\nmultiplication. And so that\\'s what\\nthey implemented. And that is something we\\nwill cover in lecture 11, how to do that. It\\'s pretty cool. There are faster\\nalgorithms, but this is one that works\\nquite practically. One more. Heap queue, this is in the\\nPython standard library and implements something\\ncalled the heap, which will be in lecture four. So, coming soon to a\\nclassroom near you. All right, enough advertisement. That gives you some idea of\\nthe model of computation. There\\'s a whole bunch more in\\nthese notes which are online. Go check them out. And some of them, we\\'ll\\ncover in recitation tomorrow. I\\'d like to-- now that we are\\nsort of comfortable for what costs what in Python, I\\nwant to do a real example. So last time, we\\ndid peak finding. We\\'re going to have\\nanother example which is called document distance. So let\\'s do that. Any questions before we go on? All right. So document distance problem\\nis, I give you two documents. I\\'ll call them D1 D2. And I want to compute the\\ndistance between them. And the first question\\nis, what does that mean? What is this distance function? Let me first tell\\nyou some motivations for computing document distance. Let\\'s say you\\'re\\nGoogle and you\\'re cataloging the entire web. You\\'d like to know when two web\\npages are basically identical. Because then you store less\\nand because you present it differently to the user. You say, well,\\nthere\\'s this page. And there\\'s lots\\nof extra copies. But you just need--\\nhere\\'s the canonical one. Or you\\'re Wikipedia. And I don\\'t know if you\\'ve\\never looked at Wikipedia. There\\'s a list of all\\nmirrors of Wikipedia. There\\'s like millions of them. And they find them by hand. But you could do that\\nusing document distance. Say, are these\\nbasically identical other than like some\\nstuff at the-- junk at the beginning or the end? Or if you\\'re teaching this\\nclass and you want to detect, are two problem sets cheating? Are they identical? We do this a lot. I\\'m not going to tell you\\nwhat distance function we use. Because that would\\ndefeat the point. It\\'s not the one\\nwe cover in class. But we use automated tests\\nfor whether you\\'re cheating. I\\'ve got some more. Web search. Let\\'s say you\\'re Google again. And you want to\\nimplement searching. Like, I give you three words. I\\'m searching for\\nintroduction to algorithms. You can think of\\nintroduction to algorithms as a very short document. And you want to test\\nwhether that document is similar to all the other\\ndocuments on the web. And the one that\\'s most\\nsimilar, the one that has the small\\ndistance, that\\'s maybe what you want to put at the top. That\\'s obviously not\\nwhat Google does. But it\\'s part of what it does. So that\\'s why you might care. It\\'s partly also\\njust a toy problem. It lets us illustrate\\na lot of the techniques that we develop in this class. All right, I\\'m going\\nto think of a document as a sequence of words. Just to be a little\\nbit more formal, what do I mean by document? And a word is just\\ngoing to be a string of alphanumeric\\ncharacters-- A through Z and zero through nine. OK, so if I have a\\ndocument which you also think of as a string\\nand you basically delete all the white space and\\npunctuation all the other junk that\\'s in there. This Everything in between\\nthose, those are the words. That\\'s a simple definition\\nof decomposing documents into words. And now we can think\\nof about what-- I want to know whether\\nD1 and D2 are similar. And I\\'ve thought\\nabout my document as a collection of words. Maybe they\\'re similar if they\\nshare a lot of words in common. So that\\'s the idea. Look at shared words\\nand use that to define document distance. This is obviously only one\\nway to define distance. It\\'ll be the way we\\ndo it in this class. But there are lots of\\nother possibilities. So I\\'m going to\\nthink of a document. It\\'s a sequence of words. But I could also think\\nof it as a vector. So if I have a document D and\\nI have a word W, this D of W is going to be the\\nnumber of times that word occurs\\nin the document. So, number of recurrences\\nW in the document D. So it\\'s a number. It\\'s an integer. Non-negative integer. Could be 0. Could be one. Could be a million. I think of this\\nas a giant vector. A vector is indexed\\nby all words. And for each of them,\\nthere\\'s some frequency. Of lot of them are zero. And then some of them have some\\npositive number occurrences. You could think\\nof every document is as being one of these\\nplots in this common axis. There\\'s infinitely\\nmany words down here. So it\\'s kind of a big axis. But it\\'s one way to\\ndraw the picture. OK, so for example, take two\\nvery important documents. Everybody likes cats and dogs. So these are two word documents. And so we can draw them. Because there\\'s only three\\ndifferent words here, we can draw them in\\nthree dimensional space. Beyond that, it\\'s a\\nlittle hard to draw. So we have, let\\'s say,\\nwhich one\\'s the-- let\\'s say this one\\'s the-- makes\\nit easier to draw. So there\\'s going to be\\njust zero here and one. For each of the axes, let\\'s say\\nthis is dog and this is cat. OK, so the cat has won the--\\nit has one cat and no dog. So it\\'s here. It\\'s a vector\\npointing out there. The dog you\\'ve got\\nbasically pointing there. OK, so these are two vectors. So how do I measure how\\ndifferent two vectors are? Any suggestions from\\nvector calculus? AUDIENCE: Inner product? PROFESSOR: Inner product? Yeah, that\\'s good suggestion. Any others. OK, we\\'ll go with inner product. I like inner product,\\nalso known as dot product. Just define that quickly. So we could-- I\\'m going\\nto call this D prime because it\\'s not what\\nwe\\'re going to end up with. We could think of this as\\nthe dot product of D1 and D2, also known as the sum over all\\nwords of D1 of W times D2 of W. So for example, you take the\\ndot product of these two guys. Those match. So you get one point there,\\ncat and dog multiplied by zero. So you don\\'t get much there. So this is some\\nmeasure of distance. But it\\'s a measure of,\\nactually, of commonality. So it would be sort of\\ninverse distance, sorry. If you have a high\\ndot product, you have a lot of things in common. Because a lot of these\\nthings didn\\'t be-- wasn\\'t zero times something. It\\'s actually a positive number\\ntimes some positive number. If you have a lot of shared\\nwords, than that looks good. The trouble of this is if\\nI have a long document-- say, a million words--\\nand it\\'s 99% in common with another document\\nthat\\'s a million words long, it\\'s still-- it\\nlooks super similar. Actually, I need to do\\nit the other way around. Let\\'s say it\\'s a million words\\nlong and half of the words are in common. So not that many,\\nbut a fair number. Then I have a score\\nof like 500,000. And then I have two documents\\nwhich are, say, 100 words long. And they\\'re identical. Their score is maybe only 100. So even though\\nthey\\'re identical, it\\'s not quite scale invariant. So it\\'s not quite\\na perfect measure. Any suggestions for\\nhow to fix this? This, I think, is\\na little trickier. Yeah? AUDIENCE: Divide by the\\nlength of the vectors? PROFESSOR: Divide by the\\nlength of the vectors. I think that\\'s worth a pillow. Haven\\'t done any pillows yet. Sorry about that. So, divide by the\\nlength of vector. That\\'s good. I\\'m going to call\\nthis D double prime. Still not quite\\nthe right answer. Or not-- no, it\\'s pretty good. It\\'s pretty good. So here, the length\\nof the vectors is the number of\\nwords that occur in them This is pretty cool. But does anyone\\nrecognize this formula? Angle, yeah. It\\'s a lot like the angle\\nbetween the two vectors. It\\'s just off by an arc cos. This is the cosine of the\\nangle between the two vectors. And I\\'m a geometer. I like geometry. So if you take arc\\ncos of that thing, that\\'s a well established\\ndistance metric. This goes back to \\'75,\\nif you can believe it, back when people-- early\\ndays of document, information retrieval, way before\\nthe web, people were still working\\non this stuff. So it\\'s a natural measure of the\\nangle between the two vectors. If it\\'s 0, they\\'re\\nbasically identical. If it\\'s 90 degrees, they\\'re\\nreally, really different. And so that gives you a nice way\\nto compute document distance. The question is, how do we\\nactually compute that measure? Now that we\\'ve come up with\\nsomething that\\'s reasonable, how do I actually\\nfind this value? I need to compute these\\nvectors-- the number of recurrences of each\\nword in the document. And I need you compute\\nthe dot product. And then I need to divide. That\\'s really easy. So, dot product--\\nand I also need to decompose a document\\nto a list of words. So there are three\\nthings I need to do. Let me write them down. So a sort of algorithm. There\\'s one, split a\\ndocument into words. Second is compute\\nword frequencies, how many times\\neach word appears. This is the document vectors . And then the third step is\\nto compute the dot product. Let me tell you a little\\nbit about how each of those is done. Some of these will be covered\\nmore in future lectures. I want to give you an overview. There\\'s a lot of ways to\\ndo each of these steps. If you look at the--\\nnext to the lecture notes for this lecture two,\\nthere\\'s a bunch of code and a bunch of data\\nexamples of documents-- big corpuses of text. And you can run,\\nI think, there are eight different\\nalgorithms for it. And let me give you--\\nactually, why don\\'t I cut to the chase a\\nlittle bit and tell you about the run times of these\\ndifferent implementations of this same algorithms. There are lots of sort of\\nversions of this algorithm. We implement it a whole bunch. Every semester I teach this, I\\nchange them a little bit more, add a few more variants. So version one, on\\na particular pair of documents which is like a\\nmegabyte-- not very much text-- it takes 228.1\\nseconds-- super slow. Pathetic. Then we do a little bit\\nof algorithmic tweaking. We get down to 164 seconds. Then we get to 123 seconds. Then we get down to 71 seconds. Then we get down\\nto 18.3 seconds. And then we get to 11.5 seconds. Then we get to 1.8 seconds. Then we get to 0.2 seconds. So factor of 1,000. This is just in Python. 2/10 of a second to\\nprocess a megabytes. It\\'s all right. It\\'s getting reasonable. This is not so reasonable. Some of these improvements\\nare algorithmic. Some of them are\\njust better coding. So there\\'s improving\\nthe constant factors. But if you look at\\nlarger and larger texts, this will become\\neven more dramatic. Because a lot of these\\nwere improvements from quadratic time algorithms\\nto linear and log n algorithms. And so for a megabyte, yeah,\\nit\\'s a reasonable improvement. But if you look at a gigabyte,\\nit\\'ll be a huge improvement. There will be no comparison. In fact, there will\\nbe no comparison. Because this one\\nwill never finish. So the reason I ran\\nsuch a small example so I could have patience\\nto wait for this one. But this one you could run\\non the bigger examples. All right, so where do\\nI want to go from here? Five minutes. I want to tell you about\\nsome of those improvements and some of the algorithms here. Let\\'s start with\\nthis very simple one. How would you split a\\ndocument into words in Python? Yeah? AUDIENCE: [INAUDIBLE]. Iterate through the document,\\n[INAUDIBLE] the dictionary? PROFESSOR: Iterate\\nthrough the-- that\\'s actually how we do number two. OK, we can talk about that one. Iterate through the\\nwords in the document and put it in a dictionary. Let\\'s say, count of\\nword plus equals 1. This would work if count\\nis something called a count dictionary if you\\'re\\nsuper Pythonista. Otherwise, you have to check,\\nis the word in the dictionary? If not, set it to one. If it is there, add one to it. But I think you know\\nwhat this means. This will count the\\nnumber of words-- this will count the frequency\\nof each word in the dictionary. And becomes dictionaries\\nrun in constant time with high probability--\\nwith high probability-- this will take order--\\nwell, cheating a little bit. Because words can\\nbe really long. And so to reduce a word\\ndown to a machine word could take order the\\nlength of the word time. To a little more\\nprecise, this is going to be the\\nsum of the lengths of the words in the\\ndocument, which is also known as a length of\\nthe document, basically. So this is good. This is linear time\\nwith high probability. OK, that\\'s a good algorithm. That is introduced\\nin algorithm four. So we got a significant boost. There are other ways to do this. For example, you\\ncould sort the words and then run through\\nthe sorted list and count, how many do you\\nget in a row for each one? If it\\'s sorted, you\\ncan count-- I mean, all the identical words are\\nput right next to each other. So it\\'s easy to count them. And that\\'ll run almost as fast. That was one of\\nthese algorithms. OK, so that\\'s a couple\\ndifferent ways to do that. Let\\'s go back to\\nthis first step. How would you split a document\\ninto words in the first place? Yeah? AUDIENCE: Search circulated\\nspaces and then [INAUDIBLE]. PROFESSOR: Run through\\nthough the string. And every time you see anything\\nthat\\'s not alphanumeric, start a new word. OK, that would run\\nin linear time. That\\'s a good answer. So it\\'s not hard. If you\\'re a fancy Pythonista,\\nyou might do it like this. Remember my Reg Exes. This will find all the\\nwords in a document. Trouble is, in general,\\nre takes exponential time. So if you think about\\nalgorithms, be very careful. Unless you know how\\nre is implemented, this probably will\\nrun in linear time. But it\\'s not obvious at all. Do anything fancy with\\nregular expressions. If you don\\'t know what this\\nmeans, don\\'t worry about it. Don\\'t use it. If you know about it, be\\nvery careful in this class when you use re. Because it\\'s not\\nalways linear time. But there is an easy\\nalgorithm for this, which is just scan through\\nand look for alpha numerics. String them together. It\\'s good. There\\'s a few other\\nalgorithms here in the notes. You should check them out. And for fun, look at this code\\nand see how small differences make dramatic difference\\nin performance. Next class will\\nbe about sorting.',\n",
       " \"The following content is\\nprovided under a Creative Commons license. Your support will help\\nMIT OpenCourseWare continue to offer high quality\\neducational resources for free. To make a donation, or to\\nview additional materials from hundreds of MIT courses,\\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Well, because\\nour subject today is trig integrals\\nand substitutions, Professor Jerison called in his\\nsubstitute teacher for today. That's me. Professor Miller. And I'm going to try to tell\\nyou about trig substitutions and trig integrals. And I'll be here tomorrow to\\ndo more of the same, as well. So, this is about trigonometry,\\nand maybe first thing I'll do is remind you of some basic\\nthings about trigonometry. So, if I have a\\ncircle, trigonometry is all based on the\\ncircle of radius 1 and centered at the origin. And so if this is an angle\\nof theta, up from the x-axis, then the coordinates\\nof this point are cosine theta and sine theta. And so that leads right away\\nto some trig identities, which you know very well. But I'm going to put them up\\nhere because we'll use them over and over again today. Remember the convention sin^2\\ntheta secretly means (sin theta)^2. It would be more\\nsensible to write a parenthesis around\\nthe sine of theta and then say you square that. But everybody in the world puts\\nthe 2 up there over the sin, and so I'll do that too. So that follows just because\\nthe circle has radius 1. But then there are some\\nother identities too, which I think you remember. I'll write them down\\nhere. cos(2theta), there's this double angle\\nformula that says cos(2theta) = cos^2(theta) - sin^2(theta). And there's also the\\ndouble angle formula for the sin(2theta). Remember what that says? 2 sin(theta) cos(theta). I'm going to use\\nthese trig identities and I'm going to use them\\nin a slightly different way. And so I'd like to pay a little\\nmore attention to this one and get a different way\\nof writing this one out. So this is actually\\nthe half angle formula. And that says, I'm going to\\ntry to express the cos(theta) in terms of the cos(2theta). So if I know the\\ncos(2theta), I want to try to express the\\ncos theta in terms of it. Well, I'll start with a\\ncos(2theta) and play with that. OK. Well, we know what this is, it's\\ncos^2(theta) - sin^2(theta). But we also know what the\\nsin^2(theta) is in terms of the cosine. So I can eliminate the\\nsin^2 from this picture. So this is equal to cos^2(theta)\\nminus the quantity 1 - cos^2(theta). I put in what sin^2 is in\\nterms of cos^2 And so that's 2 cos^2(theta) - 1. There's this cos^2,\\nwhich gets a plus sign. Because of these\\ntwo minus signs. And there's the one\\nthat was there before, so altogether there\\nare two of them. I want to isolate\\nwhat cosine is. Or rather, what cos^2 is. So let's solve for that. So I'll put the 1\\non the other side. And I get 1 + cos(2theta). And then, I want to divide by\\nthis 2, and so that puts a 2 in this denominator here. So some people call that\\nthe half angle formula. What it really is for us is\\nit's a way of eliminating powers from sines and cosines. I've gotten rid of this\\nsquare at the expense of putting in a 2theta here. We'll use that. And, similarly, same calculation\\nshows that sin^2(theta) = (1 - cos(2theta)) / 2. Same cosine, in that formula\\nalso, but it has a minus sign. For the sin^2. OK. so that's my little\\nreview of trig identities that we'll make use of\\nas this lecture goes on. I want to talk about trig\\nidentity-- trig integrals, and you know some trig\\nintegrals, I'm sure, already. Like, well, let me write\\nthe differential form first. You know that d sin\\ntheta, or maybe I'll say d sin x, is,\\nlet's see, that's the derivative of sin\\nx times dx, right. The derivative of\\nsin x is cos x, dx. And so if I integrate both sides\\nhere, the integral form of this is the integral of cos x dx. Is sin x plus a constant. And in the same way,\\nd cos x = -sin x dx. Right, the derivative of\\nthe cosine is minus sine. And when I integrate that, I\\nfind the integral of sin x dx is -cos x + c. So that's our starting point. And the game today, for the\\nfirst half of the lecture, is to use that basic-- just\\nthose basic integration formulas, together with\\nclever use of trig identities in order to compute more\\ncomplicated formulas involving trig functions. So the first thing,\\nthe first topic, is to think about integrals of\\nthe form sin^n (x) cos^n (x) dx. Where here I have in mind m and\\nn are non-negative integers. So let's try to integrate these. I'll show you some applications\\nof these pretty soon. Looking down the\\nroad a little bit, integrals like this show\\nup in Fourier series and many other subjects\\nin mathematics. It turns out they're quite\\nimportant to be able to do. So that's why we're\\ndoing them now. Well, so there are two\\ncases to think about here. When you're integrating\\nthings like this. There's the easy case, and\\nlet's do that one first. The easy case is when at\\nleast one exponent is odd. That's the easy case. So, for example, suppose\\nthat I wanted to integrate, well, let's take the case m = 1. So I'm integrating\\nsin^n (x) cos x dx. I'm taking-- Oh, I\\ncould do that one. Let's see if that's\\nwhat I want to take. Yeah. My confusion is that I meant\\nto have this a different power. You were thinking that. So let's do this\\ncase when m = 1. So the integral I'm\\ntrying to do is any power of the sine times the cosine. Well, here's the trick. Recognize, use this\\nformula up at the top there to see cos x dx as\\nsomething that we already have on the blackboard. So, the way to exploit that\\nis to make a substitution. And substitution is\\ngoing to be u = sin x. And here's why. Then this integral that I'm\\ntrying to do is the integral of u^n, that's already\\na simplification. And then there's that cos x dx. When you make a substitution,\\nyou've got to go all the way and replace everything\\nin the expression by things involving this new\\nvariable that I've introduced. So I'd better get\\nrid of the cos x dx and rewrite it in terms\\nof du or in terms of u. And I can do that because du,\\naccording to that formula, is cos x dx. Let me put a box around that. That's our substitution. When you make a\\nsubstitution, you also want to compute the\\ndifferential of the variable that you substitute in. So the cos x dx that appears\\nhere is just, exactly, du. And I've replaced this trig\\nintegral with something that doesn't involve\\ntrig functions at all. This is a lot easier. We can just plug into\\nwhat we know here. This is u^(n+1) /\\n(n+1) plus a constant, and I've done the integral. But I'm not quite done\\nwith the problem yet. Because to be nice to your\\nreader and to yourself, you should go back at\\nthis point, probably, go back and get rid of this new\\nvariable that you introduced. You're the one who introduced\\nthis variable, you. Nobody except you,\\nreally, knows what it is. But the rest of the\\nworld knows what they asked for the first\\nplace that involved x. So I have to go back\\nand get rid of this. And that's not hard to do in\\nthis case, because u = sin x. And so I make this\\nback substitution. And that's what you get. So there's the answer. OK, so the game was, I use this\\nodd power of the cosine here, and I could see it appearing as\\nthe differential of the sine. So that's what made\\nthis substitution work. Let's do another example\\nto see how that works out in a slightly different case. So here's another example. Now I do have an odd power. One of the exponents is odd,\\nso I'm in the easy case. But it's not 1. The game now is to\\nuse this trig identity to get rid of the largest\\neven power that you can, from this odd power here. So use sin^2 x = 1 - cos^2 x, to\\neliminate a lot of powers from that odd power. Watch what happens. So this is not really a\\nsubstitution or anything, this is just a trig identity. This sine cubed is sine\\nsquared times the sine. And the sine squared\\nis 1 - cos^2 x. And then I have the\\nremaining sin x. And then I have cos^2 x dx. So let me rewrite that a little\\nbit to see how this works out. This is the integral\\nof cos^2 x minus, and then there's the\\nproduct of these two. That's cos^4 x times sin x dx. So now I'm really\\nexactly in the situation that I was in over here. I've got a single power\\nof a sine or cosine. It happens that\\nit's a sine here. But that's not going\\nto cause any trouble, we can go ahead and play the\\nsame game that I did there. So, so far I've just been\\nusing trig identities. But now I'll use a\\ntrig substitution. And I think I want to write\\nthese as powers of a variable. And then this is going to be the\\ndifferential of that variable. So I'll take u to be cos x, and\\nthat means that du = -sin x dx. There's the substitution. So when I make that\\nsubstitution, what do we get. Cosine squared becomes u^2. Cosine to the 4th becomes u^4,\\nand sin x dx becomes not quite du, watch for the signum,\\nwatch for this minus sign here. It becomes -du. But that's OK. The minus sign comes outside. And I can integrate\\nboth of these powers, so I get -u^3 / 3. And then this 4th power gives me\\na 5th power, when I integrate. And don't forget the constant. Am I done? Not quite done. I have to back\\nsubstitute and get rid of my choice of variable, u,\\nand replace it with yours. Questions? STUDENT: [INAUDIBLE] PROFESSOR: There should indeed. I forgot this minus sign\\nwhen I came down here. So these two gang up\\nto give me a plus. Was that what the other\\nquestion was about, too? Thanks. So let's back substitute. And I'm going to\\nput that over here. And the result is, well, I just\\nreplace the u by cosine of x. So this is - -cos^3(x) / 3 plus,\\nthank you, cos^5(x) / 5 + c. And there's the answer. By the way, you can remember\\none of the nice things about doing an\\nintegral is it's fairly easy to check your answer. You can always differentiate\\nthe thing you get, and see whether you get the\\nright thing when you go back. It's not too hard\\nto use the power rules and the\\ndifferentiation rule for the cosine to get\\nback to this if you want to check the work. Let's do one more\\nexample, just to handle an example of this\\neasy case, which you might have thought of at first. Suppose I just want to\\nintegrate a cube. sin^3 x. No cosine in sight. But I do have an\\nodd power of a trig function, of a sine or cosine. So I'm in the easy case. And the procedure that I was\\nsuggesting says I want to take out the largest even power\\nthat I can, from the sin^3. So I'll take that out, that's\\na sin^2, and write it as 1 - cos^2. Well, now I'm very happy. Because it's just\\nlike the situation we had somewhere\\non the board here. It's just like the\\nsituation we had up here. I've got a power of a\\ncosine times sin x dx. So exactly the same\\nsubstitution steps in. You get, and maybe\\nyou can see what happens without doing the work. Shall I do the work here? I make the same substitution. And so this is (1 - u\\n(1 - u^2) times -du. Which is u - u^3 / 3. But then I want to put\\nthis minus sign in place, and so that gives me -u +\\nu^3 / 3 plus a constant. And then I back substitute\\nand get cos x + cos^3 x / 3. So this is the easy case. If you have some odd\\npower to play with, then you can make use of it and\\nit's pretty straightforward. OK the harder case is when\\nyou don't have an odd power. So what's the program? I'm going to do the\\nharder case, and then I'm going to show you an example of\\nhow to integrate square roots. And do an application, using\\nthese ideas from trigonometry. So I want to keep\\nthis blackboard. Maybe I'll come back\\nand start here again. So the harder case is when\\nthey're only even exponents. I'm still trying to\\nintegrate the same form. But now all the\\nexponents are even. So we have to do some game. And here the game is use\\nthe half angle formula. Which I just erased, very\\nsadly, on the board here. Maybe I'll rewrite\\nthem over here so we have them on the board. I think I remember\\nwhat they were. So the game is I'm going\\nto use that half angle formula to start getting\\nrid of those even powers. Half angle formula written like\\nthis, exactly, talks about-- it rewrites even powers\\nof sines and cosines. So let's see how that\\nworks out in an example. How about just the cosine\\nsquared for a start. What to do? I can't pull anything out. I could rewrite\\nthis as 1 - sin^2, but then I'd be faced with\\nintegrating the sin^2, which is exactly as hard. So instead, let's use\\nthis formula here. This is really the same\\nas (1+cos(2theta)) / 2. And now, this is easy. It's got two parts to it. Integrating one half\\ngives me theta over-- Oh. Miraculously, the x\\nturned into a theta. Let's put it back as x. I get x/2 by integrating 1/2. So, notice that something\\nnon-trigonometric occurs here when I do these even integrals. x/2 appears. And then the other one, OK, so\\nthis takes a little thought. The integral of the\\ncosine is the sine, or is it minus the sine. Negative sine. Shall we take a vote? I think it's positive. And so you get sin(2x),\\nbut is that right? Over 2. If I differentiate the\\nsin(2x), this 2 comes out. And would give me\\nan extra 2 here. So there's an extra 2\\nthat I have to put in here when I integrate it. And there's the answer. This is not a substitution. I just played with\\ntrig identities here. And then did a\\nsimple trig integral, getting your help to\\nget the sign right. And thinking about what\\nthis 2 is going to do. It produces a 2 in\\nthe denominator. But it's not applying\\nany complicated thing. It's just using this identity. Let's do another example\\nthat's a little bit harder. This time, sin^2 times cos^2. Again, no odd powers. I've got to work a\\nlittle bit harder. And what I'm going to do\\nis apply those identities up there. Now, what I recommend\\ndoing in this situation is going over to\\nthe side somewhere. And do some side work. Because it's all just\\nplaying with trig functions. It's not actually doing\\nany integrals for a while. So, I guess one way to get rid\\nof the sin^2 and the cos^2 is to use those identities\\nand so let's do that. So the sine is (1\\n- cos(2x)) / 2. And the cosine is\\n(1 + cos(2x)) / 2. So I just substitute them in. And now I can multiply that out. And what I have is a\\ndifference times a sum. So you know a formula for that. Taking the product of these two\\nthings, well there'll be a 4 in the denominator. And then in the numerator,\\nI get the square of this minus the\\nsquare of this. (a-b)(a+b) = a^2 -\\nb^2. = - So I get that. Well, I'm a little bit\\nhappier, because at least I don't have 4. I don't have 2\\ndifferent squares. I still have a square, and\\nwant to integrate this. I'm still not in the easy case. I got myself back to\\nan easier hard case. But we do know what\\nto do about this. Because I just did it up there. And I could play into\\nthis formula that we got. But I think it's just as easy\\nto continue to calculate here. Use the half angle\\nformula again for this, and continue on your way. So I get a 1/4 from this bit. And then minus 1/4 of cos^2(2x). And when I plug in 2x in for\\ntheta, there in the top board, I'm going to get a 4x\\non the right-hand side. So it comes out like that. And I guess I could simplify\\nthat a little bit more. This is a 1/4. Oh, but then there's a 2 here. It's half that. So then I can simplify\\na little more. It's 1/4 - 1/8, which is 1/8. And then I have 1/8 cos(4x). OK, that's my side work. I just did some trig\\nidentities over here. And rewrote sine\\nsquared times cosine squared as something which\\ninvolves just no powers of trig, just cosine by itself. And a constant. So I can take that and\\nsubstitute it in here. And now the integration\\nis pretty easy. 1/8, cos(4x) / 8,\\ndx, which is, OK the 1/8 is going to give me x/8. The integral or cosine is\\nplus or minus the sine. The derivative of the\\nsine is plus the cosine. So it's going to be plus the--\\nOnly there's a minus here. So it's going to be the\\nsine-- minus sin(4x) / 8, but then I have an additional\\nfactor in the denominator. And what's it going to be? I have to put a 4 there. So we've done that\\ncalculation, too. So any of these-- If you keep\\ndoing this kind of process, these two kinds\\nof procedures, you can now integrate\\nany expression that has a power of a sine times\\na power of a cosine in it, by using these ideas. Now, let's see. Oh, let me give you an alternate\\nmethod for this last one here. I know what I'll do. Let me give an alternate\\nmethod for doing, really doing the side work over there. I'm trying to deal\\nwith sin^2 times cos^2. Well that's the\\nsquare of sin x cos x. And sin x cos x\\nshows up right here. In another trig identity. So we can make use of that, too. That reduces the number of\\nfactors of sines and cosines by 1. So it's going in\\nthe right direction. This is equal to 1/2\\nsin(2x), squared. Sine times cosine is\\n1/2-- Say this right. It's sin(2x) / 2, and then\\nI want to square that. So what I get is sin^2(2x) / 4. Which is, well, I'm\\nnot too happy yet, because I still\\nhave an even power. Remember I'm trying to\\nintegrate this thing in the end, even powers are bad. I try to get rid of them. By using that formula,\\nthe half angle formula. So I can apply that\\nto sin x here again. I get 1/4 of (1 - cos(4x)) / 2. That's what the half angle\\nformula says for sin^2(2x). And that's exactly the\\nsame as the expression that I got up here, as well. It's the same expression\\nthat I have there. So it's the same\\nexpression as I have here. So this is just an alternate\\nway to play this game of using the half angle formula. OK, let's do a little\\napplication of these things and change the\\ntopic a little bit. So here's the problem. So this is an\\napplication and example of a real trig substitution. So here's the problem\\nI want to look at. OK, so I have a circle\\nwhose radius is a. And I cut out from it\\na sort of tab, here. This tab here. And the height of\\nthis thing is b. So this length is a number b. And what I want to do is compute\\nthe area of that little tab. That's the problem. So there's an arc over here. And I want to find the\\narea of this, for a and b, in terms of a and b. So the area, well,\\nI guess one way to compute the area would be\\nto take the integral of y dx. You've seen the idea\\nof splitting this up into vertical strips whose\\nheight is given by a function y(x). And then you integrate that. That's an interpretation\\nfor the integral. The area is given by y dx. But that's a little bit awkward,\\nbecause my formula for y is going to be a little strange. It's constant, value of b, along\\nhere, and then at this point it becomes this\\narc, of the circle. So working this\\nout, I could do it but it's a little awkward\\nbecause expressing y as a function of x, the\\ntop edge of this shape, it's a little awkward, and\\ntakes two different regions to express. So, a different way to\\nsay it is to say x dy. Maybe that'll work\\na little bit better. Or maybe it won't,\\nbut it's worth trying. I could just as well\\nsplit this region up into horizontal strips. Whose width is dy,\\nand whose length is x. Now I'm thinking of\\nthis as a function of y. This is the graph\\nof a function of y. And that's much better, because\\nthe function of y is, well, it's the square root\\nof a^2 - y^2, isn't it. That's x x^2 + y^2 = a^2. So that's what x is. And that's what I'm\\nasked to integrate, then. Square root of (a^2 - y^2), dy. And I can even put in\\nlimits of integration. Maybe I should do that,\\nbecause this is supposed to be an actual number. I guess I'm integrating it\\nfrom y = 0, that's here. To y = b, dy. So this is what I want to find. This is a integral formula\\nfor the area of that region. And this is a new form. I don't think that\\nyou've thought about integrating expressions\\nlike this in this class before. So, it's a new form and I\\nwant to show you how to do it, how it's related\\nto trigonometry. It's related to trigonometry\\nthrough that exact picture that we have on the blackboard. After all, this a^2 - y^2\\nis the formula for this arc. And so, what I\\npropose is that we try to exploit the\\nconnection with the circle and introduce polar coordinates. So, here if I measure\\nthis angle then there are various things you can say. Like the coordinates of this\\npoint here are a cos(theta), a-- Well, I'm sorry, it's not. That's an angle, but I\\nwant to call it theta_0. And, in general you know\\nthat the coordinates of this point are (a cos(theta),\\na sin(theta)). If the radius is a, then\\nthe angle here is theta. So x = a cos(theta),\\nand y = a sin(theta), just from looking at the\\ngeometry of the circle. So let's make that\\nsubstitution. y = a sin(theta). I'm using the picture to\\nsuggest that maybe making the substitution is\\na good thing to do. Let's follow along\\nand see what happens. If that's true, what we're\\ninterested in is integrating, a^2 - y^2. Which is a^2-- We're interested\\nin integrating the square root of a^2 - y^2. Which is the square\\nroot of a^2 minus this. a^2 sin^2(theta). And, well, that's\\nequal to a cos theta. That's just sin^2 + cos^2\\n= 1, all over again. It's also x. This is x. And this was x. So there are a lot of different\\nways to think of this. But no matter how you say\\nit, the thing we're trying to integrate, a^2 - y^2 is,\\nunder this substitution it is a cos(theta). So I'm interested in integrating\\nthe square root of (a^2 - y^2), dy. And I'm going to make this\\nsubstitution y = a sin(theta). And so under that substitution,\\nI've decided that the square root of a^2 - y^2\\nis a cos(theta). That's this. What about the dy? Well, I'd better compute the dy. So dy, just differentiating\\nthis expression, is a cos(theta) d theta. So let's put that in. dy\\n= a cos(theta) d theta. OK. Making that trig substitution,\\ny = a sin(theta), has replaced this integral\\nthat has a square root in it. And no trig functions. With an integral that involves\\nno square roots and only trig functions. In fact, it's not too hard to\\nintegrate this now, because of the work that we've done. The a^2 comes out. This is cos^2(theta) d theta. And maybe we've done that\\nexample already today. I think we have. Maybe we can think it through,\\nbut maybe the easiest thing is to look back at notes\\nand see what we got before. That was the first example\\nin the hard case that I did. And what it came out to, I used\\nx instead of theta at the time. So this is a good step forward. I started with this\\nintegral that I really didn't know how to do by any\\nmeans that we've had so far. And I've replaced it\\nby a trig integral that we do know how to do. And now I've done\\nthat trig integral. But we're still not quite\\ndone, because of the problem of back substituting. I'd like to go back and\\nrewrite this in terms of the original variable, y. Or, I'd like to go\\nback and rewrite it in terms of the original\\nlimits of integration that we had in the\\noriginal problem. In doing that, it's going\\nto be useful to rewrite this expression and get\\nrid of the sin(2theta). After all, the original\\ny was expressed in terms of sin(theta), not sin(2theta). So let me just do that here,\\nand say that this, in turn, is equal to a^2\\ntheta / 2 plus, well, sin(2theta) = 2\\nsin(theta) cos(theta). And so, when there's a 4 in\\nthe denominator, what I'll get is sin(theta) cos(theta) / 2. I did that because I'm getting\\ncloser to the original terms that the problem started with. Which was sin(theta). So let me write down the\\nintegral that we have now. The square root of a^2\\n- y^2, dy is, so far, what we know is a^2 (theta / 2 +\\nsin(theta) cos(theta) / 2) + c. But I want to go\\nback and rewrite this in terms of the original value. The original variable, y. Well, what is theta\\nin terms of y? Let's see. y in terms of\\ntheta was given like this. So what is theta in terms of y? Ah. So here the fearsome arcsine\\nrears its head, right? Theta is the angle so\\nthat y = a sin(theta). So that means that theta is\\nthe arcsine, or sine inverse, of y/a. So that's the first\\nthing that shows up here. arcsin(y/a), all over 2. That's this term. Theta is arcsin(y/a) / 2. What about the other side, here? Well sine and cosine, we knew\\nwhat they were in terms of y and in terms of x, if you like. Maybe I'll put the\\na^2 inside here. That makes it a\\nlittle bit nicer. Plus, and the other term is\\na^2 sin(theta) cos(theta). So the a sin(theta) is just y. Maybe I'll write this (a\\nsin(theta)) (a cos(theta)) / 2 + c. And so I get the same thing. And now here a\\nsin(theta), that's y. And what's the a cos(theta)? It's x, or, if you like, it's\\nthe square root of a^2 - y^2. And so there I've\\nrewritten everything, back in terms of the\\noriginal variable, y. And there's an answer. So I've done this indefinite\\nintegration of a form-- of this quadratic, this square\\nroot of something which is a constant minus y^2. Whenever you see that, the thing\\nto think of is trigonometry. That's going to play into\\nthe sin^2 + cos^2 identity. And the way to exploit it\\nis to make the substitution y = a sin(theta). You could also make a\\nsubstitution y = a cos(theta), if you wanted to. And the result would come out\\nto exactly the same in the end. I'm still not quite done\\nwith the original problem that I had, because\\nthe original problem asked for a definite integral. So let's just go back\\nand finish that as well. So the area was\\nthe integral from 0 to b of this square root. So I just want to evaluate\\nthe right-hand side here. The answer that we came up\\nwith, this indefinite integral. I want to evaluate\\nit at 0 and at b. Well, let's see. When I evaluate it at b, I get\\na^2 arcsin(b/a) / 2 plus y, which is b, times the\\nsquare root of a^2 - b^2, putting y = b, divided by 2. So I've plugged in y\\n= b into that formula, this is what I get. Then when I plug in y = 0,\\nwell the, sine of 0 is 0, so the arcsine of 0 is 0. So this term goes away. And when y = 0,\\nthis term is 0 also. And so I don't get any\\nsubtracted terms at all. So there's an\\nexpression for this. Notice that this arcsin(b/a),\\nthat's exactly this angle. arcsin(b/a), it's the angle\\nthat you get when y = b. So this theta is\\nthe arcsin(b/a). Put this over here. That is theta_0. That is the angle\\nthat the corner makes. So I could rewrite this as a\\na^2 theta_0 / 2 plus b times the square root of\\na^2 - b^2, over 2. Let's just think about\\nthis for a minute. I have these two terms in\\nthe sum, is that reasonable? The first term is a^2. That's the radius squared\\ntimes this angle, times 1/2. Well, I think that is exactly\\nthe area of this sector. a^2 theta / 2 is the formula\\nfor the area of the sector. And this one, this is\\nthe vertical elevation. This is the horizontal. a^2 - b^2 is this distance. Square root of a^2 - b^2. So the right-hand term is b\\ntimes the square root of a^2 - b^2 divided by 2, that's\\nthe area of that triangle. So using a little\\nbit of geometry gives you the same answer as\\nall of this elaborate calculus. Maybe that's enough\\ncause for celebration for us to quit for today.\",\n",
       " \"The following\\ncontent is provided by MIT OpenCourseWare under\\na Creative Commons license. Additional information\\nabout our license and OpenCourseWare in general\\nis available at ocw.mit.edu. PROFESSOR: OK. So I'll start a little formally. That this is 18.086 in\\nSpring semester of 2006. And we're lucky to have it\\nvideotaped for OpenCourseWare. So, let me begin by\\nremembering the main topics from what you might call the\\nfirst half, 18.085, the Fall course. And then, most important\\nto us, so it gets a star, are the main topics\\nfor this course. So 18.085 began with\\napplied linear algebra. The discrete equations\\nof mechanics, and physics and engineering. And the type of matrices\\nthat it involved, so we learned what positive\\ndefinite matrices are. Then the center of the course\\nwas differential equations. Ordinary differential\\nequations, so that was 1D, partial differential\\nequations like Laplace, that was 2D, with\\nboundary values. So that led to\\nsystems of equations. And then the third big\\ntopic was Fourier methods. All of Fourier ideas: series,\\nintegrals discrete transform. So that's like the first\\nhalf of the course. Well, that's 18.085. OK. And here we are. So this course has,\\nalso, three major topics. The first, the one\\nwe start on today, is differential equations that\\nstart from initial values. So I'm thinking of the wave\\nequation, where we're given the displacement of velocity. The heat equation. Black-Scholes equation,\\nwhich comes from finance, is a version of\\nthe heat equation. Ordinary differential equations,\\nthat's going to be today. And non-linear equations,\\nNavier-Stokes ultimately. But not heavily Navier-Stokes. So this is where we begin. And then, a second big\\ntopic is how to solve. Because this course\\nis really applied math and scientific computing. The second big topic is, how do\\nyou solve a large linear system A*x equal b? Do you do it by direct\\nmethods, elimination? With renumbering\\nof nodes, and there are lots of tricks that makes\\nelimination very successful. Or do you do it by\\niterative methods? Multi-grid is one. So this is really modern\\nscientific computing we're talking about. We're really at the point\\nwhere people are computing. And then the third topic,\\nwhich is a little different, is optimization, minimization. Linear programming would be one\\nexample, but among many, many. So that's a major\\narea in applied math. OK. So this is our topic,\\ndifferential equations. And I was asked before\\nthe tape started about my own background. And my thesis was in this topic. Because a key question\\nwill be stability. Is the difference method stable? You'll see that that's a\\nrequirement to be any good. You really have\\nto sort out what-- and that usually puts a\\nlimitation on the time step. So we're going to\\nhave a time step. And it may be limited by the\\nrequirement of stability. And the fact that stability\\nand convergence-- success of the method-- are\\nso intimately linked. There was a key paper by Lax and\\nRichtmyer that we'll look at. It's known now as the Lax\\nEquivalence Theorem, stability and convergence. We'll see it in detail. Actually when I was a grad\\nstudent, by good chance, there was a seminar, and I was\\nasked to report on some paper and it happened to be that one. And I just, looking back,\\nthink, gosh, I was lucky. Because that paper,\\nthe Lax-Richtmyer paper with the Lax\\nEquivalence Theorem, set the question of stability. And then years of effort\\nwent into finding tests for stability-- how do you\\ndecide, is the method stable? So we'll see some of that. OK. Since then I've worked\\non other things, well, wavelets would be one\\nthat relates to Fourier. And other topics too. And lots of linear algebra. But it's a pleasure to look\\nback to the beginning of [UNINTELLIGIBLE]. OK. So that's the\\nOpenCourseWare site which does have\\nthe course outline, and other information\\nabout the course. Some of which I have mentioned\\ninformally before the class. This is our central website,\\nwith no decimal in 18086, which will have notes coming\\nup, MATLAB things, problems. That's our content. It will be the 086 page. OK. So that's the course\\noutline in three lines. And then the web\\npage and a handout will give you half a dozen\\nsub-headings under those. OK. So that's the course. And actually it's the center\\nof scientific computing. There would be other courses\\nat MIT covering material like that, because it's just so\\nbasic you can't go without it. All right, so now\\nI'm ready to start on the first lecture, which\\nwill be ordinary differential equations. And I won't always have things\\nso clearly and beautifully written on the board, but\\ntoday I'm better organized. So here's our problem. Ordinary differential equations. So we're given initial\\nvalues u at t equals 0. OK. So there's always an\\ninitial value here. The question is, what's the\\nequation that makes it evolve? OK. So, often we'll think in\\nterms of one equation. The unknown will be u, u of t. Or, in reality there are\\ntypically N equations. N might be 6 or 12 or\\nsomething in a small problem. But also, N could be very large. We'll see how\\neasily that happens. OK. And often, to discuss stability\\nor understand a method and try it, the linear\\ncase is the natural one. So I'll use a*u with a small a\\nto make us think that we've got a scalar, or a capital A to\\nindicate we're talking about a matrix. So, the correspondence between\\nthese and the more general-- so these are linear. These are likely\\nto be not linear. But there's a natural\\nmatch between-- the number a there corresponds to the\\npartial of f with respect to u. And of course we see it. If that was f, then its\\nderivative is indeed a. And in this matrix case, there\\nwould be a Jacobian matrix. If we have N right-hand\\nsides, because I have N u's, and the\\nmatrix that comes in is the derivative of\\nright-hand side in equation i with respect to unknown j. So it's a N by N matrix,\\nand of course, this is the case where\\nit's a constant. Yeah, I should have said,\\nthese are not only linear, but constant coefficients. So we know of course the\\nsolution, it's an exponential, e to the a*t times\\nu_0, the initial bunch. So we know everything about it. Nevertheless, it's the best test\\ncase for difference methods. And let me just\\ncomment that we do have to pay attention\\nto the possibility that a could be complex. Mostly I'll think of a as\\na real, and often negative. Often the equation\\nwill be stable. A negative a means that\\ne to the a*t decreases. A negative definite matrix,\\nnegative eigenvalues, mean that the matrix\\nexponential decays. And if that matrix is\\nsymmetric, those eigenvalues are all real, that's a key case. Symmetric matrices\\nhave real eigenvalues, and they're the most important,\\nmost attractive class. And a negative\\ndefinite matrix might come from a diffusion term, like\\nsecond derivative, d second u, dx squared. But a convection term, du/dx,\\nfrom a first derivative, will not be symmetric. In fact, maybe it'll\\nbe anti-symmetric. It will push the eigenvalues\\ninto the complex plane. And therefore, we\\nhave to pay attention to the possibility of complex a. As you know, the whole\\npoint of eigenvalues is that we can understand\\nmatrices to a very large extent by diagonalizing, by reducing\\nthem to N scalar equations with the eigenvalues\\nas the little a's in those scalar equations. So anyway, that's the set up. Now I want to say\\nsomething about methods. I want to introduce\\nsome of the names. What am I thinking here? This topic, today's topic\\nof ordinary differential equations, is not going\\nto last long in 18.086. I might still be\\ndiscussing it tomorrow. Friday, I mean. But not much after that. We'll soon be on to partial\\ndifferential equations. So I want to sort of tell you\\nabout ordinary differential equations, well, in kind\\nof an organized way, so that you know the\\ncompeting methods. And also so that you\\nknow this key distinction between-- non-stiff\\nis a typical equation, u prime equal minus 4u\\nwould be a nonstiff, completely normal equation. And for that, those are the\\nrelatively easy ones to solve. We can use explicit differences. And I'll say what that\\nword explicit means. What I want to do is just, like,\\nhelp you organize in your mind. So non-stiff are the average,\\neveryday differential equations. For those we can use explicit\\nmethods that are fast. And we can make them accurate. And explicit means-- so\\nthis is the first meaning-- that I compute the new U--\\nand I'll use capital U-- at time step n plus 1. So that's capital\\nU at the new time. Natural to call\\nthat the new time. Can be computed directly from\\nU at the old time, maybe U at the time before that, maybe\\nU at the times before that. In EE terms it's causal. The new U comes\\nexplicitly by some formula that we'll construct from\\nthe previous computations. It's fast. Of course, I not only use\\nU_n but I used f of U_n. So I should say from U_n itself\\nand from f of U_n at time t_n, and similarly for earlier times. You see how fast that is? Because the only new\\ncalculation of f is this one. The previous step produced U_n,\\nand at the new step, this step, we plug it in to find\\nout what the slope is. And that may be the\\nexpensive calculation, because f could involve all\\nsorts of functions, all sorts of physical constants. It can be complicated or not. but if it is, we only\\nhave to do it once here. That's explicit. Now, what's the opposite? Implicit. So the point about implicit\\nmethods is the difference equation, the formula,\\ninvolves not just U_(n+1), the new value, but also the\\nslope at that new value, at that new unknown value. So it means that an implicit\\nequation could be non-linear. Because if f is not linear,\\nthen this term could involve cosines, or exponentials\\nor whatever, of the unknown U_(n+1). So that, you can't\\ndo it as fast. So this is definitely\\nslower per step. But, the advantage,\\nand the reason it gets used for stiff problems,\\nis that on stiff problems it will allow a\\nmuch larger step. So it's this constant trade-off\\nof speed versus stability. These are less\\nstable, as we'll see, and we'll get to see\\nwhat stability means. These are slower but more\\nstable, implicit methods. OK. I didn't yet say what stiff is. I'll say that in a moment. OK. So explicit versus implicit. U_(n+1) immediately or\\nU_(n+1) only by maybe using Newton's method to\\nsolve an equation, because U_(n+1) appears\\nin a complicated formula. And we have an\\nequation to solve. OK. So now, this part\\nof the board begins to identify different methods. And I'll follow the\\nsame two-column system that non-stiff versus stiff. So this will be explicit\\nand those will be implicit. OK. So the one method that occurs\\nto everybody right away is Euler's method. And that will be the first\\nmethod we'll construct, of course. So that's the first\\nidea anybody would have. It has the minimum accuracy. It's first order. The order of accuracy will\\nbe an issue for all methods. And Euler has p equal 1,\\norder p equal 1, first order. So it's too crude. I mean, if you wanted\\nto tracking a space station with Euler's method,\\nyou would lose it real fast, or you would have to\\ntake delta t so small that it would be impossible. So Euler's method is the\\nfirst one you think of, but not the one you finish with. And similarly on\\nthe implicit side, backward Euler, we'll see, is\\nagain the first implicit method you think of. But in the end, you\\nprobably want to do that. OK. So those are two specific\\nmethods that are easy. The first ones we'll write down. Now then comes families\\nof methods, especially these Adams families. So Adams-Bashforth is explicit,\\nAdams-Moulton are implicit, and the coefficients are in\\nbooks on numerical analysis and will be on the web. And I'll say more\\nabout them of course. And see the first ones. So what Adams-Bashforth,\\nhow does does it differ from Adams-Moulton? OK. So those are multi-step methods. Number two was\\nmulti-step methods. To get more accurate\\nwe use more old values. So Adams-Moulton\\nand Adams-Bashforth, or especially Adams-Bashforth,\\nwould use several old values to get the order of\\naccuracy up high. OK. Now this third category. Of course, actually\\nEuler would be the first of the\\nAdams-Bashforth, and backward Euler might\\nbe early in Adams-Moulton. Or maybe backward Euler is\\nearly in backward differences. OK. So what I want to\\nsay is, Runge-Kutta is like a different approach\\nto constructing methods. You might know what\\nsome of these already. And it's a one-step method. That's a method\\nthat just produces, by sort of half-steps, you\\ncould say, it gets to U_(n+1). But it's explicit. And the code in MATLAB,\\nthe code ODE forty-five, or maybe I should\\nsay ODE four five, is like the workhorse of ODEs. I guess I'm hoping\\nyou'll try that. You'll find ODE45. And I'll try to get\\nit onto the web, but you could just easily\\ndiscover the syntax to call it, and apply\\nit to an equation. Yeah I'll get\\nexamples on the web, and please do the examples. So this is-- the 4,\\n5 typically means that it use a\\nfourth-order Runge-Kutta, so that's pretty accurate. To get up to a fourth\\norder means the error up at time t equal 1, say,\\nis delta t to the fourth. So by cutting delta t in half,\\nyou divide the error by 16. And then it also uses\\na fifth-order one. And maybe I can\\npoint to these words. What makes ODE45-- four\\nfive-- good, successful. I mean, how does it work? It slows down or speeds up. It speeds up when it can, it\\nslows down when it has to. And speed up means\\na bigger delta t, slow down means a\\nsmaller delta t, for the sake of\\nstability or accuracy. Yeah. So if the equation is\\nsuddenly doing something, if the solution is\\nsuddenly doing something, you know, important and\\nquick, then probably at that period delta t will get\\nreduced automatically by ODE45. It'll cut it in half, cut\\nin half again, half again. Every good code is\\nconstantly estimating, using internal\\nchecks to estimate what error it's making. About the error. Just a quick word\\nabout the error. So ODE45, it will, unless\\nyou tell it otherwise, the default accuracy that it\\nwill adjust for is relative. So ODE45 will have a\\nrelative accuracy-- so can I just squeeze in a few\\nwords-- of 10 to the minus 3. It'll shoot for that. And an absolute accuracy\\nof 10 to the minus 6. So it will try to\\nkeep the error-- it will plan to keep\\nthe error, and it'll tell you if it has a problem,\\nbelow 10 to the minus 6. And you could set\\nthat differently. OK. I hope you experiment\\na little with ODE45. And you can either plot the\\nsolutions, some exponential. I mean, push it. Like, let delta t be pretty big,\\nand see where it breaks down. Well, I guess ODE45 is\\nengineered not to break down. If you try a delta\\nt-- it'll decide on what delta t it can do. So we'll also\\ncode, just quickly, some methods by ourselves,\\nand see for a large delta t, what problems could happen. OK. And then backwards. This says backward differences. That's the category of implicit\\nmethods for stiff equation, and backward Euler\\nwould be the very first. And ODE15S is the code that,\\nis the most used code, perhaps, for stiff equations. And it will do the same\\nthing, it will vary delta t. It was will vary the order. So, if it has to slow\\ndown, it may slow. And if things are\\nhappening too quickly, it may change to a low-order,\\nsafe, secure method. When things are, you know, when\\nthe satellite is buzzing out in space, and it\\ncan take giant steps or it can have\\nhigh-order accuracy, say in astronomy, of\\ncourse, they would go up to eighth order and higher,\\ntracking, estimating where stars would\\ngo or planets, these will do that automatically,\\nup to a certain point. And we could write codes,\\nand of course people have, for Adams-Bashforth\\nand Adams-Moulton, varying delta t, varying p. I guess here's a comment. If I had given this\\nlecture yesterday, I would have emphasized\\nnumber two, Adams-Bashforth and Adams-Moulton,\\nbecause books do it and I basically\\nlearned this subject from the major\\ntextbooks on ODEs. But I had a\\nconversation with one of the computational scientists\\nin the math department, and that changed the lecture. Because I learned\\nthat although books tend to discuss those, the\\nAdams methods, in practice these methods, the methods\\nthree-- Runge-Kutta and backward differences--\\nare the most used. And that's reflected in the fact\\nthat these two major codes that are available in MATLAB are\\nin the number three category. OK. So now, that's a picture with\\nname but not details, right? And I haven't even\\nsaid what stiff means. So somewhere I've written\\nsomething about stiff. Yeah. OK. So stiff means--\\nso, if I had only e to the minus t\\nin the solution, then the solution would decay\\nat that rate, e to the minus t. That time step would\\nadjust to keep it accurate. And if I have only\\ne to the minus 99t, then again-- that of\\ncourse is a faster decay, much faster decay--\\nso the time step would adjust to be much\\nsmaller, probably about 1/99 or something. Anyway, much smaller, to\\ncapture within each step the correct behavior of e to\\nthe minus 99t, and no problem. So in other words, it's not the\\nminus 99 that makes it stiff. If it was only the minus\\n99- in other words, if I had a equal\\nminus 99 up there, I wouldn't call it\\na stiff equation. What makes it stiff is\\nthe combination here. You see, what's going to happen\\nas time gets anywhere, this is going to control u of t. The decay of u of t is going\\nto have that time constant 1. But this is going\\nto control-- so I'll say but-- this would control\\ndelta t for explicit methods. And I just picked minus\\n99, but it could have been minus 999 or far worse. So it could be very stiff. This word stiff and identifying\\nthis class of problems, which now is familiar to everybody\\nwho has to compute, didn't come, you know, with Gauss and so on. It came much more recently. But it's become\\nvery important now, to distinguish stiff\\nfrom non-stiff. So where does stiff\\nproblems arise? Well you can see how they\\narise in chemical processes with very different decay\\nrates, biological processes, control theory, all sorts\\nof cases where there's a big dynamic range of rates. And they also arise in systems,\\nbecause the eigenvalues could be minus 1 and minus 99. I can easily create a matrix\\nthat has those two eigenvalues. So it would be a system--\\nlet me create such a matrix. I think probably,\\nif I put minus 50's on the diagonal, that\\ngives trace-- sum down the diagonal is minus 100. And that should equal the\\nsum of the eigenvalues. So, so far so good. And now, if I want these\\ntwo particular numbers, I could put 49 here. So that matrix has\\nthose two eigenvalues. I mean, this is\\nthe kind of matrix, well you might say\\nill conditioned would be a word that you hear\\nfor a matrix like this. The condition number\\nis the ratio-- so the condition\\nnumber of this matrix would be the ratio 99 over 1. And that condition\\nnumber is a number that MATLAB computes\\nall the time. Every time you give it a\\nmatrix problem like this, it estimate, not computes. Because to compute\\nthe condition number requires solving an\\neigenvalue problem, and it does not want to take\\nforever to do that exactly. But it gets an estimate. So that's only a moderate\\ncondition number of 99. That's not a disaster,\\nbut it makes the point. OK. So that's what\\nstiff equations are. OK. Now I've got one\\nmore board prepared. I won't have this every day, but\\nlet me use it while I got it. OK. It's only prepared in\\nthe sense of telling us what we're going to do. So this is what's\\ncoming: a construction of methods, what stability is\\nabout, and what's convergence. So let me begin, let me get\\nEuler constructed today. And backward Euler. So Euler's method will be\\nthe most obvious method, equals f at U_n. So, in the model\\ncase, it's a*U_n. So that's Euler. So that tells us then\\nthat we could rewrite it-- U_(n+1) is explicitly\\n1 plus a delta t U_n. Right? I've moved up the delta t\\nand I moved over the U_n, and it's simple like that. OK. So what's the solution\\nafter n time steps? Let me stay with\\nEuler for a moment. After n steps, every\\nstep just multiplied by this growth factor. Let me refer to that\\nas the growth factor even if it's, as I\\nhope, smaller than 1. So U_n, after n\\nsteps, is this thing has multiplied n times U_0. And what is the stability now? Stability is-- suppose a\\nis negative, typically. That means-- often we'll think\\nof that model, a negative, so that the differential\\nequation is completely stable. Right? e to the a*t, with a\\nnegative, is perfect. The question is, is\\nthis one perfect? So stability will be,\\nis this number below 1? That's the test. Is that-- we could argue about,\\nare we going to let it equal 1? Maybe I'll let it equal 1. So 1 plus a delta\\nt smaller than 1. That'll be the stability\\nrequirement for forward Euler. And what's the a delta t? What's the boundary? What's the critical\\nvalue of a delta t? Remember a negative. How negative can it\\nbe, or how negative can this combination be? You see, it's a\\ncombination a delta t. So let me put above here what\\nthe stability condition is. So the stability\\ncondition on Euler is going to be-- so\\ndo you see what it is? How negative can a delta t be? Go ahead, you don't even have\\nto push the-- well, let's see. So if a delta t, this\\nis a negative number, so this is dragging\\nus down from 1 always. Right? a delta t is like\\na subtracting away from 1. So we're here with the 1. And a delta t is\\npulling us this way. And how far, at what point are\\nwe going to meet instability? Yeah. When we hit minus 1. This is the 1 plus a\\ndelta t that I graphed. So it starts at 1\\nwith delta t equals 0. And as I increase delta\\nt, it moves this way. And eventually, it hits there. And the limit will be at\\na delta t equal minus 2. Because if it carries me 2 from\\n1, that carries me to minus 1. And if I go further,\\nI'm unstable. And you could easily\\ncheck that Euler will blow up like\\ncrazy if you just go a little beyond that limit. Because you're taking\\npowers of a number bigger than, or below minus 1. OK. So there's the stability\\nlimit for Euler. And that's a pretty\\nunpleasant restriction. We will have other\\nstability limits. We'll have some stability\\nlimits over here, but we're looking for\\nnumbers better than 2. This Adams-Bashforth will\\ngive us numbers worse than 2. We'll see those methods\\nfirst thing next time. OK. Now, let me just get back-- OK. If I drew a picture\\nthen-- let's see, have I got another board here? Nope. If I drew a picture of good\\nEuler, so Euler doing its job, the true solution is\\ndecaying like that, and what does Euler do? Forward Euler says,\\nit looks here, it looks at the slope,\\nthat's all it knows, it goes maybe that far. That's a small delta t. That's an OK method. You see, it's not very\\naccurate of course. It's lost all the\\ncurvature in the solution. So this was the true\\nsolution e to the a*t. And this is the 1 plus\\na delta t to the power, well, t over delta t times. Well, no, this\\nwas only one step, so that would just\\nbe 1 plus a delta t. OK. Where the bad, the unstable\\none, if I just try to draw that, the true solution is e\\nto the a*t, but I take-- I start with that value\\nand the right slope. But I take too big a time\\nstep and I'm below minus 1. So that was a case of\\na too large delta t. OK. Now, I've got one minute left\\nto mention backward Euler. Well, that won't take me long. I'll just change\\nthis to U_(n+1). So I'm evaluating the\\nslope at the new time. So this is now backward\\nEuler, or implicit Euler. OK. So that changes this equation. Oh, let's find out the\\nequation for implicit Euler. OK. I only have one more\\nmoment, I'll just pop it in this little corner. So now, here's backward Euler. All right. You can tell me what backward\\nEuler is going to be. So U_(n+1) minus U_n over\\ndelta t is a*U_(n+1). So let me collect\\nthe n plus 1's. So I have one of them. And then minus a delta t. Right? And well, I bring it\\nover to the left side. And here I just have U_n. OK. So what happens\\nat every step now? I divide-- every step\\nis a division by this. So I could bring this\\ninto the denominator. So U_n is that\\ndivision times U_0. And you see the stability? What's the size of\\nthis growth factor? Remember, I'm thinking\\nof a as a negative. I'm dealing with a stable\\ndifferential equation. And so what's the main point\\nabout this growth factor, this ratio in parentheses? It is? If a is negative, what do\\nI know about that number? Think of a as\\nminus 2, let's say. So then I have 1 over 1 plus 2\\ndelta t, because it's minus a there. And it's going to\\nbe smaller than 1. Right. It's going to be stable. So Euler is actually absolutely\\nstable, backward Euler. Backward Euler has this\\nproperty of A-stability. There is no stability limit\\non negative a, no problem. Or even pure imaginary\\na, no problem. Always stable. So that shows how\\nimplicit methods can be greatly much more\\nstable than explicit, just by comparing forward\\nto backward Euler. But, just to remind\\nyou the price. The price is that this\\nequation has to be solved. Well, it wasn't any\\ntrouble in linear case. In the linear case\\nwe're just inverting a matrix for a linear system. So backward Euler for linear\\nsystem, big linear system, is a matrix inversion, well a\\nmatrix linear system to solve. But for a non-linear\\nproblem, it's serious work. And yet, you have to do the work\\nif the explicit method gives you such a small delta t that\\nit's impossible to go with. OK. Thanks for your patience\\non this first lecture. So, obviously I'm going to have\\none more discussion of ODEs, in which we construct\\nthese methods, see their stability\\nand their convergence. And then we move on to the PDEs.\",\n",
       " \"The probability axioms\\nare the basic rules of probability theory. And they are surprisingly few. But they imply many interesting\\nproperties that we will now explore. First we will see that what you\\nmight think of as missing axioms are actually implied by\\nthe axioms already in place. For example, we have an axiom\\nthat probabilities are non-negative. We will show that probabilities\\nare also less than or equal to 1. We have another axiom that says\\nthat the probability of the entire sample space is 1. We will show a counterpart that\\nthe probability of the empty set is equal to 0. This makes perfect sense. The empty set has no elements,\\nso it is impossible. There is 0 probability that the\\noutcome of the experiment would lie in the empty set. We also have another\\nintuitive property. The probability that an event\\nhappens plus the probability that the vendor does not\\nhappen exhaust all possibilities. And these two probabilities\\ntogether should add to 1. For instance, if the probability\\nof heads is 0.6, then the probability of\\ntails should be 0.4. Finally, we can generalize the\\nadditivity axiom, which was originally given for the case of\\ntwo disjoint events to the case where we're dealing\\nwith the union of several disjoint events. By disjoint here we mean that\\nthe intersection of any two of these events is the empty set. We will prove this for the case\\nof three events and then the argument generalizes for\\nthe case where we're taking the union of k disjoint\\nevents, where k is any finite number. So the intuition of this result\\nis the same as for the case of two events. But we will derive it formally\\nand we will also use it to come up with a way of\\ncalculating the probability of a finite set by simply adding\\nthe probabilities of its individual elements. All of these statements\\nthat we just presented are intuitive. And you do not to really\\nneed to be convinced about their validity. Nevertheless, it is instructive\\nto see how these statements follow from\\nthe axioms that we have put in place. So we will now present the\\narguments based only on the three axioms that we\\nhave available. And in order to be able to refer\\nto these axioms, let us give them some names, call\\nthem axioms A, B, and C. We start as follows. Let us look at the sample space\\nand a subset of that sample space. Call it A. And consider the\\ncomplement of that subset. The complement is the set of\\nall elements that do not belong to the set A. So a set\\ntogether with its complement make up everything, which is\\nthe entire sample space. On the other hand, if an element\\nbelongs to a set A, it does not belong to\\nits complement. So the intersection of a\\nset with its complement is the empty set. Now we argue as follows. We have that the probability of\\nthe entire sample space is equal to 1. This is true by our\\nsecond axiom. Now the sample space, as we just\\ndiscussed, can be written as the union of an event and the\\ncomplement of that event. This is just a set theoretic\\nrelation. And next since a set and its\\ncomplement our disjoint, this means that we can apply the\\nadditivity axiom and write this probability as the sum of\\nthe probability of event A with the probability of the\\ncomplement of A. This is one of the relations that we had\\nclaimed and which we have now established. Based on this relation, we\\ncan also write that the probability of an event A\\nis equal to 1 minus the probability of the complement\\nof that event. And because, by the\\nnon-negativity axiom this quantity here is non-negative, 1\\nminus something non-negative is less than or equal to 1. We're using here the\\nnon-negativity axiom. And we have established another\\nproperty, namely that probabilities are always less\\nthan or equal to 1. Finally, let us note that 1 is\\nthe probability, always, of a set plus the probability of\\na complement of that set. And let us use this property for\\nthe case where the set of interest is the entire\\nsample space. Now, the probability of the\\nentire sample space is itself equal to 1. And what is the complement of\\nthe entire sample space? The complement of the entire\\nsample space consists of all elements that do not belong\\nto the sample space. But since the sample space is\\nsupposed to contain all possible elements,\\nits complement is just the empty set. And from this relation we get\\nthe implication that the probability of the empty\\nset is equal to 0. This establishes yet one more of\\nthe properties that we had just claimed a little earlier. We finally come to the proof of\\nthe generalization of our additivity axiom from the case\\nof two disjoint events to the case of three disjoint events. So we have our sample space. And within that sample\\nspace we have three events, three subsets. And these subsets are disjoint\\nin the sense that any two of those subsets have no\\nelements in common. And we're interested in the\\nprobability of the union of A, B, and C. How do we make progress? We have an additivity axiom in\\nour hands, which applies to the case of the union of\\ntwo disjoint sets. Here we have three of them. But we can do the\\nfollowing trick. We can think of the union of A,\\nB, and C as consisting of the union of this blue set\\nwith that green set. Formally, what we're doing is\\nthat we're expressing the union of these three\\nsets as follows. We form one set by taking the\\nunion of A with B. And we have the other set C. And the overall\\nunion can be thought of as the union of\\nthese two sets. Now since the three sets are\\ndisjoint, this implies that the blue set is disjoint from\\nthe green set and so we can use the additivity axiom here\\nto write this probability as the probability of A union B\\nplus the probability of C. And now we can use the additivity\\naxiom once more since the sets A and B are disjoint to write\\nthe first term as probability of A plus probability of B. We\\ncarry over the last term and we have the relation that\\nwe wanted to prove. This is the proof for the\\ncase of three events. You should be able to follow\\nthis line of proof to write an argument for the case of\\nfour events and so on. And you might want to continue\\nby induction. And eventually you should be\\nable to prove that if the sets A1 up to Ak are disjoint then\\nthe probability of the union of those sets is going to be\\nequal to the sum of their individual probabilities. So this is the generalization\\nto the case where we're dealing with the union of\\nfinitely many disjoint events. A very useful application of\\nthis comes in the case where we want to calculate the\\nprobability of a finite set. So here we have a\\nsample space. And within that sample space\\nwe have some particular elements S1, S2, up\\nto Sk, k of them. And these elements together\\nform a finite set. What can we say about\\nthe probability of this finite set? The idea is to take this finite\\nset that consists of k elements and think of it as the\\nunion of several little sets that contain one\\nelement each. So set theoretically what we're\\ndoing is that we're taking this set with k elements\\nand we write it as the union of a set that contains\\njust S1, a set that contains just the second element\\nS2, and so on, up to the k-th element. We're assuming, of course, that\\nthese elements are all different from each other. So in that case, these sets,\\nthese single element sets, are all disjoint. So using the additivity property\\nfor a union of k disjoint sets, we can write\\nthis as the sum of the probabilities of the different\\nsingle element sets. At this point, it is usual to\\nstart abusing, or rather, simplifying notation\\na little bit. Probabilities are assigned\\nto sets. So here we're talking about the\\nprobability of a set that contains a single element. But intuitively, we can also\\ntalk as just the probability of that particular element and\\nuse this simpler notation. So when using the simpler\\nnotation, we will be talking about the probabilities of\\nindividual elements. Although in terms of formal\\nmathematics, what we really mean is the probability of this\\nevent that's comprised only of a particular element\\nS1 and so on.\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T18:37:28.824078Z",
     "start_time": "2019-11-07T18:37:28.818255Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove newline terms i.e. \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:24.397811Z",
     "start_time": "2019-11-11T20:22:24.154411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. ERIC GRIMSON: Ladies and gentlemen, I\\'d like to get started. My name\\'s Eric Grimson. I have the privilege of serving as MIT\\'S chancellor for academic advancement, you can go look up what that means, and like John I\\'m a former head of course six. This term, with Ana and John, I\\'m going to be splitting the lectures, so I\\'m up to date. OK last time Ana introduced the first of the compound data types, tuples and lists. She showed lots of ways of manipulating them, lots of built in things for manipulating those structures. And the key difference between the two of them was that tuples were immutable, meaning you could not change them, lists were mutable, they could be changed, or mutated. And that led to both some nice power and some opportunities for challenges. And, in particular, she showed you things like aliasing, where you could have two names pointing to the same list structure, and because of that, you could change the contents of one, it would change the appearance of the contents of the other, and that leads to some nice challenges. So the side effects of mutability are one of the things you\\'re going to see, both as a plus and minus, as we go through the course. Today we\\'re going to take a different direction for a little while, we\\'re going to talk about recursion. It Is a powerful and wonderful tool for solving computational problems. We\\'re then going to look at another kind of compound data structure, a dictionary, which is also mutable. And then we\\'re going to put the two pieces together and show how together they actually give you a lot of power for solving some really neat problems very effectively. But I want to start with recursion. Perhaps one of the most mysterious, at least according to programmer\\'s, concepts in computer science, one that leads to lots of really bad computer science jokes, actually all computer science jokes are bad, but these are particularly bad. So let\\'s start with the obvious question, what is recursion? If you go to the ultimate source of knowledge, Wikipedia, you get something that says, in essence, recursion is the process of repeating items in a self-similar way. Well that\\'s really helpful, right? But we\\'re going to see that idea because recursion, as we\\'re going to see in a second, is the idea of taking a problem and reducing it to a smaller version of the same problem, and using that idea to actually tackle a bunch of really interesting problems. But recursion gets used in a lot of places. So it\\'s this idea of using, or repeating, the idea multiple times. So wouldn\\'t it be great if your 3D printer printed 3D printers? And you could just keep doing that all the way along. Or one that\\'s a little more common, it\\'s actually got a wonderful name, it\\'s called mise en abyme, in art, sometimes referred to as the Droste effect, pictures that have inside them a picture of the picture, which has inside them a picture of the picture, and you get the idea. And of course, one of the things you want to think about in recursion is not to have it go on infinitely. And yes there are even light bulb jokes about recursion, if you can\\'t read it, it says, how many twists does it take to screw in a light bulb? And it says, if it\\'s already screwed in, the answer is 0. Otherwise, twist it once, ask me again, add 1 to my answer. And that\\'s actually a nice description of recursion. So let\\'s look at it more seriously. What is recursion? I want to describe it both abstractly, or algorithmically, and semantically or, if you like, in terms of programming. Abstractly, this is a great instance of something often called divide-and-conquer, or sometimes called decrease-and-conquer. And the idea of recursion is, I want to take a problem I\\'m trying to solve and say, how could I reduce it to a simpler version of the same problem, plus some things I know how to do? And then that simpler version, I\\'m going to reduce it again and keep doing that until I get down to a simple case that I can solve directly. That is how we\\'re going to think about designing solutions to problems. Semantically, this is typically going to lead to the case where a program, a definition of function, will refer to itself in its body. It will call itself inside its body. Now, if you remember your high school geometry teacher, she probably would wrap your knuckles, which you\\'re not allowed to do, because in things like geometry you can\\'t define something in terms of itself, right? That\\'s not allowed. In recursion, this is OK. Our definition of a procedure can in its body call itself, so long as I have what I call a base case, a way of stopping that unwinding of the problems, when I get to something I can solve directly. And so what we\\'re going to do is avoid infinite recursion by ensuring that we have at least one or more base cases that are easy to solve. And then the basic idea is I just want to solve the same problem on some simpler input with the idea of using that solution to solve the larger problem. OK, let\\'s look at an example, and to set the stage I\\'m going to go back to something you\\'ve been doing, iterative algorithms. For loops, while loops, they naturally lead to what we would call iterative algorithms, and these algorithms can be described as being captured by a set of state variables, meaning one or more variables that tell us exactly the state of the computation. That\\'s a lot of words, let\\'s look at an example. I know it\\'s trivial, but bear with me. Suppose I want to do integer multiplication, multiply two integers together, and all I have available to me is addition. So a times b is the same as adding a to itself b times. If I\\'m thinking about this iteratively, I could capture this computation with two state variables. One we\\'d just call the iteration number, and it would be something, for example, that starts at b, and each time through the loop reduces 1. One. And it will keep doing that until I\\'ve counted down b times, and I get down to 0. And at the same time, I would have some value of the computation, I might call it result, which starts at 0, first time through adds an a, next time through adds an a, and it just keeps track of how many things have I added up, until I get done. And yeah, I know you could just do mult, but this is trying to get this idea of, how would I do this iteratively. So I might start off with i, saying there are b things still to add, and the result is 1. The first time through the loop, I add an a, reduce i by 1. Next time through the loop, I add in another a, reduce i by 1, and you get the idea. I just walk down it until, eventually, I got to the end of this computation. So we could write code for this, and, actually, it should be pretty straightforward. There it is. Going to call it mult_iter, takes in two arguments a and b, and I\\'m going to capture exactly that process. So notice what I do, I set up result internally as just a little variable I\\'m going to use to accumulate things. And then, there is the iteration, as long as b is greater than 0 what do I do? Add a to result, store it away, reduce b by 1, and I\\'ll keep doing that until b gets down to being equal to 0, in which case I just return the result. OK, simple solution. Now, let\\'s think about this a different way. A times b is just adding a to itself b times, and that\\'s the same as a plus adding a to a itself b minus 1 times. OK, that sounds like leisure to me, that sounds like just playing with words. But it\\'s really important, because what is this? Ah, that\\'s just a times b minus 1, by the definition of the top point. And I know you\\'re totally impressed, but this is actually really cool, because what have I done? I\\'ve taken one problem, this one up here, and I\\'ve reduced it to a simpler version of the same problem, plus some things I know how to do. And how would I solve this? Same trick, that\\'s a times a times b minus 2, I would just unwrap it one more time, and I would just keep doing that until I get down to something I can solve directly, a base case. And that\\'s easy, when b equal to 1, the answer is just a. Or I could do when b is equal to 0 the answer is just 0. And there\\'s code to capture that. Different form, wonderful compact description, what does it say? It says, if I\\'m at the base case, if b is equal to 1, the answer is just a. Otherwise, I\\'m going to solve the same problem with a smaller version and add it to a and return that result. And that\\'s nice, crisp characterization of a problem. Recursive definition that reduces a problem to a simpler version of the same problem. OK, let\\'s look at another example. Classic problem in recursion is to compute factorial, right? n factorial, or n bang if you like, n exclamation point is n times n minus 1, all the way down to 1. So it\\'s the product of all the integers from 1 up to n assuming n is a positive integer. So we can ask the same question if I wanted to solve this recursively what would the base case be? Well, when n is equal to 1, it\\'s just 1. In the recursive case, will n times n minus 1 all the way down to 1, that\\'s the same as n times n minus 1 factorial. So I can easily write out the base case, and I\\'ve got a nice recursive solution to this problem. OK, if you\\'re like me and this is the first time you\\'ve seen it, it feels like I\\'ve taken your head and twisted it about 180 degrees. I\\'m going to take it another 180 degrees because you might be saying, well, wait a minute, how do you know it really stops. How do you know it really terminates the computation? So let\\'s look at it. There is my definition for fact, short for factorial. Fact of 1 is, if n is equal to 1 return 1, otherwise return n times fact of n minus 1. And let\\'s use the tools that Ana talked about, in terms of an environment at a scope, and think about what happens here. So when I read that in or I evaluate that in Python, it creates a definition that binds the name fact to some code, just all of that stuff over here plus the name for the formal parameter, hasn\\'t done anything with it yet. And then I\\'m going to evaluate print a fact of 4. Print needs a value, so it has to get the value of fact of 4, and we know what that does. It looks up fact, there it is, it\\'s procedure definition. So it creates a new frame, a new environment, it calls that procedure, and inside that frame the formal parameter for fact is bound to the value passed in. So n is bound to 4. That frame is scoped by this global frame meaning it\\'s going to inherit things in the global frame. And what does it do? It says, inside of this frame evaluate the body of fact. OK, so it says as n equal to 1? Nope, it\\'s not, it\\'s 4. So in that case, go to the else statement and says, oh, return n times fact of n and n as 4, fact of n minus 1 says I need to return 4 times fact of 3. 4 is easy, multiplication is easy, fact of 3, ah yes, I look up fact. Now I\\'m in this frame, I don\\'t see fact there, but I go up to that frame. There\\'s the definition for fact, and we\\'re going to do the rest of this a little more quickly, what does that do? It creates a new frame called by fact. And the argument passed in for n is n minus 1, that value, right there, of 3. So 3 is now bound to n. Same game, evaluate the body is n equal to 1? No, so in that case, I\\'m going to go to the return statement, it says return 3 times fact of 2. And notice it\\'s only looking at this value of n because that\\'s the frame in which I\\'m in. It never sees that value of n. OK, aren\\'t you glad I didn\\'t do fact of 400? We\\'ve only got two more to go, but you get the idea. Same thing, I need to get fact of 2 is going to call fact again with n bound to 2. Relative that evaluates the body and is not yet equal to 1. That says I\\'m going to the else clause and return 2 times fact of 1. I call fact again, now with n bound to 1, and, fortunately, now that clause is true, and it says return 1. Whoops, sorry, before I do, so there\\'s the base case. And it may seem apparent to you, but this is important, right? I\\'m unwinding this till I get to something that can stop the computation. Now I\\'m simply going to gather the computation up, because it says return 1. Who asked for it? Well that call to fact of 1. So that reduces to return 2 times 1. And who called for that? Fact of 2. That reduces to return a 3 times 2, which reduces to 4 times 6, which reduces to printing out 24. So it unwinds it down to a base case and it stops. A couple of observations, notice how each recursive call creates its own frame, and as a consequence, there\\'s no confusion about which value of n I\\'m using. Also notice, in the other frames, n was not changed. We did not mutate it. So we\\'re literally creating a local scope for that recursive call, which is exactly what we want. Also notice how there was a sense of flow of control in computing fact of something, that reduces to returning n times fact of n minus 1, and that creates a new scope. And that will simply keep unwinding until I get to something that can return a value and then I gather all those frames back up. So there\\'s a natural flow of control here. But most importantly, there\\'s no confusion about which variable I\\'m using when I\\'m looking for a value of n. All right, because this is often a place where things get a little confusing, I want to do one more example. But let me first show you side by side the two different versions of factorial. Actually, I have lied slightly, we didn\\'t show this one earlier but there\\'s factorial if I wanted to do it iteratively. I\\'d set up some initial variable to 1, and then I\\'d just run through a loop. For example, from 1 up to just below n minus 1, or 1 up to n, multiplying it and putting it back into return product. Which one do you like more? You can\\'t say neither you have to pick one. Show of hands, how many of you like this one? Some hesitant ones, how many prefer this one? Yeah, that\\'s my view. I\\'m biased, but I really like the recursive one. It is crisper to look at, you can see what it\\'s doing. I\\'m reducing this problem to a simpler version of that problem. Pick your own version but I would argue that the recursive version is more intuitive to understand. From a programmer\\'s perspective, it\\'s actually often more efficient to write, because I don\\'t have to think about interior variables. Depending on the machine, it may not be as efficient when you call it because in the recursive version I\\'ve got it set up, that set of frames. And some versions of these languages are actually very efficient about it, some of them a little less so. But given the speed of computers today, who cares as long as it actually just does the computation. Right, one more example, how do we really know our recursive code works? Well, we just did a simulation but let\\'s look at it one more way. The iterative version, what can I say about it? Well, I know it\\'s going to terminate because b is initially positive, assuming I gave it an appropriate value. It decreases by 1 every time around this loop, at some point it has to get less than 1, it\\'s going to stop. So I can conclude it\\'s always going to terminate. What about the recursive version? Well, if I call it with b equal to one, I\\'m done. If I call it with b greater than one, again it\\'s going to reduce it by one on the recursive call, which means on each recursive call it\\'s going to reduce and eventually it gets down to a place, assuming I gave it a positive integer, where b is equal to one. So it\\'ll stop, which just good. What we just did was we used the great tool from math, second best department at MIT. Wow, I didn\\'t even get any hisses on that one, John, all right, and I\\'m now in trouble with the head of the math department. So now that I got your attention, and yes, all computer science jokes are bad, and mine are really bad, but I\\'m tenured. You cannot do a damn thing about it. Let\\'s look at mathematical induction which turns out to be a tool that lets us think about programs in a really nice way. You haven\\'t seen this, here\\'s the idea of mathematical induction. If I want to prove a statement, and we refer to it as being indexed on the integers. In other words, it\\'s some mathematical statement that runs over integers. If I want to prove it\\'s true for all values of those integers, mathematically I\\'d do it by simply proving it\\'s true for the smallest value of n typically n is equal to 0 or 1, and then I do an interesting thing. I say I need to prove that if it\\'s true for an arbitrary value of n, I\\'m just going to prove that it\\'s also then true for n plus 1. And if I can do those two things I can then conclude for an infinite number of values of n it\\'s always true. Then we\\'ll relate it back to programming in a second, but let me show you a simple example of this, one that you may have seen. If I had the integers from 0 up to n, or even from 1 up to n, I claim that\\'s the same as n times n plus 1 over 2. So 1, 2, 3, that\\'s 6, right. And that\\'s exactly right, 3 times 4, which is divided by 2, which gives me out 6. How would I prove this? Well, by induction? I need to do the simple cases if n is equal to 0, well then this side is just 0. And that\\'s 0 times 1, which is 0 divided by true. So 0 equals 0, it\\'s true. Now the inductive step. I\\'m going to assume it\\'s true for some k, I should have picked n, but for some k, and then what I need to show is it\\'s true for k plus 1. Well, there\\'s the left hand side, and I want to show that this is equal to that. And I\\'m going do it by using exactly this recursive idea, because what do I know, I know that this sum, in here, I\\'m assuming is true. And so that says that the left hand side, the first portion of it, is just k times k plus 1 over 2, that\\'s the definition of the thing I\\'m assuming is true. To that I\\'m going to add k plus 1. Well, you can do the algebra, right? That\\'s k plus 1 all times k over 2 plus 1, which is k plus 2 over 2. Oh cool, it\\'s exactly that. Having done that, I can now conclude this is true for all values of n. What does it have to do with programming? That\\'s exactly what we\\'re doing when we think about recursive code, right? We\\'re saying, show that it\\'s true for the base case, and then what I\\'m essentially assuming is that, if it works for values smaller than b, then does the code return the right answer for b? And the answer is, absolutely it does, and I\\'m using induction to deduce that, in fact, my code does the right thing. Why am I torturing you with this? Because this is the way I want you to think about recursion. When I\\'m going to break a problem down into a smaller version of the same problem, I can assume that the smaller version gives the answer. All I have to do is make sure that what I combined together gives me out the right result. OK, you may be wondering what I\\'m doing with these wonderful high tech toys down here. I want to show you another example of recursion. So far we\\'ve seen simple things that have just had one base case, and this is a mythical story called The towers of Hanoi and this story, as I heard it, is there\\'s a temporal somewhere in Hanoi with three tall spikes and 64 jewel-encrusted golden disks all of a different size. They all started out on one spike with the property that they were ordered from smallest down to largest. And there are priests in this temple who are moving the disks one at a time, one per second, and their goal is to move the entire stack from one spike to another spike. And when they do nirvana is achieved and we all get a really great life. We\\'ll talk separately about how long is this going to take because there\\'s one trick to it. They can never cover a smaller disk with a larger disk as they\\'re doing it, so they\\'ve got a third disk as a temporary thing. And I want to show you how to solve this problem because you\\'re going to write code with my help in a second, or I\\'m going to write code with your help in a second to solve it. So let\\'s look at it, so watch carefully, moving a disk of size one, well that\\'s pretty easy, right? Moving a disk of size two, we\\'ll just put this one on the spare one while you move it over so you don\\'t cover it up. That\\'s easy. Moving a disk of size three, you\\'ve got be a little more careful, you can\\'t cover up a smaller one with a larger one, so you have to really think about where you\\'re putting it. It would help with these things didn\\'t juggle and there you go, you got it done. All right, you\\'re watching? You\\'ve got to do four. To do four, again, you\\'ve got to be really careful not to cover things up as you do this. You want to get the bottom one eventually exposed, and so are you going to pull that one over there. If you do the pattern really well, you won\\'t notice if I make a serious mistake as I\\'m doing this, which I just did. But I\\'m going to recover from that and do it that way to put this one over here, and that one goes there, and if I did this in Harvard Square I could make money. There you go, right? OK, got the solution? See how to solve it? Could you write code for this? Eh, maybe not. That\\'s on the quiz, thanks, John, don\\'t tell them on the quiz, damn. All right, I want to claim though that in fact there\\'s a beautiful recursive solution. And here\\'s the way to think about it recursively. I want to move a tower of size n, I\\'m going to assume I can move smaller towers and then it\\'s really easy. What do I do, I take a stack of size n minus 1, I move it onto the spare one, I move the bottom one over, and then I move a stack of size n minus 1 to there, beautiful, recursive solution. And how do I move the smaller stack? Just the same way, I just unwind it, simple, and, in fact, the code follows exactly that. OK, I do a little [INAUDIBLE] domain up here to try and get your attention, but notice by doing that what did I do? I asked you to think about it recursively, the recursive solution, when you see it, is in fact very straightforward, and there\\'s the code. Dead trivial, well, that trivial is unfair, but it\\'s very simple. Right? I simply write something, so let me describe it, I need to say how big of tower am I moving and I\\'m going to label the three stacks a from, a to, and a spare. I have a little procedure that just prints out the move for me, and then what\\'s the solution? If it\\'s just a stack of size one, just print the move, take it to from-- from from to to. Otherwise, move a tower of size n minus 1 from the from spot to the spare spot, then move what\\'s left of tower size one from to two, and then take that thing are stuck on spare and move it over to two, and I\\'m done. In that code that we handed out, you\\'ll see this code, you can run it. I\\'m not going to print it out because, if I did, you are just going to say, OK, it looks like it does the right kind of thing. Look at the code, nice and easy, and that\\'s what we like you to do when you\\'re given a problem. We asked you to think about recursively. How do I solve this with a smaller version of the same problem? And then how do I use that to build the larger solution? This case is a little different. You could argue that this is not really a recursive call here, it\\'s just moving the bottom one, I could have done that directly. But I\\'ve got two recursive calls in the body here. I have to move a smaller stack twice. We\\'re going to come back to that in a little bit. Let me show you one other example of recursion that runs a little bit differently. In this case it\\'s going to have multiple base cases and this is another very old problem, it\\'s called the Fibonacci numbers. It\\'s based on something from several centuries ago when a gentleman, named Leonardo of Pisa, also known as Fibonacci, asked the following challenge. He said, I\\'m going to put a newborn pair of rabbits, one male and one female, into an enclosure, a pan of some sort. And the rabbits have the following properties, they mate at age one month, so they take a month to mature. After a one month gestation period, they produce another pair of rabbits, a male and a female, and he says I\\'m going to assume that the rabbits never die. So each month mature females are going to produce another pair. And his question was, how many female rabbits are there at the end of a year, or two years, or three years? The idea is, I start off with two immature rabbits, after one month they\\'ve matured, which means after another month, they will have produced a new pair. After another month, that mature pair has produced another pair, and the immature pair has matured. Which means, after another month, those two mature pairs are going to produce offspring, and that immature pair has matured. And you get the idea, and after several months, you get to Australia. You can also see this is going to be interesting to think about how do you compute this, but what I want you to see is the recursive solution to it. So how could we capture this? Well here\\'s another way of thinking about it, after the first month, and I know we\\'re going to do this funny thing, we\\'re going to index it 0, so call it month 0. There is 1 female which is immature. After the second month, that female is mature and now pregnant which means after the third month it has produced an offspring. And more generally, that the n-th month, after we get past the first few cases, what do we have? Any female that was there two months ago has produced an offspring. Because it\\'s taken at least one month to mature, if it hasn\\'t already been mature, and then it\\'s going to produce an offspring. And any female that was around last month is still around because they never die off. So this is a little different. This is now the number of females at month n is the number of females T month n minus 1, plus the number of females and month n minus 2. So two recursive calls, but with different arguments. Different from towers of Hanoi, where there were two recursive calls, but with the same sized problem. So now I need two base cases, one for when n is equal to 0, one for when n is equal to 1. And then I\\'ve got that recursive case, so there\\'s a nice little piece of code. Fibonacci, I\\'m going to assume x is an integer greater than or equal to 0. I\\'m going to return Fibonacci of x. And you can see now it says, if either x is equal to 0 or x is equal to 1 I\\'m going to return 1, otherwise, reduce it to two simpler versions of the problem but with different arguments, and I add them up. OK, and if we go look at this, we can actually run this, if I can find my code. Which is right there, and I\\'m just going to, so we can, for example, check it by saying fib of 0. I just hit a bug which I don\\'t see. Let me try it again. I\\'ll try it one more time with fib of 0. Darn, it\\'s wrong, let me try it. I\\'ve got two different versions of fib in here, that\\'s what I\\'ve got going on. So let me do it again, let\\'s do fib of 1. There we go, fib of 2 which is 2, fib of 3 just three, and fib of 4 which should add the previous two, which gives me 5. There we go. Sorry about that, I had two versions of fib in my file, which is why it complained at me. And which is why you should always read the error instructions because it tells you what you did wrong. Let\\'s go on and look at one more example of doing recursion, and we\\'re going to do dictionaries, and then we\\'re going to pull it all together. So far we\\'ve been doing recursion on numerical things, we can do it on non-numerical things. So a nice way of thinking about this is, how would I tell if a string of characters is a palindrome? Meaning it reads the same backwards and forwards. Probably the most famous palindrome is attributed to Napoleon \"Able was I ere I saw Elba.\" Given that Napoleon was French, I really doubt he said \"Able was I ere I saw Elba,\" but it\\'s a great palindrome. Or another one attributed to Anne Michaels \"Are we not drawn we few drawn onward to a new era,\" reads the same backwards and forwards. It\\'s fun to think about how do you create the palindromes. I want to write code to solve this. Again, I want to think about it recursively, so here\\'s what I\\'m going to do. I\\'m first going to take a string of characters, reduce them all to lowercase, and strip out spaces and punctuation. I just want the characters. And once I got that, I want to say, is that string, that list of characters or that collection of characters as I should say, a palindrome? And I\\'m going to think about it recursively, and that\\'s actually pretty easy. If it\\'s either 0 or 1 long, it\\'s a palindrome. Otherwise you could think about having an index at each end of this thing and sort of counting into the middle, but it\\'s much easier to say take the two at the end, if they\\'re the same, then check to see what\\'s left in the middle is a palindrome, and if those two properties are true, I\\'m done. And notice what I just did I nicely reduced a bigger problem to a slightly smaller problem. It\\'s exactly what I want to do. OK? So it says to check is this, I\\'m going to reduce it to just the string of characters, and then I\\'m going to check if that\\'s a palindrome by pulling those two off and checking to see they\\'re the same, and then checking to see if the middle is itself a palindrome. How would I write it? I\\'m going to create a procedure up here, isPalindrome. I\\'m going to have inside of it two internal procedures that do the work for me. The first one is simply going to reduce this to all lowercase with no spaces. And notice what I can do because s is a string of characters. I can use the built in string method lower, so there\\'s that dot notation, s.lower. It says. apply the method lower to a string. I need an open and close per end to actually call that procedure, and that will mutate s to just be all lowercase. And then I\\'m going to run a little loop, I\\'ll set up answer or ans to be an empty string, and then, for everything inside that mutated string, I\\'ll simply say, if it\\'s inside this string, if it\\'s a letter, add it into answer. If it\\'s a space or comma or something else I\\'ll ignore it, and when I\\'m done just return answer, strips it down to lowercase. And then I\\'m going to pass that into isPal which simply says, if this is either 0 or 1 long, it\\'s a palindrome, returned true. Otherwise, check to see that the first and last element of the string are the same, notice the indexing to get into the last element, and similarly just slice into the string, ignoring the first and last element, and ask is that a palindrome. And then just call it, and that will do it. And again there\\'s a nice example of that in the code I\\'m not going to run it, I\\'ll let you just go look at it, but it will actually pull out something that checks, is this a palindrome. Notice again, what I\\'m doing here. I\\'m doing divide-and-conquer. I\\'m taking a problem reducing it, I keep saying this, to a simpler version of the same problem. Keep unwinding it till I get down to something I can solve directly, my base case and I\\'m done. And that\\'s really the heart of thinking about recursive solutions to problems. I would hope that one of the things I remember, besides my really lousy patter up here, is the idea of Towers of Hanoi, because to me it\\'s one of the nicest examples of a problem that would be hard to solve iteratively, but when you see the recursive solution is pretty straightforward. Keep that in mind as you think about doing recursion. OK, let\\'s switch gears, and let\\'s talk very briefly about another kind of data type called a dictionary. And the idea of a dictionary I\\'m going to motivate with a simple example. There\\'s a quiz coming up on Thursday. I know you don\\'t want to hear that, but there is, which means we\\'re going to be recording grades. And so imagine I wanted to build a little database just to keep track of grades of students. So one of the ways I could do it, I could create a list with the names of the students, I could create another list with their grades, and a third list with the actual subject or course from which they got that great. I keep a separate list for each one of them, keep them of the same length, and in essence, what I\\'m doing here is I\\'m storing information at the same index in each list. So Ana, who\\'s going to have to take the class again, gets a B, John, who\\'s created the class, gets an A plus, Sorry Ana, John\\'s had a longer time at it. All right, bad jokes aside, what I\\'m doing is I can imagine just creating lists. I could create lists of lists, but a simple way is to do lists where basically at each index I\\'ve got associated information. It\\'s a simple way to deal with it. Getting a grade out takes a little bit of work because if I want to get the grade associated with a particular student, what would I do? I would go into the name list and use the method index, which you\\'ve seen before, again notice the dot notation it says, this is a list, use the index method, call it on student, and whatever the value of student is, it will find that in the list, return the index at that point, and then I can use that to go in and get the grade in the course and return something out. Simple way to do it but a little ugly, right, because among other things, I\\'ve got things stored in different places in the list. I\\'ve got to think about if I\\'m going to add something to the list I\\'ve got to put them in the same spot in the list. I\\'ve got to remember to always index using integers which is what we know how to do with lists, at least so far. It would be nice if I had a better way to do it, and that\\'s exactly what a dictionary is going to provide for me. So rather than indexing on integers I\\'d like to index directly on the item of interest. I\\'d like to say where\\'s Ana\\'s record and find that in one data structure. And so, whereas a list is indexed by integers, and has elements associated with it, a dictionary is going to combine a key, or if you like, a name of some sort, with an actual value. And we\\'re going to index just by the name or the label as we go into it. So let me show you some examples. First of all, to create a dictionary I use curly braces, open closed curly brace, so an empty dictionary would be simply that call. If I want to create an actual dictionary, before I insert things into it, I use a little bit of a funky notation. It is a key or a label, a colon, and then a value, in this case the string Ana and the string b, followed by a comma which separates it from the next pairing of a key and a label, or a key and a value, and so on. So if I do this what it does in my dictionary is it creates pairings of those labels with the values I associated with them. OK, these are pretty simple, but in fact, there\\'s lots of nice things we can do with it. So once we\\'ve got them indexing now is similar to a list but not done by a number, it\\'s done by value. So if that\\'s my key, I can say, what\\'s John\\'s grade, notice the call, it\\'s grades, which is in my dictionary, open close square brackets, with the label John. And what it does, it goes in and finds that in the dictionary, returns the value associated with it. If I ask for something not in the dictionary, it\\'s going to give me a key error. Other things we can do with dictionaries, we can add entries just like we would do with lists. Grades as a dictionary, in open and closed square brackets, I put in a new label and a value, and that adds that to the dictionary. I can test if something\\'s in the dictionary by simply saying, is this label in grades, and it simply checks all of the labels or the keys for the dictionary to see if it\\'s there, and if it\\'s not returns false. I can remove entries, del, something we\\'ve seen before, a very generic thing. It will delete something, and in this case, it says, in the dictionary grades, find the entry associated with that key, sorry, Ana, you\\'re about to be flushed, remove it. She\\'s only getting a b in the class and she teaches it. We\\'ve got to do something about this, right? So I can add things, I can delete things, I can test if things are there. Let me show you a couple of other things about dictionaries. I can ask for all of the keys in the dictionary. Notice the format, there is that dot notation, grades as a dictionary, it says, use the keys method associated with this data structure dictionaries. Open close actually calls it, and it gives me back a collection of all the keys in some arbitrary order. I\\'m going to use a funny term here which I\\'m not certain we\\'ve seen so far. It returns something we call an iterable, it\\'s like range. Think of it as giving us back the equivalent of a list, it\\'s not actually a list, but it\\'s something we can walk down. Which is exactly why I can then say, is something in a dictionary, because it returns this set of keys, and I can test to see something\\'s in there. I can similarly get all of the values if I wanted to look at them, giving us out two iterables. Here are the key things to keep in mind about dictionaries. The values can be anything, any type, mutable, immutable. They could be duplicates. That\\'d actually makes sense, I could have the same value associated, for example, the same grade associated with different people, that\\'s perfectly fine. The values could be lists, they could be other data structures, they could even be other dictionaries. They can be anything, which is great. The keys, the first part of it are a little more structure. They need to be unique. Well duh, that make sense. If I have that same key in two places in the dictionary, when I go to look it up, how am I going to know which one I want? So it needs to be unique, and they also need to be immutable, which also makes sense. If I\\'m storing something in a key in the dictionary, and I can go and change the value of the key, how am I going to remember what I was looking for? So they can only be things like ints, floats, strings, tuples, Booleans. I don\\'t recommend using floats because you need to make sure it\\'s exactly the same float and that\\'s sometimes a little bit challenging, but nonetheless, you can have any immutable type as your key. And notice that there\\'s no order to the keys or the values. They are simply stored arbitrarily by the Python as it puts them in. So if I compare these two, lists or ordered sequences indexed by integers, I look them up by integer index, and the indices have to have an order as a consequence. Dictionaries are this nice generalization, arbitrarily match keys to values. I simply look up one item by looking up things under the appropriate key. All I require is that the keys have to be immutable. OK, I want to do two last things I\\'ve got seven minutes to go here. I want to show you an example of using dictionaries, and I\\'m going to do this with a little bit more interesting, I hope, example. I want to analyze song lyrics. Now I\\'m going to show you, you can already tell the difference between my age and Ana\\'s age. She used Taylor Swift and Justin Bieber. I\\'m going to use The Beatles. That\\'s more my generation. Most of you have never heard of The Beatles unless you watched Shining Time Station where you saw Ringo Starr, right? OK, what I\\'m going to do is, I want to write a little set of procedures that record the frequencies of words in a song lyric. So I\\'m going to match strings, or words, to integers. How many times did that word appear in the song lyric? And then I want to ask, can I easily figure out which words occur most often, and how many times. Then I\\'m going to gather them together to see what are the most common words in here. And I\\'m going to do that where I\\'m going to let a user say, I want every word that appears more than some number of times. It\\'s a simple example, but I want you to see how a mutation of the dictionary gives you a really powerful tool for solving this problem. So let\\'s write the code to do that. It\\'s also in the handout, here we go. Lyrics to frequency\\'s, lyrics is just a list of words, strings. So I\\'m going to set up an empty dictionary, there\\'s that open close curly brace, and here\\'s what I want to do. I\\'m going to walk through all the words in lyrics. You\\'ve seen this before, this is looping over every word in lyrics. Ah, notice what I\\'m going to do. I\\'m going to simply say-- so the first part is, I can easily iterate over the list, --but now I\\'m going to say, if the word is in the dictionary, and because the dictionary is iterable, it\\'s simply going to give me back all of the keys, it\\'s simply going to say, in this case, if it\\'s in the dictionary, it\\'s already there, I\\'ve got some value associated with it, get the value out, add 1 to it, put it back in. If it\\'s not already in the dictionary, this is the first time I\\'ve seen it, just store it into the dictionary. And when I\\'m done just return the dictionary. OK? So I\\'m going to, if I can do this right with my Python, show you an example of this. I have put in one of the great classic Beatles songs, you might recognize it right there. Mostly because it\\'s got a whole lot of repetitions of things. So she loves you yeah, yeah, yeah, yeah. Sorry, actually they sing it better than I just did it sarcastically. Sorry about that, but I got she loves you there, and here\\'s my code up here, lyrics to frequency. So let\\'s see what happens if we call it. And we say lyrics to frequencies she loves you. And it would help if I can type, all right, we\\'ll try it one more time, lyrics to frequency\\'s, she loves you. Cool, this gave me back a dictionary, you can see the curly braces, and there are all the words that appear in there and the number of times that they appear. What\\'s the order? You don\\'t care. You don\\'t know. What we want to do is to think about how can we analyze this, so let\\'s go back and look at the last piece of this. Which is, OK, I can convert lyrics to frequencies. So here\\'s the next thing I want to do, how do I find the most common words? Well, here\\'s what I\\'m going to do, frequencies is the dictionary, something that I just pulled out. So I can use the values method on it which returns and iterable, as I said earlier, again notice the open close because I got to call it. That gives me back an iterable that has all of the frequencies inside of there, because it\\'s an iterable, I can use max on it, and it will take that editable and give me back the biggest value. I\\'m going to call that best, I\\'m going to set up words to be an empty list, and then I\\'m just going to walk through all of the entries in the dictionary saying, if the value at that entry is equal to best add that entry into words, just append it onto the end of the list. And when I\\'m done all of that loop, I\\'m just going to return a tuple of both the collections of words that period that many times and how often they appeared. I\\'m going to show you an example in a second, but notice I\\'m simply using the properties of the dictionary. The last thing I want to do then is say, I want to see how often the words appear. So I\\'m going to give it a dictionary and a minimum number of times. And here I\\'m going to set result up to be an empty list, I\\'m going to create a flag called false, it\\'s going to keep track of when I\\'m done. And as long as I\\'m not yet done, I\\'ll call that previous procedure that\\'s going to give me back the most common words and how often they appeared. I check and remember it was a tuple, how often do they appear, if it\\'s bigger than the thing I\\'m looking for, I\\'ll add that into my result. And then the best part is, I\\'m now going to walk through all the words that appeared that many times, and just delete them from the dictionary. I can mutate the dictionary. And by doing that, I can go back around and do this again, and it will pull out how many times has this appeared and keep doing it. When I can go all the way through that, if I can\\'t find any more, I\\'ll set the flag to true which means it will drop out of here and return the result. I\\'m going to let you run this yourself, if you do that, you\\'ll find that it comes up with, not surprisingly, I think yeah is the most common one and she loves you, followed by loves and a few others. What I want you to see here is how the dictionary captured the pieces we wanted to. Very last one, there\\'s Fibonacci, as we called it before. It\\'s actually incredibly inefficient, because if I call it, I have to do all the sub calls until I get down to the base case, which is OK. But notice, every other thing I do here, I\\'ve actually computed those values. I\\'m wasting measures, or wasting time, it\\'s not so bad with fib of 5, but if this is fib of 20, almost everything on the right hand side of this tree I\\'ve already computed once. That means fibs very inefficient. I can improve it by using a dictionary, very handy tool. I\\'m going to call fib not only with a value of n, but a dictionary which initially I\\'m going to initialized to the base cases. And notice what I do, I\\'m going to say if I\\'ve already computed this, just return the value in the dictionary. If I haven\\'t, go ahead and do the computation, store it in the dictionary at that point, and return the answer. Different way of thinking about it, and the reason this is really nice is a method called memoization, is if I call fib of 34 the standard way it takes 11 million plus recursive calls to get the answer out. It takes a long time. I\\'ve given you some code for it, you can try it and see how long it takes. Using the dictionary to keep track of intermediate values, 65 calls. And if you try it, you\\'ll see the difference in speed as you run this. So dictionaries are valuable, not only for just storing away data, they\\'re valuable on procedure calls when those intermediate values are not going to change. What you\\'re going to see as we go along is we\\'re going to use exactly these ideas, using dictionaries to capture information, but especially using recursion to break bigger problems down into smaller versions of the same problem, to use that as a tool for solving what turn out to be really complex things. And with that, we\\'ll see you next time.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_n_0 = re.sub('[%s]' % re.escape(\"\\n\"), ' ', test[0][0])\n",
    "test_n_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:24.727924Z",
     "start_time": "2019-11-11T20:22:24.401507Z"
    }
   },
   "outputs": [],
   "source": [
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### investigate and remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:25.785521Z",
     "start_time": "2019-11-11T20:22:24.737121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION 1: Standardize  \n",
    "FUNCTION 2: Vectorize  \n",
    "FUNCTION 3: Reduce Dimensions  \n",
    "FUNCTION 4: Cluster/Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1: Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:26.732639Z",
     "start_time": "2019-11-11T20:22:25.788688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:26.782618Z",
     "start_time": "2019-11-11T20:22:26.746459Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    # indicates things to be removed\n",
    "    remove = ',.(--)?'\n",
    "    # replace '\\n' with whitespace\n",
    "    repl = lambda x: re.sub('\\n', ' ', x)\n",
    "    # remove indicated items with regex\n",
    "    rem = lambda x: re.sub('[%s]' % re.escape(remove), '', x.lower())\n",
    "    \n",
    "    # apply \"repl\" and \"rem\" functions to documents\n",
    "    df['text'] = df.text.map(repl).map(rem)\n",
    "    # also replace \"taylor's\" with \"taylor\"\n",
    "    df['text']= df['text'].str.replace(\"taylor's\", \"taylor\", case = False) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:29.384565Z",
     "start_time": "2019-11-11T20:22:26.789825Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mvp_s = standardize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:29.403435Z",
     "start_time": "2019-11-11T20:22:29.388140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the following content is provided under a creative commons license your support will help mit opencourseware continue to offer high quality educational resources for free to make a donation or to view additional materials from hundreds of mit courses visit mit opencourseware at ocwmitedu professor: so professor jerison is relaxing in sunny london ontario today and sent me in as his substitute again i'm glad to the here and see you all again so our agenda today: he said that he'd already talked about power series and taylor formula i guess on last week right on friday so i'm going to go a little further with that and show you some examples show you some applications and then i have this course evaluation survey that i'll hand out in the last 10 minutes or so of the class i also have this handout that he made that says 1801 end of term 2007 if you didn't pick this up coming in grab it going out people tend not to pick it up when they walk in i see so grab this when you're going out there's some things missing from it he has not decided when his office hours will be at the end of term he will have them just hasn't decided when so check the website for that information and we're looking forward to the final exam which is uh  aren't we any questions about this technical stuff all right let's talk about power series for a little bit so i thought i should review for you what the story with power series is ok could i have your attention please so power series is a way of writing a function as a sum of integral powers of x these a_0 a_1 and so on are numbers an example of a power series is a polynomial not to be forgotten one type of power series is one which goes on for a finite number of terms and then ends so that all of the other all the higher a_i's are all 0 this is a perfectly good example of a power series; it's a very special kind of power series and part of what i want to tell you today is that power series behave almost exactly like polynomials there's just one thing that you have to be careful about when you're using power series that isn't a concern for polynomials and i'll show you what that is in a minute so you should think of them as generalized polynomials the one thing that you have to be careful about is that there is a number so one caution there's a number which i'll call r where r can be between 0 and it can also be infinity it's a number between 0 and infinity inclusive so that when the absolute value of x is less than r so when x is smaller than r in size the sum converges this sum that sum converges to a finite value and when x is bigger than r in absolute value the sum diverges this r is called the radius of convergence so we'll see some examples of what the radius of convergence is in various powers series as well and how you find it also but let me go on and give you a few more of the properties about power series which i think that professor jerison talked about earlier so one of them is there's a radius of convergence here's another one if you're inside of the radius convergence then the function has all its derivatives has all its derivatives just like a polynomial does you can differentiate it over and over again and in terms of those derivatives the number a_n in the power series can be expressed in terms of the value of the derivative at 0 and this is called taylor formula so i'm saying that inside of this radius of convergence the function that we're looking at this fx can be written as the value of the function at 0 that's a_0 plus the value of the derivative this bracket n means you take the derivative n times so when n is 1 you take the derivative once at 0 divided by 1! which is ! and multiply it by x that's the linear term in the power series and then the quadratic term is you take the second derivative remember to divide by 2! which is 2 multiply that by x^2 and so on out so in terms so the coefficients in the power series just record the values of the derivatives of the function at x = 0 they can be computed that way also let's see i think that's the end of my summary of things that he talked about i think he did one example and i'll repeat that example of a power series this example wasn't due to david jerison; it was due to leonard euler it's the example of where the function is the exponential function e^x so let's see let's compute what i will just repeat for you the computation of the power series for e^x just because it's such an important thing to do so in order to do that i have to know what the derivative of e^x is and what the second derivative of e^x is and so on because that comes into the taylor formula for the coefficients but we know what the derivative of e^x is it's just e^x again and it's that way all the way down all the derivatives are e^x over and over again so when i evaluate this at x = 0 well the value of e^x is 1 the value of e^x is 1 at x = 0 you get a value of 1 all the way down so all these derivatives at 0 have the value 1 and now when i plug into this formula i find e^x is 1 plus 1*x plus 1/2! x^2 plus 1/3! x^3 plus and so on so all of these numbers are 1 and all you wind up with is the factorials in the denominators that's the power series for e^x this was a discovery of leonhard euler in 1740 or something yes ma'am audience: when you're writing out the power series how far do you have to write it out professor: how far do you have to write the power series before it becomes well defined before it's a satisfactory solution to an exam problem i suppose is another way to phrase the question until you can see what the pattern is i can see what the pattern is is there anyone who's in doubt about what the next term might be some people would tell you that you have to write the summation convention thing don't believe them if you right out enough terms to make it clear that's good enough ok is that an answer for you audience: yes thank you professor: ok so that's a basic example let's do another basic example of a power series oh yes and by the way whenever you write out a power series you should say what the radius of convergence is and for now i will just to tell you that the radius of convergence of this power series is infinity; that is this sum always converges for any value of x i'll say a little more about that in a few minutes yeah audience: so which functions can be written as power series professor: which functions can be written as power series that's an excellent question any function that has a reasonable expression can be written as a power series i'm not giving you a very good answer because the true answer is a little bit complicated but any of the functions that occur in calculus like sines cosines tangents they all have power series expansions ok we'll see more examples let's do another example here's another example i guess this was example one so this example i think was due to newton not euler let's find the power series expansion of this function: 1/1+x well i think that somewhere along the line you learned about the geometric series which tells you that which tells you what the answer to this is and i'll just write it out the geometric series tells you that this function can be written as an alternating sum of powers of x you may wonder where these minuses came from well if you really think about the geometric series as you probably remembered there was a minus sign here and that gets replaced by these minus signs i think maybe jerison talked about this also anyway here's another basic example remember what the graph of this function looks like when x = 1 then there's a little problem here because the denominator becomes 0 so the graph has a pole there it goes up to infinity at x = 1 and that's an indication that the radius of convergence is not infinity because if you try to converge to this infinite number by putting in x = 1 here you'll have a big problem in fact you see when you put in x = 1 you keep getting 1 in every term and it gets bigger and bigger and does not converge in this example the radius of convergence is 1 ok so let's do a new example now oh and by the way i should say you can calculate these numbers using taylor formula if you haven't seen it check it out calculate the iterated derivatives of this function and plug in x = 0 and see that you get +1 1 +1 1 and so on yes sir audience: for the radius of convergence i see that if you do 1 it'll blow out if you put in 1 though it seems like it would be fine professor: the questions is i can see that there's a problem at x = 1 why is there also a problem at x = 1 where the graph is perfectly smooth and innocuous and finite that's another excellent question the problem is that if you go off to a radius of 1 in any direction and there's a problem that's it that's what the radius of convergence is here what does happen if i put an x = +1 so let's look at the partial sums do x = +1 in your mind here so i'll get a partial sum 1 then 0 and then 1 and then 0 and then 1 so even though it doesn't go up to infinity it still does not converge audience: and anything in between professor: any of these other things will also fail to converge in this example well that's the only two real numbers at the edge right ok let's do a different example now how about a trig function the sine of x i'm going to compute the power series expansion for sinx and i'm going to do it using taylor formula so taylor formula says that i have to start computing derivatives of sinx sounds like it's going to be a lot of work let's see the derivative of the sine is the cosine and the derivative of the cosine that's the second derivative of the sine is what remember the minus it's sinx ok now i want to take the third derivative of the sine which is the derivative of sine prime prime so it's the derivative of this and we just decided the derivative of sine is cosine so i get cosine but i have this minus sign in front and now i want to differentiate again so the cosine becomes a minus sine and that sign cancels with this minus sign to give me sinx you follow that it's a lot of 1's canceling out there so all of a sudden i'm right back where i started; these two are the same and the pattern will now repeat forever and ever higher and higher derivatives of sines are just plus or minus sines and cosines now taylor formula says i should now substitute x = 0 into this and see what happens so let's do that when x is equals to 0 the sine is 0 and the cosine is 1 the sine is 0 so minus 0 is also 0 the cosine is 1 but now there's a minus one and now i'm back where i started and so the pattern will repeat ok so the values of the derivatives are all zeros and plus and minus ones and they go through that pattern fourfold periodicity over and over again and so we can write out what sinx is using taylor formula using this formula so i put in the value at 0 which is 0 then i put in the derivative which is 1 multiplied by x then i have the second derivative divided by 2! but the second derivative at 0 is 0 so i'm going to drop that term out now i have the third derivative which is 1 and remember the 3! in the denominator that's the coefficient of x^3 what's the fourth derivative well here we are it's on the board it's 0 so i drop that term out go up to the fifth term the fifth power of x its derivative is now 1 we've gone through the pattern we're back at +1 as the value of the iterated derivative so now i get 1/5! x^5 now you tell me have we done enough terms to see what the pattern is i guess the next term will be a 1/7! x^7 and so on let me write this out again just so we have it x^3 / 3! so it's x minus x^3 / 3! plus x^5 / 5! you guessed it and so on that's the power series expansion for the sine of x ok and so the sign alternate and these denominators get very big don't they exponentials grow very fast let me make a remark r is infinity here the radius of convergence of this power series again is infinity and let me just say why the reason is that the general term is going to be like x^2n+1 / 2n+1! an odd number i can write as 2n + 1 and what i want to say is that the size of this what happens to the size of this as n goes to infinity so let's just think about this for a fixed x let's fix the number x look at powers of x and think about the size of this expression when n gets to be large so let's just do that for a second so x^2n+1 / 2n+1! i can write out like this it's x / 1 times x / 2  sorry  times x / 3 times x / 2n+1 i've multiplied x by itself 2n+1 times in the numerator and i've multiplied the numbers 1 2 3 4 and so on by each other in the denominator and that gives me the factorial so i've just written this out like this now x is fixed so maybe it's a million ok it's big but fixed what happens to these numbers well at first they're pretty big this is 1000000 / 2 this is 1000000 / 3 but when n gets to be maybe if n is 1000000 then this is about 1/2 if n is a billion then this is about 1/2000 right the denominators keep getting bigger and bigger but the numerators stay the same; they're always x so when i take the product if i go far enough out i'm going to be multiplying by very very small numbers and more and more of them and so no matter what x is these numbers will converge to 0 they'll get smaller and smaller as x gets to be bigger that's the sign that x is inside of the radius of convergence this is the sign for you that this series converges for that value of x and because i could do this for any x this works this convergence to 0 for any fixed x that's what tells you that you can take that the radius of convergence is infinity because in the formula in the fact in this property that the radius of convergence talks about if r is equal to infinity this is no condition on x every number is less than infinity in absolute value so if this convergence to 0 of the general term works for every x then radius of convergence is infinity well that was kind of fast but i think that you've heard something about that earlier as well anyway so we've got the sine function a new function with its own power series it's a way of computing sinx if you take enough terms you'll get a good evaluation of sinx for any x this tells you a lot about the function sinx but not everything at all for example from this formula it's very hard to see that the sine of x is periodic it's not obvious at all somewhere hidden away in this expression is the number pi the half of the period but that's not clear from the power series at all so the power series are very good for some things but they hide other properties of functions well so i want to spend a few minutes telling you about what you can do with a power series once you have one to get new power series so new power series from old and this is also called operations on power series so what are the things that we can do to a power series well one of the things you can do is multiply so for example what if i want to compute a power series for x sinx well i have a power series for sinx i just did it how about a power series for x actually i did that here too the function x is a very simple polynomial it's a polynomial where that's 0 a_1 is 1 and all the other coefficients are 0 so x itself is a power series a very simple one sinx is a powers series and what i want to encourage you to do is treat power series just like polynomials and multiply them together we'll see other operations too so to compute the power series for x sinx of i just take this one and multiply it by x so let's see if i can do that right it distributes through: x^2 minus x^4 / 3! plus x^6 / 5! and so on and again the radius of convergence is going to be the smaller of the two radii of convergence here so it's r equals infinity in this case ok you can multiply power series together it can be a pain if the power series are very long but if one of them is x it's pretty simple ok that's one thing i can do notice something by the way you know that even and odd functions so sine is an odd function x is an odd function the product of two odd functions is an even function and that's reflected in the fact that all the powers that occur in the power series are even for an odd function like the sine all the powers that occur are odd powers of x that's always true ok we can multiply i can also differentiate so let's just do a case of that and use the process of differentiation to find out what the power series for cosx is by writing the cosx as the derivative of the sine and differentiating term by term so i'll take this expression for the power series of the sine and differentiate it term by term and i'll get the power series for cosine so let's see the derivative of x is one now the derivative of x^3 is 3x^2 and then there's a 3! in the denominator and the derivative of x^5 5x^4 and there's a 5! in the denominator and so on and so on and now some cancellation happens so this is 1 minus well the 3 cancels with the last factor in this 3 factorial and leaves you with 2! and the 5 cancels with the last factor in the 5 factorial and leaves you with a 4! in the denominator and so there you go there's the power series expansion for the cosine it's got all even powers of x they alternate and you have factorials in the denominator and of course you could derive that expression by using taylor formula by the same kind of calculation you did here taking higher and higher derivatives of the cosine you get the same periodic pattern of derivatives and values of derivatives at x = 0 but here's a cleaner way to do it simpler way to do it because we already knew the derivative of the sine when you differentiate you keep the same radius of convergence ok so we can multiply i can add too and multiply by a constant things like that how about integrating that's what half of this course was about isn't it so let's integrate something so the integration i'm going to do is this one: the integral from 0 to x of dt / 1+x what is that integral as a function so when i find the antiderivative of this i get ln1+t and then when i evaluate that at t = x i get ln1+x and when i evaluate the natural log at 0 i get the ln 1 which is 0 so this is what you get ok this is really valid by the way for x bigger than 1 but you don't want to think about this quite like this when x is smaller than that now i'm going to try to apply power series methods here and find use this integral to find a power series for the natural log and i'll do it by plugging into this expression what the power series for 1/1+t was and i know what that is because i wrote it down on the board up here change the variable from x to t there and so 1/1+t is 1 minus t plus t^2 minus t^3 and so on so that's the thing in the inside of the integral and now it's legal to integrate that term by term so let's do that i'm going to get something which i will then evaluate at x and at 0 so when i integrate 1 i get x and when i integrate t i get t i'm sorry when i integrate t i get t^2 / 2 and t^2 gives me t^3 / 3 and so on and so on and then when i put in t = x well i just replace all the t's by x's and when i put in t = 0 i get 0 so this equals x so i've discovered that ln1+x is x minus x^2 / 2 plus x^3 / 3 minus x^4 / 4 and so on and so on there's the power series expansion for ln1+x and because i began with a power series whose radius of convergence was just 1 i began with this power series the radius of convergence of this is also going to be 1 also because this function as i just pointed out this function goes bad when x becomes less than 1 so some problem happens and that's reflected in the radius of convergence cool so you can integrate that is the correct power series expansion for the ln1+x and another victory of euler's was to use this kind of power series expansion to calculate natural logarithms in a much more efficient way than people had done before ok one more property i think what are we at here 3 4 substitute very appropriate for me as a substitute teacher to tell you about substitution so i'm going to try to find the power series expansion of e^t^2 ok and the way i'll do that is by taking the power series expansion for e^x which we have up there and make the substitution x = t^2 in the expansion for e^x did you have a question audience: well it's just concerning the radius of convergence you can't define x so that is always positive and if so it wouldn't have a radius of convergence right professor: like i say again the worry is this ln1+x function is perfectly well behaved for large x why does the power series fail to converge for large x well suppose that x is bigger than 1 then here you get bigger and bigger powers of x which will grow to infinity and they grow large faster than the numbers 2 3 4 5 6 they grow exponentially and these just grow linearly so again the general term when x is bigger than one the general term will go off to infinity even though the function that you're talking about log of net of 1 plus x is perfectly good so the power series is not good outside of the radius of convergence it's just a fact of life yes audience: [inaudible] professor: i'd rather talk to me after class the question is why is it the smaller of the two radii of convergence the basic answer is well you can't expect it to be bigger than that smaller one because the power series only gives you information inside of that range about the function so audience: [inaudible] professor: well in this case both of the radii of convergence are infinity x has radius of convergence infinity for sure and sinx does too so you get infinity in that case ok ok let's just do this and then i'm going to integrate this and that'll be the end of what i have time for today so what's the power series expansion for this the power series expansion of this is going to be a function of t right because the variable here is t i get it by taking my expansion for e^x and putting in what x is in terms of t whoops! and so on and so on i just put in t^2 in place of x there in the series expansion for e^x i can work this out a little bit better t^2 is what it is this is going to give me a t^4 and the minus squared is going to give me a plus so i get t^4 / 2! then i get t^3 so there'll be a minus sign and a t^6 and the denominator 3! so the signs are going to alternate the powers are all even and the denominators are these factorials several times as this course has gone on the error function has made an appearance the error function was i guess it gets normalized by putting a 2 over the square root of pi in front and it's the integral of e^t^2 dt from 0 to x and this normalization is here because as x gets to be large the value becomes 1 so this error function is very important in the theory of probability and i think you calculated this fact at some point in the course so the standard definition of the error function you put a 2 over the square root of pi in front let's calculate its power series expansion so there's a 2 over the square root of pi that hurts nobody here in the front and now i want to integrate e^t^2 and i'm going to use this power series expansion for that to see what you get so i'm just going to write this out i think i did it out carefully in another example over there so i'll do it a little quicker now integrate this term by term you're just integrating powers of t so it's pretty simple so i get and then i'm evaluating at x and then at 0 so i get x minus x^3 / 3 plus x^5 / 5*2! 5 from integrating the t^4 and the 2! from this denominator that we already had and then there's a x^7 / 7*3! and plus and so on and you can imagine how they go on from there i guess to get this exactly in the form that we began talking about i should multiply through so the coefficient of x is 2 over the square root of pi and the coefficient of x^3 is 2 over 3 times the square root of pi and so on but this is a perfectly good way to write this power series expansion as well and this is a very good way to compute the value of the error function it's a new function in our experience your calculator probably calculates it and your calculator probably does it by this method ok so that's my sermon on examples of things you can do with power series so we're going to do the ceg thing in just a minute professor jerison wanted me to make an ad for 1802 just in case you were thinking of not taking it next term you really should take it it will put a lot of things in this course into context for one thing it's about vector calculus and so on so you'll learn about vectors and things like that but it comes back and explains some things in this course that might have been a little bit strange like these strange formulas for the product rule and the quotient rule and the sort of random formulas well one of the things you learn in 1802 is that they're all special cases of the chain rule and just to drive that point home he wanted me to show you this poem of his that really drives the points home forcefully i think\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mvp_s.iloc[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2: Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:29.564653Z",
     "start_time": "2019-11-11T20:22:29.409671Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_count(df):\n",
    "    '''\n",
    "    Creates a sparse matrix of counts with Count Vectorizer\n",
    "    '''\n",
    "    # define series to go into vectorizer\n",
    "    x = df['text']\n",
    "    # define vectorizer\n",
    "    cv1 = CountVectorizer()\n",
    "    # vectorize; convert to sparse matrix \"sm\"\n",
    "    sm = cv1.fit_transform(x)\n",
    "    # print the matrix\n",
    "    print(pd.DataFrame(sm.toarray(), columns=cv1.get_feature_names()))\n",
    "    # return the sparse matrix\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:36.928695Z",
     "start_time": "2019-11-11T20:22:29.567424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     00  000  0000  00000000  000000001  0000001  000001  00001  00001001  \\\n",
      "0     0    0     0         0          0        0       0      0         0   \n",
      "1     0    0     0         0          0        0       0      0         0   \n",
      "2     0    0     0         0          0        0       0      0         0   \n",
      "3     0    0     0         0          0        0       0      0         0   \n",
      "4     0    0     0         0          0        0       0      0         0   \n",
      "..   ..  ...   ...       ...        ...      ...     ...    ...       ...   \n",
      "855   0    0     0         0          0        0       0      0         0   \n",
      "856   1    0     0         0          0        0       0      0         0   \n",
      "857   0    0     0         0          0        0       0      0         0   \n",
      "858   0    0     0         0          0        0       0      0         0   \n",
      "859   0    0     0         0          0        0       0      0         0   \n",
      "\n",
      "     0001  ...  zt  zuiden  zx  zxy  zy  zyaxis  zz  zz1  zzz  zzzzzz  \n",
      "0       0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "1       0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "2       0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "3       0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "4       0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "..    ...  ...  ..     ...  ..  ...  ..     ...  ..  ...  ...     ...  \n",
      "855     0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "856     0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "857     0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "858     0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "859     0  ...   0       0   0    0   0       0   0    0    0       0  \n",
      "\n",
      "[860 rows x 27175 columns]\n"
     ]
    }
   ],
   "source": [
    "sm_mvp_v_c = vectorize_count(df_mvp_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:36.945086Z",
     "start_time": "2019-11-11T20:22:36.932585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860, 27175)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_mvp_v_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3: Reduce Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:38.363903Z",
     "start_time": "2019-11-11T20:22:36.948192Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_dim(sm):\n",
    "    # define Truncated SVD\n",
    "    lsa = TruncatedSVD(5)\n",
    "    # do LSA on sparse matrix \"sm\"\n",
    "    rd = lsa.fit_transform(sm)\n",
    "    # print explained variance ratio\n",
    "    print(\"LSA Explained Variance Ratio: \",lsa.explained_variance_ratio_)\n",
    "    # return matrix of reduced dimensions\n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:55.063532Z",
     "start_time": "2019-11-11T20:22:38.366852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Explained Variance Ratio:  [0.68294091 0.03126201 0.0259533  0.02054043 0.01713769]\n"
     ]
    }
   ],
   "source": [
    "rd_mvp_v = reduce_dim(sm_mvp_v_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:55.095994Z",
     "start_time": "2019-11-11T20:22:55.070255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.04195928e+02, -5.95668693e+01, -7.88173298e+00,\n",
       "         2.33061230e+01,  3.55245369e+01],\n",
       "       [ 1.77218204e+01,  3.94034711e-01, -8.23993924e-01,\n",
       "         2.95877453e+00,  3.62982865e-01],\n",
       "       [ 6.39328180e+02,  8.83198069e+01,  4.10248349e+01,\n",
       "        -5.85406310e+01, -4.28884284e+01],\n",
       "       ...,\n",
       "       [ 5.30604217e+02, -3.77497686e+01, -7.73703962e+01,\n",
       "        -1.83192393e+01, -2.19415246e+01],\n",
       "       [ 5.10920812e+02,  3.80267249e+01,  3.86597455e+00,\n",
       "         2.28367350e+00,  9.57524200e+00],\n",
       "       [ 6.33125456e+02,  4.62061753e+00, -2.02611315e+00,\n",
       "        -7.39795939e+01,  1.04477597e+01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_mvp_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T21:22:39.437720Z",
     "start_time": "2019-11-11T21:22:39.407541Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-num_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T21:33:47.348942Z",
     "start_time": "2019-11-11T21:33:40.829967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "the, to, that, and, of\n",
      "\n",
      "Topic  1\n",
      "we, so, to, gt, re\n",
      "\n",
      "Topic  2\n",
      "you, and, it, gt, in\n",
      "\n",
      "Topic  3\n",
      "of, we, and, gt, that\n",
      "\n",
      "Topic  4\n",
      "gt, of, that, is, this\n"
     ]
    }
   ],
   "source": [
    "x = df['text']\n",
    "cv1 = CountVectorizer()\n",
    "sm = cv1.fit_transform(x)\n",
    "lsa = TruncatedSVD(5)\n",
    "rd = lsa.fit_transform(sm)\n",
    "display_topics(lsa, cv1.get_feature_names(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T21:36:41.095213Z",
     "start_time": "2019-11-11T21:36:36.275139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "the, to, that, of, is\n",
      "\n",
      "Topic  1\n",
      "matrix, vector, row, minus, times\n",
      "\n",
      "Topic  2\n",
      "probability, the, of, event, conditional\n",
      "\n",
      "Topic  3\n",
      "node, we, this, address, list\n",
      "\n",
      "Topic  4\n",
      "gt, matrix, the, row, transpose\n",
      "\n",
      "Topic  5\n",
      "gt, laplace, of, transform, just\n",
      "\n",
      "Topic  6\n",
      "vector, probability, we, you, of\n",
      "\n",
      "Topic  7\n",
      "vector, vectors, plane, will, it\n",
      "\n",
      "Topic  8\n",
      "laplace, transform, of, you, vector\n",
      "\n",
      "Topic  9\n",
      "so, we, that, laplace, okay\n",
      "\n",
      "Topic  10\n",
      "audience, professor, laplace, so, vector\n",
      "\n",
      "Topic  11\n",
      "we, to, and, laplace, it\n",
      "\n",
      "Topic  12\n",
      "equation, audience, solution, professor, differential\n",
      "\n",
      "Topic  13\n",
      "of, transpose, to, space, matrix\n",
      "\n",
      "Topic  14\n",
      "probability, node, it, okay, solution\n",
      "\n",
      "Topic  15\n",
      "and, so, null, space, you\n",
      "\n",
      "Topic  16\n",
      "is, graph, edges, edge, row\n",
      "\n",
      "Topic  17\n",
      "lambda, audience, state, professor, graph\n",
      "\n",
      "Topic  18\n",
      "psi, partial, transpose, respect, node\n",
      "\n",
      "Topic  19\n",
      "tree, subtree, and, mit, psi\n"
     ]
    }
   ],
   "source": [
    "x = df['text']\n",
    "cv2 = TfidfVectorizer()\n",
    "sm = cv2.fit_transform(x)\n",
    "lsa = TruncatedSVD(20)\n",
    "rd = lsa.fit_transform(sm)\n",
    "display_topics(lsa, cv2.get_feature_names(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4: Cluster/Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:55.380321Z",
     "start_time": "2019-11-11T20:22:55.100460Z"
    }
   },
   "outputs": [],
   "source": [
    "# From KMeansClustering.ipynb: \n",
    "# helper function that allows us to display data in 2 dimensions and highlights the clusters\n",
    "def display_cluster(X,km=[],num_clusters=0):\n",
    "    color = 'brgcmyk'\n",
    "    alpha = 0.5\n",
    "    s = 20\n",
    "    if num_clusters == 0:\n",
    "        plt.scatter(X[:,0],X[:,1],c = color[0],alpha = alpha,s = s)\n",
    "    else:\n",
    "        for i in range(num_clusters):\n",
    "            plt.scatter(X[km.labels_==i,0],X[km.labels_==i,1],c = color[i],alpha = alpha,s=s)\n",
    "            plt.scatter(km.cluster_centers_[i][0],km.cluster_centers_[i][1],c = color[i], marker = 'x', s = 100)\n",
    "            plt.savefig(\"mvp.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:22:55.438998Z",
     "start_time": "2019-11-11T20:22:55.383398Z"
    }
   },
   "outputs": [],
   "source": [
    "def cluster(rd):\n",
    "    num_clusters = 5\n",
    "    km = KMeans(n_clusters=num_clusters,random_state=10,n_init=10) # n_init, number of times the K-mean algorithm will run\n",
    "    km.fit(rd)\n",
    "    display_cluster(rd,km,num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:23:13.173001Z",
     "start_time": "2019-11-11T20:22:55.442102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster(rd_mvp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it's something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Code Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to display topics\n",
    "# def display_topics(model, feature_names, num_top_words, topic_names=None):\n",
    "#     for ix, topic in enumerate(model.components_):\n",
    "#         if not topic_names or not topic_names[ix]:\n",
    "#             print(\"\\nTopic \", ix)\n",
    "#         else:\n",
    "#             print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "#         print(\", \".join([feature_names[i]\n",
    "#                         for i in topic.argsort()[:-num_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:23:13.184245Z",
     "start_time": "2019-11-11T20:23:13.178250Z"
    }
   },
   "outputs": [],
   "source": [
    "# How to CountVectorizer and TfIDF\n",
    "# corpus = ['This is the first document.',\n",
    "#           'This is the second document.',\n",
    "#           'And the third one. One is fun.]\n",
    "\n",
    "# # original Count Vectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cv = CountVectorizer()\n",
    "# X = cv.fit_transform(corpus).toarray()\n",
    "# pd.DataFrame(X, columns=cv.get_feature_names())\n",
    "\n",
    "# # new TF-IDF Vectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# cv_tfidf = TfidfVectorizer()\n",
    "# X_tfidf = cv_tfidf.fit_transform(corpus).toarray()\n",
    "# pd.DataFrame(X_tfidf, columns=cv_tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:23:17.778759Z",
     "start_time": "2019-11-11T20:23:13.187722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
    "# import re\n",
    "# import string\n",
    "\n",
    "# alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "# punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "# data['reviews'] = data.reviews.map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:23:20.652518Z",
     "start_time": "2019-11-11T20:23:17.782745Z"
    }
   },
   "outputs": [],
   "source": [
    "# How to make sure all components match a certain format: 'XX-###'\n",
    "# coc_regex = re.compile(r\"^[A-Z]{2}-\\d{3}.\") # any two letters plus - plus any three digits plus any character\n",
    "#                                             # to find any entries without this format\n",
    "# df_pit_clean[\"CoC Number\"].apply(lambda x: bool(coc_regex.search(x))).value_counts()\n",
    "\n",
    "# trying to display the row that doesn't satisfy the regex test\n",
    "# df_pit_clean[df_pit_clean[\"CoC Number\"].apply(lambda x: bool(coc_regex.search(x)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:23:30.612173Z",
     "start_time": "2019-11-11T20:23:20.655355Z"
    }
   },
   "outputs": [],
   "source": [
    "# How to split on a given regex delimiter - from pair-eternal_golden_braid.ipynb (Scott)\n",
    "# split_re = re.compile(r'\\W')\n",
    "# mmg_words = split_re.split(mmg.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T20:23:34.490475Z",
     "start_time": "2019-11-11T20:23:30.619319Z"
    }
   },
   "outputs": [],
   "source": [
    "# How to take some choices at random - from pair_lda.ipynb (kristen and danish)\n",
    "# import random \n",
    "# def make_doc(topic_probs, n_words):\n",
    "#     for prob in topic_probs:\n",
    "#         doc = random.choices(prob, k = n_words)\n",
    "#         print(' '.join(doc))\n",
    "# make_doc([prob_words0, prob_words1, prob_words2], 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
